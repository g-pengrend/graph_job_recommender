{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import textwrap\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Brandon\\AppData\\Local\\Temp\\ipykernel_12188\\2209732762.py:1: DtypeWarning: Columns (28,29,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('6.1.cleaned_and_merged_back.csv')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['title', 'company', 'job_type', 'is_remote', 'description_x', 'address',\n",
       "       'cleaned_address', 'lat_long', 'model_response', 'id', 'site',\n",
       "       'job_url', 'job_url_direct', 'location', 'date_posted', 'emails',\n",
       "       'description_y', 'company_url', 'company_url_direct',\n",
       "       'company_addresses', 'company_num_employees', 'company_revenue',\n",
       "       'company_description', 'logo_photo_url', 'banner_photo_url',\n",
       "       'company_industry', 'ceo_name', 'ceo_photo_url', 'salary_source',\n",
       "       'interval', 'min_amount', 'max_amount', 'currency'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('6.1.cleaned_and_merged_back.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all spaces and ensure the comma is the only separator\n",
    "df['job_type_cleaned'] = df['job_type'].str.replace(r'\\s+', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job_type\n",
       "fulltime                                               22894\n",
       "fulltime, contract                                      1086\n",
       "parttime, fulltime                                       516\n",
       "fulltime, internship                                     275\n",
       "fulltime, temporary                                      123\n",
       "parttime, fulltime, contract                              72\n",
       "parttime, fulltime, internship                            50\n",
       "fulltime, temporary, contract                             31\n",
       "parttime, fulltime, temporary, contract, internship       25\n",
       "parttime, fulltime, contract, internship                  20\n",
       "parttime, fulltime, temporary, contract                   17\n",
       "parttime, fulltime, temporary                             12\n",
       "fulltime, contract, internship                            10\n",
       "parttime, fulltime, temporary, internship                  8\n",
       "fulltime, temporary, internship                            2\n",
       "fulltime, temporary, contract, internship                  1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['job_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job_type_cleaned\n",
       "fulltime                                           22894\n",
       "fulltime,contract                                   1086\n",
       "parttime,fulltime                                    516\n",
       "fulltime,internship                                  275\n",
       "fulltime,temporary                                   123\n",
       "parttime,fulltime,contract                            72\n",
       "parttime,fulltime,internship                          50\n",
       "fulltime,temporary,contract                           31\n",
       "parttime,fulltime,temporary,contract,internship       25\n",
       "parttime,fulltime,contract,internship                 20\n",
       "parttime,fulltime,temporary,contract                  17\n",
       "parttime,fulltime,temporary                           12\n",
       "fulltime,contract,internship                          10\n",
       "parttime,fulltime,temporary,internship                 8\n",
       "fulltime,temporary,internship                          2\n",
       "fulltime,temporary,contract,internship                 1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['job_type_cleaned'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-hot Encode the 'job_type' column\n",
    "mlb = MultiLabelBinarizer()\n",
    "df['job_type_encoded'] = mlb.fit_transform(df['job_type_cleaned'].str.split(',')).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['contract' 'fulltime' 'internship' 'parttime' 'temporary']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "job_type_encoded\n",
       "[0, 1, 0, 0, 0]    22894\n",
       "[1, 1, 0, 0, 0]     1086\n",
       "[0, 1, 0, 1, 0]      516\n",
       "[0, 1, 1, 0, 0]      275\n",
       "[0, 1, 0, 0, 1]      123\n",
       "[1, 1, 0, 1, 0]       72\n",
       "[0, 1, 1, 1, 0]       50\n",
       "[1, 1, 0, 0, 1]       31\n",
       "[1, 1, 1, 1, 1]       25\n",
       "[1, 1, 1, 1, 0]       20\n",
       "[1, 1, 0, 1, 1]       17\n",
       "[0, 1, 0, 1, 1]       12\n",
       "[1, 1, 1, 0, 0]       10\n",
       "[0, 1, 1, 1, 1]        8\n",
       "[0, 1, 1, 0, 1]        2\n",
       "[1, 1, 1, 0, 1]        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the resulting encoded column and the associated class labels\n",
    "print(\"Classes:\", mlb.classes_)  # This shows the sorted order of the job types\n",
    "\n",
    "df['job_type_encoded'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Pooling - Takes attention mask into account for correct averaging\n",
    "def job_title_mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0]  # First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "# Function to get embeddings for a batch of job titles\n",
    "def get_job_title_embeddings(job_titles, tokenizer, model, batch_size=32, device='cpu'):\n",
    "    embeddings = []\n",
    "    \n",
    "    for i in range(0, len(job_titles), batch_size):\n",
    "        batch_titles = job_titles[i:i + batch_size]\n",
    "        \n",
    "        # Tokenize the job titles\n",
    "        encoded_input = tokenizer(batch_titles, padding=True, truncation=True, return_tensors='pt').to(device)\n",
    "        \n",
    "        # Compute token embeddings\n",
    "        with torch.no_grad():\n",
    "            model_output = model(**encoded_input)\n",
    "        \n",
    "        # Perform mean pooling\n",
    "        sentence_embeddings = job_title_mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "        \n",
    "        # Normalize the embeddings\n",
    "        sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "        \n",
    "        # Append to list\n",
    "        embeddings.append(sentence_embeddings.cpu().numpy())\n",
    "    \n",
    "    # Return embeddings as a numpy array\n",
    "    return np.vstack(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Pooling - Takes attention mask into account for correct averaging\n",
    "def job_description_mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0]  # First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "# Function to process long job descriptions by splitting into overlapping chunks of text\n",
    "def get_job_description_embedding(job_description, tokenizer, model, max_chunk_length=512, overlap=50, device='cpu'):\n",
    "    # Split the raw text into chunks, ensuring no chunk exceeds max_chunk_length\n",
    "    tokens_per_chunk = max_chunk_length - 2  # Leave space for special tokens\n",
    "    words = job_description.split()\n",
    "    \n",
    "    # Create overlapping text chunks\n",
    "    chunks = [' '.join(words[i:i+tokens_per_chunk]) for i in range(0, len(words), tokens_per_chunk - overlap)]\n",
    "    \n",
    "    embeddings = []\n",
    "    for chunk in chunks:\n",
    "        # Tokenize the chunk (now we're passing the raw text directly)\n",
    "        encoded_input = tokenizer(chunk, return_tensors='pt', padding=True, truncation=True, max_length=max_chunk_length).to(device)\n",
    "        \n",
    "        # Compute token embeddings\n",
    "        with torch.no_grad():\n",
    "            model_output = model(**encoded_input)\n",
    "        \n",
    "        # Perform mean pooling\n",
    "        sentence_embedding = job_description_mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "        \n",
    "        # Normalize the embedding\n",
    "        sentence_embedding = F.normalize(sentence_embedding, p=2, dim=1)\n",
    "        \n",
    "        # Append the chunk embedding\n",
    "        embeddings.append(sentence_embedding.cpu().numpy())\n",
    "\n",
    "    # Average embeddings from all chunks to get a single embedding\n",
    "    if embeddings:\n",
    "        return np.mean(embeddings, axis=0).squeeze()\n",
    "    else:\n",
    "        return np.zeros((384,))  # Return a zero vector if no chunks were processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer and model from Hugging Face Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L12-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L12-v2')\n",
    "\n",
    "# If GPU is available, move model to GPU\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df[['title', 'company', 'job_type_encoded', 'is_remote', 'lat_long', 'model_response']]\n",
    "df_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process job titles in batches\n",
    "job_titles = df_new['title'].tolist()\n",
    "embeddings = get_job_title_embeddings(job_titles, tokenizer, model, batch_size=256, device=device)\n",
    "\n",
    "# Assign the embeddings to the dataframe as a list for each row\n",
    "df_new['job_title_embedding'] = [embedding for embedding in embeddings]\n",
    "\n",
    "# Process job descriptions with overlapping chunks\n",
    "df_new['job_description_embedding'] = df_new['model_response'].apply(\n",
    "    get_job_description_embedding, \n",
    "    tokenizer=tokenizer, \n",
    "    model=model, \n",
    "    max_chunk_length=512,  # Model's max token length\n",
    "    overlap=50,            # Amount of token overlap between chunks\n",
    "    device=device\n",
    ")\n",
    "\n",
    "df_new['job_description_embedding'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['job_description_embedding'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ready = df_new.drop(columns=['title', 'model_response'])\n",
    "df_ready['lat_long'] = df_ready['lat_long'].apply(ast.literal_eval)\n",
    "\n",
    "df_ready.to_csv('final_graph_model_training.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start here if final_graph_model_training.csv exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the correct line below depending on if you want to start from scratch or load the csv\n",
    "import pandas as pd\n",
    "\n",
    "# df_ready.to_csv('final_graph_model_training.csv', index=False)\n",
    "df_ready = pd.read_csv('7.1.final_graph_model_training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Helper Functions\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from geopy.distance import geodesic\n",
    "from tqdm import tqdm\n",
    "import multiprocessing as mp\n",
    "from itertools import combinations\n",
    "import time\n",
    "import torch\n",
    "import pickle\n",
    "from annoy import AnnoyIndex\n",
    "from scipy.spatial import cKDTree\n",
    "import faiss\n",
    "from sklearn.cluster import KMeans\n",
    "import cupy as cp\n",
    "import ast\n",
    "\n",
    "def calculate_total_potential_edges(df_ready):\n",
    "    \"\"\"\n",
    "    Calculate the total number of potential edges in a complete graph.\n",
    "    \n",
    "    Args:\n",
    "        df_ready (pd.DataFrame): Input dataframe\n",
    "        \n",
    "    Returns:\n",
    "        int: Total number of potential edges\n",
    "    \"\"\"\n",
    "    n = len(df_ready)\n",
    "    return (n * (n-1)) // 2\n",
    "\n",
    "def save_graph_checkpoint(graph, filename):\n",
    "    \"\"\"\n",
    "    Save the graph to a pickle file checkpoint.\n",
    "    \n",
    "    Args:\n",
    "        graph (nx.Graph): Graph to save\n",
    "        filename (str): Path to save the checkpoint\n",
    "    \"\"\"\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(graph, f)\n",
    "    print(f\"Saved checkpoint: {filename}\")\n",
    "\n",
    "def load_graph_checkpoint(filename):\n",
    "    \"\"\"\n",
    "    Load a graph checkpoint from a pickle file.\n",
    "    \n",
    "    Args:\n",
    "        filename (str): Path to the checkpoint file\n",
    "        \n",
    "    Returns:\n",
    "        nx.Graph: Loaded graph\n",
    "    \"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        graph = pickle.load(f)\n",
    "    \n",
    "    # Parse string embeddings and lat_long back to proper format\n",
    "    for node in graph.nodes():\n",
    "        if 'job_title_embedding' in graph.nodes[node]:\n",
    "            graph.nodes[node]['job_title_embedding'] = parse_embedding(graph.nodes[node]['job_title_embedding'])\n",
    "        if 'job_description_embedding' in graph.nodes[node]:\n",
    "            graph.nodes[node]['job_description_embedding'] = parse_embedding(graph.nodes[node]['job_description_embedding'])\n",
    "        if 'lat_long' in graph.nodes[node]:\n",
    "            graph.nodes[node]['lat_long'] = ast.literal_eval(graph.nodes[node]['lat_long'])\n",
    "            \n",
    "    return graph\n",
    "    \n",
    "def parse_embedding(embedding_str):\n",
    "    # Remove newlines and replace multiple spaces with a single space\n",
    "    cleaned_str = embedding_str.replace('\\n', ' ').strip()\n",
    "    \n",
    "    # Split the string into individual components and convert them to floats\n",
    "    try:\n",
    "        embedding_list = [float(val) for val in cleaned_str.strip('[]').split()]\n",
    "        return embedding_list\n",
    "    except ValueError:\n",
    "        # In case of any parsing errors, return np.nan or handle as needed\n",
    "        return np.nan\n",
    "    \n",
    "def initialize_graph(df_ready):\n",
    "    \"\"\"\n",
    "    Initialize graph and add nodes with their attributes.\n",
    "    \n",
    "    Args:\n",
    "        df_ready (pd.DataFrame): Input dataframe with job data\n",
    "        \n",
    "    Returns:\n",
    "        nx.Graph: Graph with nodes added\n",
    "    \"\"\"\n",
    "    print(\"Initializing graph and adding nodes...\")\n",
    "    graph = nx.Graph()\n",
    "    \n",
    "    # Convert embeddings from string to list\n",
    "    df_ready['job_title_embedding'] = df_ready['job_title_embedding'].apply(parse_embedding)\n",
    "    df_ready['job_description_embedding'] = df_ready['job_description_embedding'].apply(parse_embedding)\n",
    "    \n",
    "    for idx, row in tqdm(df_ready.iterrows(), total=len(df_ready), desc=\"Adding nodes\"):\n",
    "        graph.add_node(\n",
    "            f\"job_{idx}\",\n",
    "            job_title_embedding=row['job_title_embedding'],\n",
    "            job_description_embedding=row['job_description_embedding'],\n",
    "            company=row['company'],\n",
    "            job_type_encoding=row['job_type_encoded'],\n",
    "            is_remote=row['is_remote'],\n",
    "            lat_long=row['lat_long']\n",
    "        )\n",
    "    \n",
    "    save_graph_checkpoint(graph, 'graph_with_nodes.pkl')\n",
    "    return graph\n",
    "\n",
    "def create_company_edges(df_ready, graph):\n",
    "    \"\"\"\n",
    "    Create edges between jobs from the same company.\n",
    "    \n",
    "    Args:\n",
    "        df_ready (pd.DataFrame): Input dataframe with job data\n",
    "        graph (nx.Graph): Graph to add edges to\n",
    "        \n",
    "    Returns:\n",
    "        nx.Graph: Graph with company edges added\n",
    "    \"\"\"\n",
    "    print(\"Creating edges between jobs from the same company...\")\n",
    "    company_groups = df_ready.groupby('company').groups\n",
    "    \n",
    "    total_company_edges = sum(len(indices) * (len(indices) - 1) // 2 \n",
    "                            for indices in company_groups.values())\n",
    "    \n",
    "    pbar = tqdm(total=total_company_edges, desc=\"Company edges\")\n",
    "    edge_count = 0\n",
    "    \n",
    "    for company, indices in company_groups.items():\n",
    "        if len(indices) > 1:\n",
    "            for idx1, idx2 in combinations(indices, 2):\n",
    "                graph.add_edge(f\"job_{idx1}\", f\"job_{idx2}\", \n",
    "                             type=\"same_company\")\n",
    "                edge_count += 1\n",
    "                pbar.update(1)\n",
    "    \n",
    "    pbar.close()\n",
    "    print(f\"Added {edge_count} company edges\")\n",
    "    save_graph_checkpoint(graph, 'graph_with_company_edges.pkl')\n",
    "    return graph\n",
    "\n",
    "def create_job_type_edges(df_ready, graph, threshold=0.5, n_trees=10, k=10):\n",
    "    \"\"\"\n",
    "    Create edges between jobs with similar job types using Jaccard similarity.\n",
    "    \n",
    "    Args:\n",
    "        df_ready (pd.DataFrame): Input dataframe with job data\n",
    "        graph (nx.Graph): Graph to add edges to\n",
    "        threshold (float): Minimum similarity threshold for creating edges\n",
    "        n_trees (int): Number of trees for Annoy index\n",
    "        k (int): Number of nearest neighbors to search for (reduced from default)\n",
    "        \n",
    "    Returns:\n",
    "        nx.Graph: Graph with job type similarity edges added\n",
    "    \"\"\"\n",
    "    print(f\"Creating edges between jobs with similar job types (threshold={threshold})...\")\n",
    "    \n",
    "    job_types = np.array([eval(x) for x in df_ready['job_type_encoded']])\n",
    "    n_jobs = len(job_types)\n",
    "    edge_count = 0\n",
    "\n",
    "    index = AnnoyIndex(job_types.shape[1], 'hamming')\n",
    "    \n",
    "    for i in tqdm(range(n_jobs), desc=\"Building index\"):\n",
    "        index.add_item(i, job_types[i])\n",
    "    \n",
    "    index.build(n_trees)\n",
    "    \n",
    "    for i in tqdm(range(n_jobs), desc=\"Finding similar jobs\"):\n",
    "        similar_indices = index.get_nns_by_item(i, k)  # Reduced k for better performance\n",
    "        \n",
    "        for j in similar_indices:\n",
    "            if j > i:\n",
    "                intersection = np.sum(np.logical_and(job_types[i], job_types[j]))\n",
    "                union = np.sum(np.logical_or(job_types[i], job_types[j]))\n",
    "                similarity = intersection / union if union > 0 else 0\n",
    "                \n",
    "                if similarity > threshold:\n",
    "                    graph.add_edge(f\"job_{i}\", f\"job_{j}\",\n",
    "                                type=\"job_type_similarity\",\n",
    "                                weight=float(similarity))\n",
    "                    edge_count += 1\n",
    "    \n",
    "    print(f\"Added {edge_count} job type similarity edges\")\n",
    "    save_graph_checkpoint(graph, 'graph_with_job_type_edges.pkl')\n",
    "    return graph\n",
    "\n",
    "def create_location_edges(df_ready, graph, max_distance=3, min_weight=0.4, chunk_size=500, sigma=1.5):\n",
    "    \"\"\"\n",
    "    Create edges between jobs within geographical proximity using Gaussian decay.\n",
    "    Optimized for Singapore's scale.\n",
    "    \n",
    "    Args:\n",
    "        df_ready (pd.DataFrame): Input dataframe with job data\n",
    "        graph (nx.Graph): Graph to add edges to\n",
    "        max_distance (float): Maximum distance in km (3km default for Singapore's context)\n",
    "        min_weight (float): Minimum weight threshold for creating edges\n",
    "        chunk_size (int): Size of chunks for processing\n",
    "        sigma (float): Standard deviation for Gaussian decay (1.5km default)\n",
    "    \"\"\"\n",
    "    print(f\"Creating edges between jobs within {max_distance}km of each other...\")\n",
    "    print(f\"Using minimum weight threshold of {min_weight}\")\n",
    "    edge_count = 0\n",
    "\n",
    "    # Extract coordinates\n",
    "    lat_longs = []\n",
    "    valid_indices = []\n",
    "    \n",
    "    for idx in tqdm(range(len(df_ready)), desc=\"Extracting coordinates\"):\n",
    "        try:\n",
    "            lat_long = eval(df_ready.iloc[idx]['lat_long'])\n",
    "            lat_longs.append(lat_long)\n",
    "            valid_indices.append(idx)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    print(f\"Processing {len(valid_indices)} locations\")\n",
    "    \n",
    "    lat_longs = cp.array(lat_longs)\n",
    "    n_points = len(lat_longs)\n",
    "    \n",
    "    # Build KD-tree for efficient spatial querying\n",
    "    tree = cKDTree(cp.asnumpy(lat_longs))\n",
    "    \n",
    "    # Process in chunks\n",
    "    for i in tqdm(list(range(0, n_points, chunk_size)), desc=\"Processing location proximity\"):\n",
    "        chunk_end = min(i + chunk_size, n_points)\n",
    "        chunk_points = lat_longs[i:chunk_end]\n",
    "        \n",
    "        # Find nearby points within max_distance\n",
    "        chunk_points_cpu = cp.asnumpy(chunk_points)\n",
    "        nearby_points = tree.query_ball_point(chunk_points_cpu, max_distance/111.32)\n",
    "        \n",
    "        for j, neighbors in enumerate(nearby_points):\n",
    "            if not neighbors:\n",
    "                continue\n",
    "                \n",
    "            point1 = chunk_points[j]\n",
    "            points2 = lat_longs[neighbors]\n",
    "            \n",
    "            # Calculate distances using haversine formula\n",
    "            lat1, lon1 = point1[0], point1[1]\n",
    "            lat2, lon2 = points2[:, 0], points2[:, 1]\n",
    "            \n",
    "            dlat = cp.radians(lat2 - lat1)\n",
    "            dlon = cp.radians(lon2 - lon1)\n",
    "            lat1, lat2 = cp.radians(lat1), cp.radians(lat2)\n",
    "            \n",
    "            a = cp.sin(dlat/2)**2 + cp.cos(lat1) * cp.cos(lat2) * cp.sin(dlon/2)**2\n",
    "            distances = 2 * 6371 * cp.arcsin(cp.sqrt(a))  # Earth radius in km\n",
    "            \n",
    "            # Calculate weights with Gaussian decay\n",
    "            weights = cp.exp(-(distances**2)/(2*sigma**2))\n",
    "            \n",
    "            # Apply distance and weight thresholds\n",
    "            weights = cp.where((distances <= max_distance) & (weights >= min_weight), weights, 0)\n",
    "            \n",
    "            weights_cpu = cp.asnumpy(weights)\n",
    "            actual_idx1 = valid_indices[i+j]\n",
    "            \n",
    "            # Add edges only for significant weights and avoid duplicates\n",
    "            for k, neighbor_idx in enumerate(neighbors):\n",
    "                if (neighbor_idx > i+j and  # Only process upper triangle\n",
    "                    weights_cpu[k] > min_weight):\n",
    "                    actual_idx2 = valid_indices[neighbor_idx]\n",
    "                    \n",
    "                    # Add edge with weight\n",
    "                    graph.add_edge(f\"job_{actual_idx1}\", f\"job_{actual_idx2}\",\n",
    "                                 type=\"location_proximity\", \n",
    "                                 weight=float(weights_cpu[k]))\n",
    "                    edge_count += 1\n",
    "            \n",
    "            # Print progress every 5000 edges\n",
    "            if edge_count % 5000 == 0:\n",
    "                print(f\"Created {edge_count} edges so far...\")\n",
    "\n",
    "    print(f\"Added {edge_count} location proximity edges\")\n",
    "    save_graph_checkpoint(graph, 'graph_with_location_edges.pkl')\n",
    "    return graph\n",
    "\n",
    "def create_embedding_edges(df_ready, graph, embedding_type, threshold=0.7, k=10, n_clusters=500):\n",
    "    \"\"\"\n",
    "    Create edges between jobs with similar embeddings using parallel processing and optimized FAISS search.\n",
    "    \n",
    "    Args:\n",
    "        df_ready (pd.DataFrame): Input dataframe with job data\n",
    "        graph (nx.Graph): Graph to add edges to\n",
    "        embedding_type (str): Either 'job_title_embedding' or 'job_description_embedding'\n",
    "        threshold (float): Minimum similarity threshold for creating edges\n",
    "        k (int): Number of nearest neighbors to search for\n",
    "        n_clusters (int): Number of clusters to use\n",
    "        \n",
    "    Returns:\n",
    "        nx.Graph: Graph with embedding similarity edges added\n",
    "    \"\"\"\n",
    "    print(f\"Creating edges between jobs with similar {embedding_type} (threshold={threshold})...\")\n",
    "    edge_count = 0\n",
    "    use_gpu = torch.cuda.is_available()\n",
    "    \n",
    "    # Get embeddings and normalize once\n",
    "    embeddings = np.array([parse_embedding(row[embedding_type]) for _, row in df_ready.iterrows()]).astype('float32')\n",
    "    faiss.normalize_L2(embeddings)\n",
    "    n_jobs = len(df_ready)\n",
    "    \n",
    "    # Create optimized IVF index\n",
    "    d = embeddings.shape[1]  # Embedding dimension\n",
    "    nlist = min(n_clusters, int(np.sqrt(n_jobs)))  # Number of Voronoi cells\n",
    "    quantizer = faiss.IndexFlatIP(d)\n",
    "    index = faiss.IndexIVFFlat(quantizer, d, nlist, faiss.METRIC_INNER_PRODUCT)\n",
    "    \n",
    "    if use_gpu:\n",
    "        res = faiss.StandardGpuResources()\n",
    "        index = faiss.index_cpu_to_gpu(res, 0, index)\n",
    "    \n",
    "    # Train and add vectors\n",
    "    index.train(embeddings)\n",
    "    index.add(embeddings)\n",
    "    \n",
    "    # Process in batches\n",
    "    edge_type = \"title_similarity\" if embedding_type == \"job_title_embedding\" else \"description_similarity\"\n",
    "    batch_size = 1000\n",
    "    \n",
    "    for start_idx in tqdm(range(0, n_jobs, batch_size), desc=\"Finding similar jobs\"):\n",
    "        end_idx = min(start_idx + batch_size, n_jobs)\n",
    "        batch_embeddings = embeddings[start_idx:end_idx]\n",
    "        \n",
    "        # Batch search\n",
    "        similarities, indices = index.search(batch_embeddings, k)\n",
    "        \n",
    "        # Process results\n",
    "        for i, (sims, nbrs) in enumerate(zip(similarities, indices)):\n",
    "            global_idx = start_idx + i\n",
    "            for sim, nbr in zip(sims, nbrs):\n",
    "                if nbr <= global_idx or sim < threshold or nbr == -1:\n",
    "                    continue\n",
    "                graph.add_edge(f\"job_{global_idx}\", f\"job_{nbr}\",\n",
    "                             type=edge_type, weight=float(sim))\n",
    "                edge_count += 1\n",
    "    \n",
    "    print(f\"Added {edge_count} {edge_type} edges\")\n",
    "    checkpoint_name = 'graph_with_title_edges.pkl' if edge_type == \"title_similarity\" else 'graph_with_description_edges.pkl'\n",
    "    save_graph_checkpoint(graph, checkpoint_name)\n",
    "    return graph\n",
    "\n",
    "def build_complete_graph(df_ready, resume_from=None):\n",
    "    \"\"\"\n",
    "    Build the complete graph with all edge types.\n",
    "    \n",
    "    Args:\n",
    "        df_ready (pd.DataFrame): Input dataframe with job data\n",
    "        resume_from (str): Checkpoint to resume from ('nodes', 'company', 'job_type', 'location', 'title', 'description')\n",
    "        \n",
    "    Returns:\n",
    "        nx.Graph: Complete graph with all edges\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    if resume_from is None:\n",
    "        graph = initialize_graph(df_ready)\n",
    "    else:\n",
    "        checkpoint_files = {\n",
    "            'nodes': 'graph_with_nodes.pkl',\n",
    "            'company': 'graph_with_company_edges.pkl',\n",
    "            'job_type': 'graph_with_job_type_edges.pkl',\n",
    "            'location': 'graph_with_location_edges.pkl',\n",
    "            'title': 'graph_with_title_edges.pkl',\n",
    "            'description': 'graph_with_description_edges.pkl'\n",
    "        }\n",
    "        graph = load_graph_checkpoint(checkpoint_files[resume_from])\n",
    "    \n",
    "    steps = ['company', 'job_type', 'location', 'title', 'description']\n",
    "    start_idx = steps.index(resume_from) + 1 if resume_from in steps else 0\n",
    "    \n",
    "    for step in steps[start_idx:]:\n",
    "        step_start = time.time()\n",
    "        if step == 'company':\n",
    "            graph = create_company_edges(df_ready, graph)\n",
    "        elif step == 'job_type':\n",
    "            graph = create_job_type_edges(df_ready, graph)\n",
    "        elif step == 'location':\n",
    "            graph = create_location_edges(\n",
    "                    df_ready, \n",
    "                    graph,\n",
    "                    max_distance=2,      # Only connect very close jobs\n",
    "                    min_weight=0.5,      # Only strong connections\n",
    "                    sigma=1,            # Sharp distance decay\n",
    "                    chunk_size=500\n",
    "                )\n",
    "        elif step == 'title':\n",
    "            graph = create_embedding_edges(df_ready, graph, 'job_title_embedding', threshold=0.7, k=10)\n",
    "        elif step == 'description':\n",
    "            graph = create_embedding_edges(df_ready, graph, 'job_description_embedding', threshold=0.7, k=10)\n",
    "        step_end = time.time()\n",
    "        print(f\"{step} step took {(step_end - step_start)/60:.2f} minutes\")\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\nTotal graph construction time: {total_time/60:.2f} minutes\")\n",
    "    print(\"\\nGraph construction complete!\")\n",
    "    print(f\"Nodes: {graph.number_of_nodes()}, Edges: {graph.number_of_edges()}\")\n",
    "    \n",
    "    save_graph_checkpoint(graph, 'final_complete_graph.pkl')\n",
    "    print(\"Final graph saved to 'final_complete_graph.pkl'\")\n",
    "    \n",
    "    return graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total graph construction time: 7.08 minutes\n",
      "\n",
      "Graph construction complete!\n",
      "Nodes: 25142, Edges: 79444658\n",
      "Saved checkpoint: final_complete_graph.pkl\n",
      "Final graph saved to 'final_complete_graph.pkl'\n"
     ]
    }
   ],
   "source": [
    "graph = build_complete_graph(df_ready, resume_from='description')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes: 25142\n",
      "Edges: 79444658\n",
      "\n",
      "Sample node data: ('job_0', {'job_title_embedding': [-0.0323692635, 0.037560612, -0.0851607397, -0.0453846455, -0.0546593554, -0.0279194303, 0.0278429296, 0.0215941686, 0.0325031728, 0.000887234812, 0.036646761, -0.0450273678, -0.0109668206, -0.0368140303, -0.0451355092, 0.0584830716, 0.114421636, 0.0379366949, -0.0109098526, -0.0450774394, -0.0636187941, -0.0283169001, -0.0749196559, 0.0460793413, -0.00873038266, 0.0490450747, -0.0230729543, 0.083348833, 0.0108598638, -0.0804005265, -0.0902405754, 0.0268752687, 0.0291939843, 0.0203662012, -0.0047371788, -0.0222695544, -0.0255234633, 0.0452349409, 0.028607415, -0.00115934608, -0.0206206571, -0.00999114104, -0.0118169105, -0.0274297539, -0.081966795, 0.0121426117, -0.0515504405, -0.0148908487, 0.0312867016, 0.0425315909, 0.0544571318, 0.00782229751, 0.011188155, 0.0547044016, -0.0220145993, 0.0660661459, -0.000419043761, 0.0151083982, -0.0381165333, -0.0169295501, -0.0283929724, 0.0029114394, -0.0551629476, -0.000226649194, -0.0343298875, -0.00412429823, -0.0298547298, -0.0337917432, -0.00667487271, -0.0516205207, -0.0235408433, -0.0655120388, -0.0543309487, -0.00318038044, 0.118260279, 0.0123469625, 0.0310083572, -0.00657702377, -0.0433183387, -0.031532757, -0.0532171801, -0.0790918916, -0.0897181183, -0.0554492138, -0.0425002277, -0.000756329333, -0.0165863, -0.106061913, 0.0259988382, 0.0207840949, 0.00133714674, -0.00926006585, 0.00314535759, -0.0602836423, -0.018318139, 0.0256741643, 0.00914465636, -0.0555429906, -0.0884505436, 0.39128226, -0.00247407961, -0.00223034644, -0.0644639209, 0.00810331851, 0.0130994283, -0.0324723758, -0.0285277367, 0.0155969588, 0.0452222973, 0.0154045047, 0.0034656194, -0.0148824835, 0.0111183515, -0.00905900355, 0.0309257172, -0.0648853332, 0.00192772993, -0.0646893084, -0.0407922976, 0.0253239293, -0.022198759, 0.0132965529, -0.0609473698, 0.0668524578, -0.0485373959, -0.0828857571, 0.0591504909, 0.0367421769, 0.0702980533, -0.031284254, 0.0292981789, -0.0124304015, -0.0186609458, 0.0325256102, -0.00764538813, 0.0358827077, 0.0413202457, 0.0221810602, 0.00830523204, -0.0865380988, -0.0776792392, 0.0178593751, 0.0483536199, 0.0277861524, -0.144324973, -0.00760203507, -0.0401397571, -0.0447938107, -0.0334054939, -0.0244215354, -0.00575259374, -0.0520751402, 0.000775870751, -0.0123337768, 0.01293384, -0.080203414, 0.0211065952, -0.0449649915, 0.0214948338, 0.0135897845, -0.0142045617, -0.0263703838, -0.0934049189, 0.0557276681, 0.0303679276, 0.00374490186, 0.0913090929, 0.00638637133, -0.0277776998, 0.0345626883, 0.0453553386, -0.0230159592, -0.00479518948, -0.111290269, -0.00895944051, 0.00104231539, 0.0237247851, -0.0651265085, 0.0776792318, 0.0445088558, 0.0391672403, 0.0254097451, 0.01759452, -0.0165704452, 0.0225449074, -0.00494741416, -0.00493709696, 0.00611147424, -0.00426019914, 0.0209297892, -0.0770777613, 0.0908500254, 0.0892148167, 0.00770267053, 0.0151695954, 0.0580228493, -0.0591513738, -0.114342354, -0.0478661917, -0.04457343, -0.0437174551, 0.0802927762, -0.0829034522, 0.0353400931, 0.0543061979, -0.0156353936, 0.00663642865, 0.0361496247, 0.0429536663, 0.0683567822, 0.00458838232, 0.0552805252, -0.02193534, -0.0199466478, 0.0235863067, -0.00450922083, 0.0406951569, 0.140976965, -0.0815058723, -0.00963929854, 0.00867818482, 0.0831316859, 0.0352667086, 1.43831623e-32, 0.0288145263, -0.0634856895, 0.0123033132, -0.0052141021, -0.0359964408, -0.0333254412, -0.0127209127, -0.0234470386, -0.0208499115, 0.0212439578, 0.0727671981, 0.0653406158, -0.0257615652, 0.0140882498, 0.0433069579, 0.0341918468, 0.037436489, -0.0260379836, 0.0336297713, 0.0465884171, 0.073693268, 0.107746378, -0.0389717631, 0.0922504738, -0.0379243158, 0.024798058, 0.0851481929, 0.00906614494, -0.00610294566, -0.0480599292, 0.00496918568, 0.0391633324, 0.0467728637, 0.0384538323, 0.00237442995, -0.00906903204, 0.0311495718, 0.0208101738, -0.0126826223, 0.0279557668, 0.00216998253, 0.0365901999, -0.0197251514, 0.13924481, 0.0127784228, -0.0235874821, 0.0118140243, -0.0658190325, -0.0401728563, 0.0803137273, -0.0127761886, 0.0938898176, -0.0634313896, 0.0539411977, -0.00924549811, -0.1209848, 0.0740353316, -0.0249420553, 0.0851942077, 0.0758455768, -0.0220798608, -0.00362527091, 0.0545755476, -0.0227589048, 0.107168436, 0.0712979361, -0.0360227637, -0.0520168282, -0.0382262431, -0.00720303366, -0.111469358, -0.00258243666, 0.104044072, -0.0653100759, -0.0136057567, 0.0007249685, 0.103582293, 0.0351125263, 0.00933734607, -0.00114919676, -0.0330896378, -0.0469578356, -0.00655823341, -0.00230119191, 0.0529548526, -0.0253250729, -0.0131702144, 0.0220445693, -0.0419955254, -0.0464358702, 0.0301925503, -0.0476837568, -0.00450549182, -0.0238191169, 0.100967191, -1.76783213e-32, -0.00518036308, 0.0328982249, -5.42606685e-05, 0.0169234872, 0.0699944422, 0.0534766354, 0.0379161797, -0.0146630788, -0.00334069971, 0.0303177554, 0.0830600858, 0.0131890038, -0.00475431141, -0.00619639782, -0.0246302467, -0.0220883377, -0.0293468554, 0.0417624228, 0.0127821313, 0.0243057236, -0.0116377054, 0.0614821166, 0.0854958892, -0.0465557948, 0.0039823195, -0.0219085813, -0.110072725, -0.00188876735, 0.0245277695, -0.0392255001, -0.017779028, 0.041083131, 0.0290686078, -0.0824375972, -0.00121110445, -0.00798466243, 0.0542106181, -0.0256740227, -0.0270067137, 0.0229956564, -0.0311662741, 0.0619803108, -0.00923316181, -0.0264205784, -0.00206903275, 0.0384881385, 0.102722503, -0.00187071436, -0.0234825388, -0.0434261151, -0.0119220717, 0.0157711282, 0.0530413501, 0.0101837898, -0.0161338169, 0.0596855059, -0.072131969, -0.0772478729, -0.0446728319, -0.0175949782, 0.0365964286, -0.0143841049, -0.0724985972, 0.0135575728], 'job_description_embedding': [0.0364928544, 0.0229546651, 0.0382401571, 0.0592471026, 0.0319772027, -0.00618717307, 0.0327850059, -0.0614954121, -0.128817067, -0.0445765331, -0.0505791977, -0.0556147993, 0.0296713077, 0.0855619982, 0.0190957617, -0.00826452579, 0.0582200028, 0.00413926458, 0.0140653206, -0.0558966063, -0.0661553293, 0.00995611306, -0.0186332017, -0.0374281406, 0.0405047312, -0.0635395125, 0.0365796238, 0.0372376405, -0.0164702814, -0.0322364718, -0.0113707585, 0.0236477423, 0.0358835571, 0.0301380996, 0.0437186398, 0.193368807, -0.00682446174, -0.0214293078, 0.048211161, -0.0158358272, 0.0583657362, 0.0159103926, 0.00495204004, -0.00803317595, 0.0207290146, -0.0472191907, 0.0750665143, 0.00316392351, -0.0435716435, 0.0174822304, -0.0449199528, -0.0256875511, 0.0668603182, -0.048777543, -0.0270033702, -0.0913284421, 0.0107634095, -0.0988661051, -0.0599086918, -0.0783258155, 0.0115558468, -0.0225886758, 0.00560818333, 0.00754998066, 0.00344080036, 0.0564387478, -0.129369304, -0.0106958859, -0.0175501164, -0.0895912647, -0.0804907829, -0.0259433687, -0.0610160045, 0.0623396598, 0.010200141, 0.00881079305, -0.0342469923, -0.00486409012, 0.0139151365, -0.0297677852, -0.0129658794, -0.00242109178, 0.00754315872, 0.0168106537, 0.0141748982, 0.017053023, -0.0482148454, -0.019525649, 0.022809118, 0.0242336318, 0.0722049996, -0.0729160979, -0.0336161293, -0.0833360702, 0.00680711074, -0.0338155106, -0.0682516173, 0.000690144778, 0.0600614883, -0.012483147, 0.061897058, 0.0841215476, 0.138690293, 0.0156089934, -0.110535376, 0.0612647794, 0.0351449847, -0.0625724569, 0.0329796895, -0.00568579789, -0.0780197084, 0.0424728096, -0.0370895267, -0.0401840135, 0.0100729773, 0.0197940674, -0.0678629279, 0.130778477, -0.0414995924, -0.0322848707, 0.0549642704, 0.0531237945, 0.0316418484, 0.0210385136, 0.00654016435, -0.0696910396, 0.062894538, -0.00607657526, -0.148391232, 0.0898125768, -0.0253445487, 0.112730823, 0.0601800755, 0.0523854159, -0.112736613, -0.0709913, 0.0545689203, 0.0115667796, -0.0538522042, -0.00538914092, -0.00576464226, -0.0202087164, -0.00656955969, 0.0122802723, 0.0234057419, -0.0396360569, -0.0388765223, -0.00153655792, 0.0449452214, -0.0457917303, -0.0452247635, -0.00750974845, 0.0623245835, 0.0327010415, 0.0629530698, 0.0413270853, 0.0643879771, -0.020035224, -0.034536317, 0.0344446115, 0.0605411828, -0.023460282, -0.0264252853, 0.00962501857, -0.00961338729, -0.0237670988, -0.0165019892, -0.0117089758, -0.164644971, -0.0734917074, -0.017416602, 0.0602889694, -0.0286653712, -0.0382752791, 0.0687135756, -0.0259679705, 0.0502222702, 0.090642564, 0.0228762086, -0.0675605386, 0.0193421654, -0.0223511476, 0.0356821939, 0.00676594255, 0.0584258549, 0.0396697931, -0.0343459435, -0.100821331, 0.171071529, -0.0493320562, 0.0282839909, -0.0245172661, 0.016149573, -0.0361048914, 0.0334983952, 0.0111077055, 0.064003177, -0.0825286955, 0.0104260882, 0.0366790071, -0.00729327789, 0.0961335003, -0.0672337264, 0.0513937734, 0.0404797941, -0.00336193107, 0.0861158147, 0.0175328851, 0.030346958, 0.0886671394, 0.0634275153, -0.00132156885, 0.0413285829, -0.0376426391, 0.0617200881, 0.0670840964, 0.0631245226, 0.030078005, -0.00532123027, -0.0369142741, 0.0193397775, 0.0602114536, -0.0214995574, -1.16061127e-32, -0.0495273359, 0.0171222612, 0.0554801151, -0.0184570979, -0.0362529978, -0.0296389125, -0.0154816462, -0.0868446305, 0.0406958722, -0.0130058583, -0.0944467112, 0.028383974, -0.0159223005, -0.00211985176, 0.0555225536, -0.121888518, 0.0557366237, 0.00716061797, -0.115423664, -0.017654296, 0.0934635326, 0.0714069828, -0.0223153159, -0.0187193491, -0.0929075032, 0.0296504013, -0.0168310069, -0.0398974977, -0.0384935737, -0.0493126959, -0.0276999325, -0.0257869698, -0.0327163972, -0.0275224578, 0.0580830835, 0.0100572007, 0.0056452225, 0.0266729835, -0.0577755868, -0.016761018, 0.0160814207, -0.00281225098, -0.0322770774, -0.0284356996, 0.063191928, -0.0733917058, 0.042376969, -0.100894667, -0.015460656, -0.084804602, -0.0268904921, -0.0126974229, -0.0734603107, -0.0135742407, -0.034926638, 0.0459280722, 0.0418779887, -0.0413558148, 0.021826813, -0.0363962054, 0.0496744327, -0.0344252735, 0.0497264415, -0.0152844423, -0.0674610659, -0.0987097099, -0.0527925156, 0.0316803753, -0.089550063, 0.0154678645, 0.017333705, -0.0360344462, 0.0493597388, 0.0265982114, -0.0519319475, -0.0337503701, 0.00441258447, 0.0200672746, -0.00415402278, -0.0122447126, -0.0317830816, -0.0436532088, 0.00223930879, -0.0298080072, -0.045647312, 0.00860313792, 0.041187223, 0.00913626514, -0.0181087498, -0.0124064898, 0.0436432511, 0.021604551, 0.00420758734, -0.00475653773, 0.00124478817, 9.36472092e-32, -0.0437908359, 0.0107480325, -0.0594223626, -0.00313284877, -0.014139493, -0.0200673137, -0.00988597143, -0.00200346764, -0.0287625622, 0.0386763439, 0.030828679, 0.0127823092, 0.0354033075, -0.0709906071, -0.00793242361, 0.0361390263, 0.0189688653, 0.0925001949, -0.0520271659, -0.0851631984, 0.0070293285, -0.0150114717, -0.0225839838, 0.0446380675, -0.0140275676, 0.056773074, -0.088982597, -0.0360949785, 0.030700583, 0.0939799473, -0.0893647894, 0.0287467819, -0.004572846, -0.0470306017, -0.0274040755, 0.000720319629, 0.0918206945, 0.0431668386, -0.0651820824, 0.000440399628, -0.0451262109, 0.0856586173, -0.0744710863, -0.0577205941, -0.0145431766, -0.0322530381, -0.0663036183, 0.0398493595, -0.0504956394, -0.00229618093, 0.0250373706, -0.0222002994, 0.0506313853, 0.0498431958, 0.0430674367, 0.0476892516, -0.0235399865, -0.0603665635, 0.0988124758, 0.0278188828, -0.0461105779, 7.28295126e-05, 0.0141029228, -0.0962653533], 'company': 'PHOENIX OPCO PTE. LTD.', 'job_type_encoding': '[0, 1, 0, 0, 0]', 'is_remote': False, 'lat_long': (1.2744927000000001, 103.84404662674353)})\n",
      "\n",
      "Sample edge: ('job_0', 'job_2955')\n"
     ]
    }
   ],
   "source": [
    "print(f\"Nodes: {len(graph.nodes)}\")\n",
    "print(f\"Edges: {len(graph.edges)}\")\n",
    "print(\"\\nSample node data:\", next(iter(graph.nodes(data=True))))\n",
    "print(\"\\nSample edge:\", next(iter(graph.edges())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading graph from pickle file...\n",
      "Nodes: 25142\n",
      "Edges: 79444658\n",
      "\n",
      "Sample node data: ('job_0', {'job_title_embedding': [-0.0323692635, 0.037560612, -0.0851607397, -0.0453846455, -0.0546593554, -0.0279194303, 0.0278429296, 0.0215941686, 0.0325031728, 0.000887234812, 0.036646761, -0.0450273678, -0.0109668206, -0.0368140303, -0.0451355092, 0.0584830716, 0.114421636, 0.0379366949, -0.0109098526, -0.0450774394, -0.0636187941, -0.0283169001, -0.0749196559, 0.0460793413, -0.00873038266, 0.0490450747, -0.0230729543, 0.083348833, 0.0108598638, -0.0804005265, -0.0902405754, 0.0268752687, 0.0291939843, 0.0203662012, -0.0047371788, -0.0222695544, -0.0255234633, 0.0452349409, 0.028607415, -0.00115934608, -0.0206206571, -0.00999114104, -0.0118169105, -0.0274297539, -0.081966795, 0.0121426117, -0.0515504405, -0.0148908487, 0.0312867016, 0.0425315909, 0.0544571318, 0.00782229751, 0.011188155, 0.0547044016, -0.0220145993, 0.0660661459, -0.000419043761, 0.0151083982, -0.0381165333, -0.0169295501, -0.0283929724, 0.0029114394, -0.0551629476, -0.000226649194, -0.0343298875, -0.00412429823, -0.0298547298, -0.0337917432, -0.00667487271, -0.0516205207, -0.0235408433, -0.0655120388, -0.0543309487, -0.00318038044, 0.118260279, 0.0123469625, 0.0310083572, -0.00657702377, -0.0433183387, -0.031532757, -0.0532171801, -0.0790918916, -0.0897181183, -0.0554492138, -0.0425002277, -0.000756329333, -0.0165863, -0.106061913, 0.0259988382, 0.0207840949, 0.00133714674, -0.00926006585, 0.00314535759, -0.0602836423, -0.018318139, 0.0256741643, 0.00914465636, -0.0555429906, -0.0884505436, 0.39128226, -0.00247407961, -0.00223034644, -0.0644639209, 0.00810331851, 0.0130994283, -0.0324723758, -0.0285277367, 0.0155969588, 0.0452222973, 0.0154045047, 0.0034656194, -0.0148824835, 0.0111183515, -0.00905900355, 0.0309257172, -0.0648853332, 0.00192772993, -0.0646893084, -0.0407922976, 0.0253239293, -0.022198759, 0.0132965529, -0.0609473698, 0.0668524578, -0.0485373959, -0.0828857571, 0.0591504909, 0.0367421769, 0.0702980533, -0.031284254, 0.0292981789, -0.0124304015, -0.0186609458, 0.0325256102, -0.00764538813, 0.0358827077, 0.0413202457, 0.0221810602, 0.00830523204, -0.0865380988, -0.0776792392, 0.0178593751, 0.0483536199, 0.0277861524, -0.144324973, -0.00760203507, -0.0401397571, -0.0447938107, -0.0334054939, -0.0244215354, -0.00575259374, -0.0520751402, 0.000775870751, -0.0123337768, 0.01293384, -0.080203414, 0.0211065952, -0.0449649915, 0.0214948338, 0.0135897845, -0.0142045617, -0.0263703838, -0.0934049189, 0.0557276681, 0.0303679276, 0.00374490186, 0.0913090929, 0.00638637133, -0.0277776998, 0.0345626883, 0.0453553386, -0.0230159592, -0.00479518948, -0.111290269, -0.00895944051, 0.00104231539, 0.0237247851, -0.0651265085, 0.0776792318, 0.0445088558, 0.0391672403, 0.0254097451, 0.01759452, -0.0165704452, 0.0225449074, -0.00494741416, -0.00493709696, 0.00611147424, -0.00426019914, 0.0209297892, -0.0770777613, 0.0908500254, 0.0892148167, 0.00770267053, 0.0151695954, 0.0580228493, -0.0591513738, -0.114342354, -0.0478661917, -0.04457343, -0.0437174551, 0.0802927762, -0.0829034522, 0.0353400931, 0.0543061979, -0.0156353936, 0.00663642865, 0.0361496247, 0.0429536663, 0.0683567822, 0.00458838232, 0.0552805252, -0.02193534, -0.0199466478, 0.0235863067, -0.00450922083, 0.0406951569, 0.140976965, -0.0815058723, -0.00963929854, 0.00867818482, 0.0831316859, 0.0352667086, 1.43831623e-32, 0.0288145263, -0.0634856895, 0.0123033132, -0.0052141021, -0.0359964408, -0.0333254412, -0.0127209127, -0.0234470386, -0.0208499115, 0.0212439578, 0.0727671981, 0.0653406158, -0.0257615652, 0.0140882498, 0.0433069579, 0.0341918468, 0.037436489, -0.0260379836, 0.0336297713, 0.0465884171, 0.073693268, 0.107746378, -0.0389717631, 0.0922504738, -0.0379243158, 0.024798058, 0.0851481929, 0.00906614494, -0.00610294566, -0.0480599292, 0.00496918568, 0.0391633324, 0.0467728637, 0.0384538323, 0.00237442995, -0.00906903204, 0.0311495718, 0.0208101738, -0.0126826223, 0.0279557668, 0.00216998253, 0.0365901999, -0.0197251514, 0.13924481, 0.0127784228, -0.0235874821, 0.0118140243, -0.0658190325, -0.0401728563, 0.0803137273, -0.0127761886, 0.0938898176, -0.0634313896, 0.0539411977, -0.00924549811, -0.1209848, 0.0740353316, -0.0249420553, 0.0851942077, 0.0758455768, -0.0220798608, -0.00362527091, 0.0545755476, -0.0227589048, 0.107168436, 0.0712979361, -0.0360227637, -0.0520168282, -0.0382262431, -0.00720303366, -0.111469358, -0.00258243666, 0.104044072, -0.0653100759, -0.0136057567, 0.0007249685, 0.103582293, 0.0351125263, 0.00933734607, -0.00114919676, -0.0330896378, -0.0469578356, -0.00655823341, -0.00230119191, 0.0529548526, -0.0253250729, -0.0131702144, 0.0220445693, -0.0419955254, -0.0464358702, 0.0301925503, -0.0476837568, -0.00450549182, -0.0238191169, 0.100967191, -1.76783213e-32, -0.00518036308, 0.0328982249, -5.42606685e-05, 0.0169234872, 0.0699944422, 0.0534766354, 0.0379161797, -0.0146630788, -0.00334069971, 0.0303177554, 0.0830600858, 0.0131890038, -0.00475431141, -0.00619639782, -0.0246302467, -0.0220883377, -0.0293468554, 0.0417624228, 0.0127821313, 0.0243057236, -0.0116377054, 0.0614821166, 0.0854958892, -0.0465557948, 0.0039823195, -0.0219085813, -0.110072725, -0.00188876735, 0.0245277695, -0.0392255001, -0.017779028, 0.041083131, 0.0290686078, -0.0824375972, -0.00121110445, -0.00798466243, 0.0542106181, -0.0256740227, -0.0270067137, 0.0229956564, -0.0311662741, 0.0619803108, -0.00923316181, -0.0264205784, -0.00206903275, 0.0384881385, 0.102722503, -0.00187071436, -0.0234825388, -0.0434261151, -0.0119220717, 0.0157711282, 0.0530413501, 0.0101837898, -0.0161338169, 0.0596855059, -0.072131969, -0.0772478729, -0.0446728319, -0.0175949782, 0.0365964286, -0.0143841049, -0.0724985972, 0.0135575728], 'job_description_embedding': [0.0364928544, 0.0229546651, 0.0382401571, 0.0592471026, 0.0319772027, -0.00618717307, 0.0327850059, -0.0614954121, -0.128817067, -0.0445765331, -0.0505791977, -0.0556147993, 0.0296713077, 0.0855619982, 0.0190957617, -0.00826452579, 0.0582200028, 0.00413926458, 0.0140653206, -0.0558966063, -0.0661553293, 0.00995611306, -0.0186332017, -0.0374281406, 0.0405047312, -0.0635395125, 0.0365796238, 0.0372376405, -0.0164702814, -0.0322364718, -0.0113707585, 0.0236477423, 0.0358835571, 0.0301380996, 0.0437186398, 0.193368807, -0.00682446174, -0.0214293078, 0.048211161, -0.0158358272, 0.0583657362, 0.0159103926, 0.00495204004, -0.00803317595, 0.0207290146, -0.0472191907, 0.0750665143, 0.00316392351, -0.0435716435, 0.0174822304, -0.0449199528, -0.0256875511, 0.0668603182, -0.048777543, -0.0270033702, -0.0913284421, 0.0107634095, -0.0988661051, -0.0599086918, -0.0783258155, 0.0115558468, -0.0225886758, 0.00560818333, 0.00754998066, 0.00344080036, 0.0564387478, -0.129369304, -0.0106958859, -0.0175501164, -0.0895912647, -0.0804907829, -0.0259433687, -0.0610160045, 0.0623396598, 0.010200141, 0.00881079305, -0.0342469923, -0.00486409012, 0.0139151365, -0.0297677852, -0.0129658794, -0.00242109178, 0.00754315872, 0.0168106537, 0.0141748982, 0.017053023, -0.0482148454, -0.019525649, 0.022809118, 0.0242336318, 0.0722049996, -0.0729160979, -0.0336161293, -0.0833360702, 0.00680711074, -0.0338155106, -0.0682516173, 0.000690144778, 0.0600614883, -0.012483147, 0.061897058, 0.0841215476, 0.138690293, 0.0156089934, -0.110535376, 0.0612647794, 0.0351449847, -0.0625724569, 0.0329796895, -0.00568579789, -0.0780197084, 0.0424728096, -0.0370895267, -0.0401840135, 0.0100729773, 0.0197940674, -0.0678629279, 0.130778477, -0.0414995924, -0.0322848707, 0.0549642704, 0.0531237945, 0.0316418484, 0.0210385136, 0.00654016435, -0.0696910396, 0.062894538, -0.00607657526, -0.148391232, 0.0898125768, -0.0253445487, 0.112730823, 0.0601800755, 0.0523854159, -0.112736613, -0.0709913, 0.0545689203, 0.0115667796, -0.0538522042, -0.00538914092, -0.00576464226, -0.0202087164, -0.00656955969, 0.0122802723, 0.0234057419, -0.0396360569, -0.0388765223, -0.00153655792, 0.0449452214, -0.0457917303, -0.0452247635, -0.00750974845, 0.0623245835, 0.0327010415, 0.0629530698, 0.0413270853, 0.0643879771, -0.020035224, -0.034536317, 0.0344446115, 0.0605411828, -0.023460282, -0.0264252853, 0.00962501857, -0.00961338729, -0.0237670988, -0.0165019892, -0.0117089758, -0.164644971, -0.0734917074, -0.017416602, 0.0602889694, -0.0286653712, -0.0382752791, 0.0687135756, -0.0259679705, 0.0502222702, 0.090642564, 0.0228762086, -0.0675605386, 0.0193421654, -0.0223511476, 0.0356821939, 0.00676594255, 0.0584258549, 0.0396697931, -0.0343459435, -0.100821331, 0.171071529, -0.0493320562, 0.0282839909, -0.0245172661, 0.016149573, -0.0361048914, 0.0334983952, 0.0111077055, 0.064003177, -0.0825286955, 0.0104260882, 0.0366790071, -0.00729327789, 0.0961335003, -0.0672337264, 0.0513937734, 0.0404797941, -0.00336193107, 0.0861158147, 0.0175328851, 0.030346958, 0.0886671394, 0.0634275153, -0.00132156885, 0.0413285829, -0.0376426391, 0.0617200881, 0.0670840964, 0.0631245226, 0.030078005, -0.00532123027, -0.0369142741, 0.0193397775, 0.0602114536, -0.0214995574, -1.16061127e-32, -0.0495273359, 0.0171222612, 0.0554801151, -0.0184570979, -0.0362529978, -0.0296389125, -0.0154816462, -0.0868446305, 0.0406958722, -0.0130058583, -0.0944467112, 0.028383974, -0.0159223005, -0.00211985176, 0.0555225536, -0.121888518, 0.0557366237, 0.00716061797, -0.115423664, -0.017654296, 0.0934635326, 0.0714069828, -0.0223153159, -0.0187193491, -0.0929075032, 0.0296504013, -0.0168310069, -0.0398974977, -0.0384935737, -0.0493126959, -0.0276999325, -0.0257869698, -0.0327163972, -0.0275224578, 0.0580830835, 0.0100572007, 0.0056452225, 0.0266729835, -0.0577755868, -0.016761018, 0.0160814207, -0.00281225098, -0.0322770774, -0.0284356996, 0.063191928, -0.0733917058, 0.042376969, -0.100894667, -0.015460656, -0.084804602, -0.0268904921, -0.0126974229, -0.0734603107, -0.0135742407, -0.034926638, 0.0459280722, 0.0418779887, -0.0413558148, 0.021826813, -0.0363962054, 0.0496744327, -0.0344252735, 0.0497264415, -0.0152844423, -0.0674610659, -0.0987097099, -0.0527925156, 0.0316803753, -0.089550063, 0.0154678645, 0.017333705, -0.0360344462, 0.0493597388, 0.0265982114, -0.0519319475, -0.0337503701, 0.00441258447, 0.0200672746, -0.00415402278, -0.0122447126, -0.0317830816, -0.0436532088, 0.00223930879, -0.0298080072, -0.045647312, 0.00860313792, 0.041187223, 0.00913626514, -0.0181087498, -0.0124064898, 0.0436432511, 0.021604551, 0.00420758734, -0.00475653773, 0.00124478817, 9.36472092e-32, -0.0437908359, 0.0107480325, -0.0594223626, -0.00313284877, -0.014139493, -0.0200673137, -0.00988597143, -0.00200346764, -0.0287625622, 0.0386763439, 0.030828679, 0.0127823092, 0.0354033075, -0.0709906071, -0.00793242361, 0.0361390263, 0.0189688653, 0.0925001949, -0.0520271659, -0.0851631984, 0.0070293285, -0.0150114717, -0.0225839838, 0.0446380675, -0.0140275676, 0.056773074, -0.088982597, -0.0360949785, 0.030700583, 0.0939799473, -0.0893647894, 0.0287467819, -0.004572846, -0.0470306017, -0.0274040755, 0.000720319629, 0.0918206945, 0.0431668386, -0.0651820824, 0.000440399628, -0.0451262109, 0.0856586173, -0.0744710863, -0.0577205941, -0.0145431766, -0.0322530381, -0.0663036183, 0.0398493595, -0.0504956394, -0.00229618093, 0.0250373706, -0.0222002994, 0.0506313853, 0.0498431958, 0.0430674367, 0.0476892516, -0.0235399865, -0.0603665635, 0.0988124758, 0.0278188828, -0.0461105779, 7.28295126e-05, 0.0141029228, -0.0962653533], 'company': 'PHOENIX OPCO PTE. LTD.', 'job_type_encoding': '[0, 1, 0, 0, 0]', 'is_remote': False, 'lat_long': (1.2744927000000001, 103.84404662674353)})\n",
      "\n",
      "Sample edge: ('job_0', 'job_2955')\n"
     ]
    }
   ],
   "source": [
    "del graph\n",
    "\n",
    "print(\"Loading graph from pickle file...\")\n",
    "with open('final_complete_graph.pkl', 'rb') as f:\n",
    "    new_graph = pickle.load(f)\n",
    "\n",
    "print(f\"Nodes: {len(new_graph.nodes)}\")\n",
    "print(f\"Edges: {len(new_graph.edges)}\")\n",
    "print(\"\\nSample node data:\", next(iter(new_graph.nodes(data=True))))\n",
    "print(\"\\nSample edge:\", next(iter(new_graph.edges())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
