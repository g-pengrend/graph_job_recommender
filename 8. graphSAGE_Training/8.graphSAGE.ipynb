{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# At this point, remember to use pygraph environment\n",
    "\n",
    "Long story..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the final complete graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import from_networkx\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading final complete graph...\n",
      "Graph loaded successfully!\n",
      "Nodes: 25610, Edges: 25728679\n"
     ]
    }
   ],
   "source": [
    "def load_graph_checkpoint(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "# Load the final complete graph\n",
    "print(\"Loading final complete graph...\")\n",
    "graph = load_graph_checkpoint('../7. GraphBuilding/final_complete_graph.pkl')\n",
    "print(\"Graph loaded successfully!\")\n",
    "print(f\"Nodes: {graph.number_of_nodes()}, Edges: {graph.number_of_edges()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the graphSAGE model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GraphSAGE model\n",
    "class EfficientGraphSAGE(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        hidden_channels=256,\n",
    "        out_channels=128,\n",
    "        num_layers=2,\n",
    "        dropout=0.2\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # Input layer\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_channels, aggr='mean'))\n",
    "        \n",
    "        # Hidden layers\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(SAGEConv(hidden_channels, hidden_channels, aggr='mean'))\n",
    "        \n",
    "        # Output layer\n",
    "        self.convs.append(SAGEConv(hidden_channels, out_channels, aggr='mean'))\n",
    "        \n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        self.batch_norm = torch.nn.ModuleList([\n",
    "            torch.nn.BatchNorm1d(hidden_channels) for _ in range(num_layers-1)\n",
    "        ])\n",
    "        self.batch_norm.append(torch.nn.BatchNorm1d(out_channels))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for i, conv in enumerate(self.convs[:-1]):\n",
    "            x = conv(x, edge_index)\n",
    "            x = self.batch_norm[i](x)\n",
    "            x = F.relu(x)\n",
    "            x = self.dropout(x)\n",
    "        x = self.convs[-1](x, edge_index)\n",
    "        x = self.batch_norm[-1](x)\n",
    "        return x\n",
    "    \n",
    "def prepare_graph_data(graph, device):\n",
    "    \"\"\"Convert NetworkX graph to PyG data\"\"\"\n",
    "    print(\"Converting NetworkX graph to PyG format...\")\n",
    "    \n",
    "    # Extract node features and edge index\n",
    "    node_features = []\n",
    "    \n",
    "    # Get a sample node to check structure\n",
    "    first_node = list(graph.nodes())[0]\n",
    "    print(\"\\nSample node data:\")\n",
    "    print(f\"Title embedding type: {type(graph.nodes[first_node]['job_title_embedding'])}\")\n",
    "    print(f\"Title embedding length: {len(graph.nodes[first_node]['job_title_embedding'])}\")\n",
    "    \n",
    "    try:\n",
    "        for node in tqdm(graph.nodes(), desc=\"Extracting node features\"):\n",
    "            features = []\n",
    "            \n",
    "            # Combine all embeddings\n",
    "            features.extend(graph.nodes[node]['job_title_embedding'])\n",
    "            features.extend(graph.nodes[node]['job_description_embedding'])\n",
    "            features.extend(graph.nodes[node]['job_type_encoding'])\n",
    "            node_features.append(features)\n",
    "            \n",
    "            # Print first node information\n",
    "            if len(node_features) == 1:\n",
    "                print(f\"\\nFeature dimensions for first node:\")\n",
    "                print(f\"Title embedding: {len(graph.nodes[node]['job_title_embedding'])}\")\n",
    "                print(f\"Description embedding: {len(graph.nodes[node]['job_description_embedding'])}\")\n",
    "                print(f\"Job type encoding: {len(graph.nodes[node]['job_type_encoding'])}\")\n",
    "                print(f\"Total features: {len(features)}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError processing node features: {str(e)}\")\n",
    "        print(\"\\nDetailed error information:\")\n",
    "        print(f\"Node: {node}\")\n",
    "        print(f\"Title embedding sample: {graph.nodes[node]['job_title_embedding'][:100]}\")\n",
    "        raise\n",
    "\n",
    "    # Convert to tensors\n",
    "    try:\n",
    "        x = torch.tensor(np.array(node_features), dtype=torch.float)\n",
    "        print(f\"\\nNode features tensor shape: {x.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError converting to tensor: {str(e)}\")\n",
    "        print(f\"Node features list shape: {len(node_features)} x {len(node_features[0]) if node_features else 0}\")\n",
    "        raise\n",
    "    \n",
    "    # Create edge index and weights\n",
    "    print(\"\\nProcessing edges...\")\n",
    "    edge_index = []\n",
    "    edge_weights = []\n",
    "    \n",
    "    try:\n",
    "        for u, v, data in tqdm(graph.edges(data=True), desc=\"Processing edges\"):\n",
    "            u_idx = int(u.split('_')[1])\n",
    "            v_idx = int(v.split('_')[1])\n",
    "            edge_index.append([u_idx, v_idx])\n",
    "            edge_weights.append(float(data.get('weight', 1.0)))\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError processing edges: {str(e)}\")\n",
    "        print(f\"Sample edge: {u} -> {v}\")\n",
    "        print(f\"Edge data: {data}\")\n",
    "        raise\n",
    "\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    edge_weights = torch.tensor(edge_weights, dtype=torch.float)\n",
    "    \n",
    "    # Create PyG data object\n",
    "    data = Data(\n",
    "        x=x,\n",
    "        edge_index=edge_index,\n",
    "        edge_weight=edge_weights,\n",
    "        num_nodes=len(graph)\n",
    "    )\n",
    "    \n",
    "    print(\"\\nData preparation completed successfully!\")\n",
    "    print(f\"Features shape: {data.x.shape}\")\n",
    "    print(f\"Edge index shape: {data.edge_index.shape}\")\n",
    "    print(f\"Edge weights shape: {data.edge_weight.shape}\")\n",
    "    \n",
    "    return data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Initial GPU memory: 0.62 GB\n",
      "Attempting to load cached graph data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Brandon\\AppData\\Local\\Temp\\ipykernel_13096\\2586903041.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(cached_data_path)\n",
      "C:\\Users\\Brandon\\AppData\\Local\\Temp\\ipykernel_13096\\2586903041.py:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('best_graphsage_model.pt')\n",
      "c:\\Users\\Brandon\\anaconda3\\envs\\pygraph\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Brandon\\AppData\\Local\\Temp\\ipykernel_13096\\2586903041.py:82: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded cached graph data!\n",
      "Initializing model...\n",
      "No checkpoint found, starting fresh training\n",
      "GPU memory after data loading: 0.63 GB\n",
      "Starting training from epoch 1 to 150...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/150:   0%|          | 0/51 [00:00<?, ?it/s]C:\\Users\\Brandon\\AppData\\Local\\Temp\\ipykernel_13096\\2586903041.py:97: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Epoch 1/150: 100%|██████████| 51/51 [00:04<00:00, 12.27it/s, loss=0.17] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Average Loss: 0.3316\n",
      "Saved new best model with loss: 0.3316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/150: 100%|██████████| 51/51 [00:03<00:00, 13.52it/s, loss=0.143] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Average Loss: 0.1126\n",
      "Saved new best model with loss: 0.1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/150: 100%|██████████| 51/51 [00:03<00:00, 13.48it/s, loss=0.134] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Average Loss: 0.1026\n",
      "Saved new best model with loss: 0.1026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/150: 100%|██████████| 51/51 [00:03<00:00, 13.45it/s, loss=0.118] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Average Loss: 0.0948\n",
      "Saved new best model with loss: 0.0948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/150: 100%|██████████| 51/51 [00:03<00:00, 13.47it/s, loss=0.11]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Average Loss: 0.0880\n",
      "Saved new best model with loss: 0.0880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/150: 100%|██████████| 51/51 [00:03<00:00, 13.40it/s, loss=0.12]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Average Loss: 0.0806\n",
      "Saved new best model with loss: 0.0806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/150: 100%|██████████| 51/51 [00:03<00:00, 13.50it/s, loss=0.0935]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Average Loss: 0.0743\n",
      "Saved new best model with loss: 0.0743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/150: 100%|██████████| 51/51 [00:03<00:00, 13.31it/s, loss=0.0985]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Average Loss: 0.0676\n",
      "Saved new best model with loss: 0.0676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/150: 100%|██████████| 51/51 [00:03<00:00, 13.35it/s, loss=0.0936]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Average Loss: 0.0620\n",
      "Saved new best model with loss: 0.0620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/150: 100%|██████████| 51/51 [00:03<00:00, 13.34it/s, loss=0.0685]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Average Loss: 0.0561\n",
      "Saved new best model with loss: 0.0561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/150: 100%|██████████| 51/51 [00:03<00:00, 13.38it/s, loss=0.0641]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Average Loss: 0.0515\n",
      "Saved new best model with loss: 0.0515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/150: 100%|██████████| 51/51 [00:03<00:00, 13.52it/s, loss=0.0576]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Average Loss: 0.0460\n",
      "Saved new best model with loss: 0.0460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/150: 100%|██████████| 51/51 [00:03<00:00, 13.45it/s, loss=0.0518]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Average Loss: 0.0416\n",
      "Saved new best model with loss: 0.0416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/150: 100%|██████████| 51/51 [00:03<00:00, 13.46it/s, loss=0.04]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Average Loss: 0.0369\n",
      "Saved new best model with loss: 0.0369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/150: 100%|██████████| 51/51 [00:03<00:00, 13.56it/s, loss=0.038] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Average Loss: 0.0326\n",
      "Saved new best model with loss: 0.0326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/150: 100%|██████████| 51/51 [00:03<00:00, 13.52it/s, loss=0.0313]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Average Loss: 0.0285\n",
      "Saved new best model with loss: 0.0285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/150: 100%|██████████| 51/51 [00:03<00:00, 13.55it/s, loss=0.0276]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Average Loss: 0.0246\n",
      "Saved new best model with loss: 0.0246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/150: 100%|██████████| 51/51 [00:03<00:00, 13.57it/s, loss=0.0253]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Average Loss: 0.0210\n",
      "Saved new best model with loss: 0.0210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/150: 100%|██████████| 51/51 [00:03<00:00, 13.49it/s, loss=0.0183]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Average Loss: 0.0173\n",
      "Saved new best model with loss: 0.0173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/150: 100%|██████████| 51/51 [00:03<00:00, 13.62it/s, loss=0.014] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Average Loss: 0.0140\n",
      "Saved new best model with loss: 0.0140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/150: 100%|██████████| 51/51 [00:03<00:00, 13.60it/s, loss=0.00941]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Average Loss: 0.0108\n",
      "Saved new best model with loss: 0.0108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/150: 100%|██████████| 51/51 [00:03<00:00, 13.58it/s, loss=0.00756]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, Average Loss: 0.0084\n",
      "Saved new best model with loss: 0.0084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/150: 100%|██████████| 51/51 [00:03<00:00, 13.64it/s, loss=0.00619]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, Average Loss: 0.0069\n",
      "Saved new best model with loss: 0.0069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/150: 100%|██████████| 51/51 [00:03<00:00, 13.62it/s, loss=0.00481]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, Average Loss: 0.0055\n",
      "Saved new best model with loss: 0.0055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/150: 100%|██████████| 51/51 [00:03<00:00, 13.49it/s, loss=0.00349]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, Average Loss: 0.0041\n",
      "Saved new best model with loss: 0.0041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/150: 100%|██████████| 51/51 [00:03<00:00, 13.53it/s, loss=0.00221]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, Average Loss: 0.0028\n",
      "Saved new best model with loss: 0.0028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/150: 100%|██████████| 51/51 [00:03<00:00, 13.59it/s, loss=0.00101]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, Average Loss: 0.0015\n",
      "Saved new best model with loss: 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/150: 100%|██████████| 51/51 [00:03<00:00, 13.59it/s, loss=0.000558]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, Average Loss: 0.0007\n",
      "Saved new best model with loss: 0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/150: 100%|██████████| 51/51 [00:03<00:00, 13.60it/s, loss=0.00054] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, Average Loss: 0.0005\n",
      "Saved new best model with loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/150: 100%|██████████| 51/51 [00:03<00:00, 13.50it/s, loss=0.00055] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/150: 100%|██████████| 51/51 [00:03<00:00, 13.57it/s, loss=0.00052] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31, Average Loss: 0.0005\n",
      "Saved new best model with loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/150: 100%|██████████| 51/51 [00:03<00:00, 13.56it/s, loss=0.000538]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/150: 100%|██████████| 51/51 [00:03<00:00, 13.66it/s, loss=0.000535]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33, Average Loss: 0.0005\n",
      "Saved new best model with loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/150: 100%|██████████| 51/51 [00:03<00:00, 13.67it/s, loss=0.000532]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34, Average Loss: 0.0005\n",
      "Saved new best model with loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/150: 100%|██████████| 51/51 [00:03<00:00, 13.60it/s, loss=0.000514]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35, Average Loss: 0.0005\n",
      "Saved new best model with loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/150: 100%|██████████| 51/51 [00:03<00:00, 13.64it/s, loss=0.000509]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36, Average Loss: 0.0005\n",
      "Saved new best model with loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/150: 100%|██████████| 51/51 [00:03<00:00, 13.63it/s, loss=0.000541]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37, Average Loss: 0.0005\n",
      "Saved new best model with loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/150: 100%|██████████| 51/51 [00:03<00:00, 13.54it/s, loss=0.000504]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/150: 100%|██████████| 51/51 [00:03<00:00, 13.63it/s, loss=0.000466]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/150: 100%|██████████| 51/51 [00:03<00:00, 13.54it/s, loss=0.000545]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/150: 100%|██████████| 51/51 [00:03<00:00, 13.24it/s, loss=0.000501]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/150: 100%|██████████| 51/51 [00:03<00:00, 13.32it/s, loss=0.000536]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/150: 100%|██████████| 51/51 [00:03<00:00, 13.30it/s, loss=0.000552]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/150: 100%|██████████| 51/51 [00:03<00:00, 13.25it/s, loss=0.000454]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44, Average Loss: 0.0005\n",
      "Saved new best model with loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/150: 100%|██████████| 51/51 [00:03<00:00, 13.36it/s, loss=0.000491]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45, Average Loss: 0.0005\n",
      "Saved new best model with loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/150: 100%|██████████| 51/51 [00:03<00:00, 13.22it/s, loss=0.000452]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46, Average Loss: 0.0005\n",
      "Saved new best model with loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/150: 100%|██████████| 51/51 [00:03<00:00, 13.22it/s, loss=0.000445]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/150: 100%|██████████| 51/51 [00:03<00:00, 13.02it/s, loss=0.000478]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/150: 100%|██████████| 51/51 [00:03<00:00, 13.28it/s, loss=0.000473]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49, Average Loss: 0.0005\n",
      "Saved new best model with loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/150: 100%|██████████| 51/51 [00:03<00:00, 13.29it/s, loss=0.000436]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/150: 100%|██████████| 51/51 [00:03<00:00, 13.36it/s, loss=0.000483]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51, Average Loss: 0.0005\n",
      "Saved new best model with loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/150: 100%|██████████| 51/51 [00:03<00:00, 13.14it/s, loss=0.000471]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/150: 100%|██████████| 51/51 [00:03<00:00, 13.23it/s, loss=0.000452]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/150: 100%|██████████| 51/51 [00:03<00:00, 13.15it/s, loss=0.000477]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/150: 100%|██████████| 51/51 [00:03<00:00, 13.28it/s, loss=0.000478]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/150: 100%|██████████| 51/51 [00:03<00:00, 13.36it/s, loss=0.000445]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/150: 100%|██████████| 51/51 [00:03<00:00, 13.40it/s, loss=0.000458]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/150: 100%|██████████| 51/51 [00:03<00:00, 13.32it/s, loss=0.000427]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58, Average Loss: 0.0005\n",
      "Saved new best model with loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/150: 100%|██████████| 51/51 [00:03<00:00, 13.31it/s, loss=0.00049] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/150: 100%|██████████| 51/51 [00:03<00:00, 13.37it/s, loss=0.000465]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/150: 100%|██████████| 51/51 [00:03<00:00, 13.38it/s, loss=0.000461]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62/150: 100%|██████████| 51/51 [00:03<00:00, 13.39it/s, loss=0.000472]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63/150: 100%|██████████| 51/51 [00:03<00:00, 13.53it/s, loss=0.000487]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64/150: 100%|██████████| 51/51 [00:03<00:00, 13.52it/s, loss=0.000479]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64, Average Loss: 0.0005\n",
      "Saved new best model with loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65/150: 100%|██████████| 51/51 [00:03<00:00, 13.35it/s, loss=0.000459]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66/150: 100%|██████████| 51/51 [00:03<00:00, 13.46it/s, loss=0.000442]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67/150: 100%|██████████| 51/51 [00:03<00:00, 13.47it/s, loss=0.000475]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68/150: 100%|██████████| 51/51 [00:03<00:00, 13.44it/s, loss=0.000429]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69/150: 100%|██████████| 51/51 [00:03<00:00, 13.50it/s, loss=0.000446]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/150: 100%|██████████| 51/51 [00:03<00:00, 13.48it/s, loss=0.000466]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71/150: 100%|██████████| 51/51 [00:03<00:00, 13.41it/s, loss=0.000421]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71, Average Loss: 0.0004\n",
      "Saved new best model with loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72/150: 100%|██████████| 51/51 [00:03<00:00, 13.55it/s, loss=0.000474]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73/150: 100%|██████████| 51/51 [00:03<00:00, 13.51it/s, loss=0.000441]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74/150: 100%|██████████| 51/51 [00:03<00:00, 13.49it/s, loss=0.000457]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75/150: 100%|██████████| 51/51 [00:03<00:00, 13.52it/s, loss=0.000473]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75, Average Loss: 0.0004\n",
      "Saved new best model with loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76/150: 100%|██████████| 51/51 [00:03<00:00, 13.54it/s, loss=0.000464]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76, Average Loss: 0.0004\n",
      "Saved new best model with loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77/150: 100%|██████████| 51/51 [00:03<00:00, 13.48it/s, loss=0.000425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78/150: 100%|██████████| 51/51 [00:03<00:00, 13.55it/s, loss=0.000434]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78, Average Loss: 0.0004\n",
      "Saved new best model with loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79/150: 100%|██████████| 51/51 [00:03<00:00, 13.32it/s, loss=0.000448]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80/150: 100%|██████████| 51/51 [00:03<00:00, 13.59it/s, loss=0.000435]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81/150: 100%|██████████| 51/51 [00:03<00:00, 13.22it/s, loss=0.000443]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82/150: 100%|██████████| 51/51 [00:03<00:00, 13.60it/s, loss=0.000456]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83/150: 100%|██████████| 51/51 [00:03<00:00, 13.65it/s, loss=0.000458]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84/150: 100%|██████████| 51/51 [00:03<00:00, 13.60it/s, loss=0.00044] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85/150: 100%|██████████| 51/51 [00:03<00:00, 13.73it/s, loss=0.00045] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85, Average Loss: 0.0004\n",
      "Saved new best model with loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86/150: 100%|██████████| 51/51 [00:03<00:00, 13.65it/s, loss=0.000456]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87/150: 100%|██████████| 51/51 [00:03<00:00, 13.61it/s, loss=0.000424]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88/150: 100%|██████████| 51/51 [00:03<00:00, 13.65it/s, loss=0.000441]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88, Average Loss: 0.0004\n",
      "Saved new best model with loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89/150: 100%|██████████| 51/51 [00:03<00:00, 13.59it/s, loss=0.000402]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89, Average Loss: 0.0004\n",
      "Saved new best model with loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90/150: 100%|██████████| 51/51 [00:03<00:00, 13.77it/s, loss=0.000456]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91/150: 100%|██████████| 51/51 [00:03<00:00, 13.60it/s, loss=0.000459]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91, Average Loss: 0.0004\n",
      "Saved new best model with loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92/150: 100%|██████████| 51/51 [00:03<00:00, 13.66it/s, loss=0.000406]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 93/150: 100%|██████████| 51/51 [00:03<00:00, 13.69it/s, loss=0.000438]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93, Average Loss: 0.0004\n",
      "Saved new best model with loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94/150: 100%|██████████| 51/51 [00:03<00:00, 13.65it/s, loss=0.000429]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 95/150: 100%|██████████| 51/51 [00:03<00:00, 13.59it/s, loss=0.000429]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 96/150: 100%|██████████| 51/51 [00:03<00:00, 13.64it/s, loss=0.000434]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97/150: 100%|██████████| 51/51 [00:03<00:00, 13.71it/s, loss=0.000382]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 98/150: 100%|██████████| 51/51 [00:03<00:00, 13.51it/s, loss=0.000436]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99/150: 100%|██████████| 51/51 [00:03<00:00, 13.68it/s, loss=0.000423]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100/150: 100%|██████████| 51/51 [00:03<00:00, 13.62it/s, loss=0.000468]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 101/150: 100%|██████████| 51/51 [00:03<00:00, 13.67it/s, loss=0.000441]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 102/150: 100%|██████████| 51/51 [00:03<00:00, 13.53it/s, loss=0.000459]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 103/150: 100%|██████████| 51/51 [00:03<00:00, 13.67it/s, loss=0.000432]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103, Average Loss: 0.0004\n",
      "Saved new best model with loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 104/150: 100%|██████████| 51/51 [00:03<00:00, 13.55it/s, loss=0.000458]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 105/150: 100%|██████████| 51/51 [00:03<00:00, 13.57it/s, loss=0.000452]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 106/150: 100%|██████████| 51/51 [00:03<00:00, 13.66it/s, loss=0.000451]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 107/150: 100%|██████████| 51/51 [00:03<00:00, 13.49it/s, loss=0.000416]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 108/150: 100%|██████████| 51/51 [00:03<00:00, 13.60it/s, loss=0.000423]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 109/150: 100%|██████████| 51/51 [00:03<00:00, 13.64it/s, loss=0.000464]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109, Average Loss: 0.0004\n",
      "Saved new best model with loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 110/150: 100%|██████████| 51/51 [00:03<00:00, 13.61it/s, loss=0.00041] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 111/150: 100%|██████████| 51/51 [00:03<00:00, 13.45it/s, loss=0.000479]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 112/150: 100%|██████████| 51/51 [00:03<00:00, 13.65it/s, loss=0.000428]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 113/150: 100%|██████████| 51/51 [00:03<00:00, 13.74it/s, loss=0.000437]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 114/150: 100%|██████████| 51/51 [00:03<00:00, 13.69it/s, loss=0.000451]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 115/150: 100%|██████████| 51/51 [00:03<00:00, 13.67it/s, loss=0.000428]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 116/150: 100%|██████████| 51/51 [00:03<00:00, 13.67it/s, loss=0.000461]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 117/150: 100%|██████████| 51/51 [00:03<00:00, 13.69it/s, loss=0.000429]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 118/150: 100%|██████████| 51/51 [00:03<00:00, 13.66it/s, loss=0.000444]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119/150: 100%|██████████| 51/51 [00:03<00:00, 13.72it/s, loss=0.000426]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119, Average Loss: 0.0004\n",
      "Early stopping triggered!\n",
      "Training completed!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set up GPU device and print memory info\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Initial GPU memory: {torch.cuda.memory_allocated()/1e9:.2f} GB\")\n",
    "\n",
    "# Try to load cached data first\n",
    "cached_data_path = 'gpu_processed_graph.pt'\n",
    "try:\n",
    "    print(\"Attempting to load cached graph data...\")\n",
    "    data = torch.load(cached_data_path)\n",
    "    data = data.to(device)\n",
    "    print(\"Successfully loaded cached graph data!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"No cached data found. Processing graph from scratch...\")\n",
    "    # Prepare the data\n",
    "    data = prepare_graph_data(graph, device)\n",
    "    # Cache the processed data\n",
    "    print(\"Caching processed graph data...\")\n",
    "    torch.save(data, cached_data_path)\n",
    "    print(\"Graph data cached successfully!\")\n",
    "\n",
    "in_channels = data.x.size(1)\n",
    "\n",
    "# Initialize model\n",
    "print(\"Initializing model...\")\n",
    "model = EfficientGraphSAGE(\n",
    "    in_channels=in_channels,\n",
    "    hidden_channels=512,  # Increased to help with dimensionality reduction\n",
    "    out_channels=384,    # Changed to desired embedding size\n",
    "    num_layers=3,        # Added an extra layer to help with dimensionality reduction\n",
    "    dropout=0.2\n",
    ").to(device)\n",
    "\n",
    "# Set up optimizer with different learning rates for different components\n",
    "optimizer = torch.optim.AdamW([\n",
    "    {'params': model.convs.parameters(), 'lr': 0.001},\n",
    "    {'params': model.batch_norm.parameters(), 'lr': 0.001}\n",
    "])\n",
    "\n",
    "# Try to load checkpoint if it exists\n",
    "start_epoch = 0\n",
    "training_losses = []  # Store losses for plotting\n",
    "try:\n",
    "    checkpoint = torch.load('best_graphsage_model.pt')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    best_loss = checkpoint['loss']\n",
    "    if 'training_losses' in checkpoint:\n",
    "        training_losses = checkpoint['training_losses']\n",
    "    print(f\"Loaded checkpoint from epoch {start_epoch-1} with loss {best_loss:.4f}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"No checkpoint found, starting fresh training\")\n",
    "    best_loss = float('inf')\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=5, verbose=True\n",
    ")\n",
    "\n",
    "# Process data in smaller chunks if needed\n",
    "batch_size = 512  # Smaller batch size for memory efficiency\n",
    "train_loader = NeighborLoader(\n",
    "    data,\n",
    "    num_neighbors=[10, 5],  # Reduced number of neighbors\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "# Print memory usage after data loading\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU memory after data loading: {torch.cuda.memory_allocated()/1e9:.2f} GB\")\n",
    "\n",
    "num_epochs = 150\n",
    "patience = 10\n",
    "patience_counter = 0\n",
    "\n",
    "# Enable automatic mixed precision for faster training\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "print(f\"Starting training from epoch {start_epoch+1} to {num_epochs}...\")\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    # Process batches with progress bar\n",
    "    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}')\n",
    "    for batch in pbar:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Use automatic mixed precision\n",
    "        with torch.cuda.amp.autocast():\n",
    "            # Forward pass\n",
    "            out = model(batch.x, batch.edge_index)[:batch.batch_size]  # Only take batch_size nodes\n",
    "            \n",
    "            # Project target to same dimension as output\n",
    "            target = batch.x[:batch.batch_size]\n",
    "            target_projected = torch.nn.Linear(target.shape[1], 384).to(device)(target)\n",
    "            \n",
    "            loss = F.mse_loss(out, target_projected)\n",
    "            \n",
    "            # Add L2 regularization\n",
    "            l2_reg = 0\n",
    "            for param in model.parameters():\n",
    "                l2_reg += torch.norm(param)\n",
    "            loss += 0.001 * l2_reg\n",
    "        \n",
    "        # Backward pass with gradient scaling\n",
    "        scaler.scale(loss).backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "        \n",
    "        # Update progress bar\n",
    "        pbar.set_postfix({'loss': loss.item()})\n",
    "    \n",
    "    # Compute average loss\n",
    "    avg_loss = total_loss / num_batches\n",
    "    training_losses.append(avg_loss)\n",
    "    print(f'Epoch {epoch+1}, Average Loss: {avg_loss:.4f}')\n",
    "    \n",
    "    # Learning rate scheduling\n",
    "    scheduler.step(avg_loss)\n",
    "    \n",
    "    # Early stopping check\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        patience_counter = 0\n",
    "        # Save best model\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': best_loss,\n",
    "            'training_losses': training_losses\n",
    "        }, 'best_graphsage_model.pt')\n",
    "        print(f\"Saved new best model with loss: {best_loss:.4f}\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        \n",
    "    if patience_counter >= patience:\n",
    "        print(\"Early stopping triggered!\")\n",
    "        break\n",
    "\n",
    "print(\"Training completed!\")\n",
    "\n",
    "# Plot training loss\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(len(training_losses)), training_losses)\n",
    "plt.title('Training Loss Over Time')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the embeddings from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import from_networkx\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GraphSAGE model\n",
    "class EfficientGraphSAGE(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        hidden_channels=256,\n",
    "        out_channels=128,\n",
    "        num_layers=2,\n",
    "        dropout=0.2\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # Input layer\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_channels, aggr='mean'))\n",
    "        \n",
    "        # Hidden layers\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(SAGEConv(hidden_channels, hidden_channels, aggr='mean'))\n",
    "        \n",
    "        # Output layer\n",
    "        self.convs.append(SAGEConv(hidden_channels, out_channels, aggr='mean'))\n",
    "        \n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        self.batch_norm = torch.nn.ModuleList([\n",
    "            torch.nn.BatchNorm1d(hidden_channels) for _ in range(num_layers-1)\n",
    "        ])\n",
    "        self.batch_norm.append(torch.nn.BatchNorm1d(out_channels))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for i, conv in enumerate(self.convs[:-1]):\n",
    "            x = conv(x, edge_index)\n",
    "            x = self.batch_norm[i](x)\n",
    "            x = F.relu(x)\n",
    "            x = self.dropout(x)\n",
    "        x = self.convs[-1](x, edge_index)\n",
    "        x = self.batch_norm[-1](x)\n",
    "        return x\n",
    "    \n",
    "def prepare_graph_data(graph, device):\n",
    "    \"\"\"Convert NetworkX graph to PyG data\"\"\"\n",
    "    print(\"Converting NetworkX graph to PyG format...\")\n",
    "    \n",
    "    # Extract node features and edge index\n",
    "    node_features = []\n",
    "    \n",
    "    # Get a sample node to check structure\n",
    "    first_node = list(graph.nodes())[0]\n",
    "    print(\"\\nSample node data:\")\n",
    "    print(f\"Title embedding type: {type(graph.nodes[first_node]['job_title_embedding'])}\")\n",
    "    print(f\"Title embedding length: {len(graph.nodes[first_node]['job_title_embedding'])}\")\n",
    "    \n",
    "    try:\n",
    "        for node in tqdm(graph.nodes(), desc=\"Extracting node features\"):\n",
    "            features = []\n",
    "            \n",
    "            # Get numpy arrays directly\n",
    "            title_emb = graph.nodes[node]['job_title_embedding']\n",
    "            desc_emb = graph.nodes[node]['job_description_embedding']\n",
    "            type_emb = graph.nodes[node]['job_type_encoding']\n",
    "            \n",
    "            # Combine all embeddings\n",
    "            features.extend(title_emb)\n",
    "            features.extend(desc_emb)\n",
    "            features.extend(type_emb)\n",
    "            node_features.append(features)\n",
    "            \n",
    "            # Print first node information\n",
    "            if len(node_features) == 1:\n",
    "                print(f\"\\nFeature dimensions for first node:\")\n",
    "                print(f\"Title embedding: {len(title_emb)}\")\n",
    "                print(f\"Description embedding: {len(desc_emb)}\")\n",
    "                print(f\"Job type encoding: {len(type_emb)}\")\n",
    "                print(f\"Total features: {len(features)}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError processing node features: {str(e)}\")\n",
    "        print(\"\\nDetailed error information:\")\n",
    "        print(f\"Node: {node}\")\n",
    "        print(f\"Title embedding sample: {graph.nodes[node]['job_title_embedding'][:100]}\")\n",
    "        raise\n",
    "\n",
    "    # Convert to tensors\n",
    "    try:\n",
    "        x = torch.tensor(np.array(node_features), dtype=torch.float)\n",
    "        print(f\"\\nNode features tensor shape: {x.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError converting to tensor: {str(e)}\")\n",
    "        print(f\"Node features list shape: {len(node_features)} x {len(node_features[0]) if node_features else 0}\")\n",
    "        raise\n",
    "    \n",
    "    # Create edge index and weights\n",
    "    print(\"\\nProcessing edges...\")\n",
    "    edge_index = []\n",
    "    edge_weights = []\n",
    "    \n",
    "    try:\n",
    "        for u, v, data in tqdm(graph.edges(data=True), desc=\"Processing edges\"):\n",
    "            u_idx = int(u.split('_')[1])\n",
    "            v_idx = int(v.split('_')[1])\n",
    "            edge_index.append([u_idx, v_idx])\n",
    "            edge_weights.append(float(data.get('weight', 1.0)))\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError processing edges: {str(e)}\")\n",
    "        print(f\"Sample edge: {u} -> {v}\")\n",
    "        print(f\"Edge data: {data}\")\n",
    "        raise\n",
    "\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    edge_weights = torch.tensor(edge_weights, dtype=torch.float)\n",
    "    \n",
    "    # Create PyG data object\n",
    "    data = Data(\n",
    "        x=x,\n",
    "        edge_index=edge_index,\n",
    "        edge_weight=edge_weights,\n",
    "        num_nodes=len(graph)\n",
    "    )\n",
    "    \n",
    "    print(\"\\nData preparation completed successfully!\")\n",
    "    print(f\"Features shape: {data.x.shape}\")\n",
    "    print(f\"Edge index shape: {data.edge_index.shape}\")\n",
    "    print(f\"Edge weights shape: {data.edge_weight.shape}\")\n",
    "    \n",
    "    return data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Initial GPU memory: 0.67 GB\n",
      "Attempting to load cached graph data...\n",
      "Successfully loaded cached graph data!\n",
      "Initializing model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Brandon\\AppData\\Local\\Temp\\ipykernel_13096\\2110895155.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(cached_data_path)\n"
     ]
    }
   ],
   "source": [
    "# Set up GPU device and print memory info\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Initial GPU memory: {torch.cuda.memory_allocated()/1e9:.2f} GB\")\n",
    "\n",
    "# Try to load cached data first\n",
    "cached_data_path = 'gpu_processed_graph.pt'\n",
    "try:\n",
    "    print(\"Attempting to load cached graph data...\")\n",
    "    data = torch.load(cached_data_path)\n",
    "    data = data.to(device)\n",
    "    print(\"Successfully loaded cached graph data!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"No cached data found. Processing graph from scratch...\")\n",
    "    # Prepare the data\n",
    "    data = prepare_graph_data(graph, device)\n",
    "    # Cache the processed data\n",
    "    print(\"Caching processed graph data...\")\n",
    "    torch.save(data, cached_data_path)\n",
    "    print(\"Graph data cached successfully!\")\n",
    "\n",
    "in_channels = data.x.size(1)\n",
    "\n",
    "# Initialize model\n",
    "print(\"Initializing model...\")\n",
    "model = EfficientGraphSAGE(\n",
    "    in_channels=in_channels,\n",
    "    hidden_channels=512,  # Increased to help with dimensionality reduction\n",
    "    out_channels=384,    # Changed to desired embedding size\n",
    "    num_layers=3,        # Added an extra layer to help with dimensionality reduction\n",
    "    dropout=0.2\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading best model...\n",
      "Generating embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 401/401 [03:18<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings shape: torch.Size([25610, 384])\n",
      "Embeddings saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Set CUDA launch blocking for better error tracking\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "# Load the best model and generate embeddings\n",
    "print(\"Loading best model...\")\n",
    "checkpoint = torch.load('best_graphsage_model.pt', weights_only=True)  # Set weights_only=True\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "def generate_embeddings(model, data, batch_size=64):  # Reduced batch size to 64\n",
    "    \"\"\"Generate embeddings for all nodes\"\"\"\n",
    "    print(\"Generating embeddings...\")\n",
    "    embeddings = []\n",
    "    model.eval()\n",
    "    \n",
    "    # Get list of all edges and keep on CPU\n",
    "    edge_index = data.edge_index.cpu()\n",
    "    data.x = data.x.cpu()  # Move features to CPU\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, data.num_nodes, batch_size)):\n",
    "            batch_end = min(i + batch_size, data.num_nodes)\n",
    "            batch_nodes = list(range(i, batch_end))\n",
    "            \n",
    "            # Process edge mask on CPU\n",
    "            mask = (edge_index[0].unsqueeze(1) == torch.tensor(batch_nodes)).any(dim=1) | \\\n",
    "                   (edge_index[1].unsqueeze(1) == torch.tensor(batch_nodes)).any(dim=1)\n",
    "            \n",
    "            # Only move necessary data to GPU\n",
    "            batch_edge_index = edge_index[:, mask].to(device)\n",
    "            batch_x = data.x.to(device)  # Move all node features to GPU\n",
    "            \n",
    "            try:\n",
    "                # Verify indices are in valid range\n",
    "                max_index = batch_edge_index.max().item()\n",
    "                if max_index >= batch_x.size(0):\n",
    "                    print(f\"Invalid index found: {max_index} >= {batch_x.size(0)}\")\n",
    "                    continue\n",
    "                    \n",
    "                # Generate embeddings for batch\n",
    "                batch_emb = model(batch_x, batch_edge_index)\n",
    "                embeddings.append(batch_emb[i:batch_end].cpu())  # Only keep embeddings for batch nodes\n",
    "            except RuntimeError as e:\n",
    "                print(f\"Error with batch {i}-{batch_end}: {str(e)}\")\n",
    "                del batch_edge_index, batch_x\n",
    "                torch.cuda.empty_cache()\n",
    "                continue\n",
    "                \n",
    "            # Clear GPU memory\n",
    "            del batch_edge_index, batch_x\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    # Concatenate all embeddings on CPU\n",
    "    all_embeddings = torch.cat(embeddings, dim=0)\n",
    "    print(f\"Generated embeddings shape: {all_embeddings.shape}\")\n",
    "    return all_embeddings\n",
    "\n",
    "# Generate and save embeddings\n",
    "node_embeddings = generate_embeddings(model, data)\n",
    "torch.save(node_embeddings, 'node_embeddings.pt')\n",
    "print(\"Embeddings saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
