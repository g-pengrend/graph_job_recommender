{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the final complete graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import from_networkx\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading final complete graph...\n",
      "Graph loaded successfully!\n",
      "Nodes: 25142, Edges: 79444658\n"
     ]
    }
   ],
   "source": [
    "def load_graph_checkpoint(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "# Load the final complete graph\n",
    "print(\"Loading final complete graph...\")\n",
    "graph = load_graph_checkpoint('final_complete_graph.pkl')\n",
    "print(\"Graph loaded successfully!\")\n",
    "print(f\"Nodes: {graph.number_of_nodes()}, Edges: {graph.number_of_edges()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# At this point, remember to use pygraph environment\n",
    "\n",
    "Long story..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the graphSAGE model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GraphSAGE model\n",
    "class EfficientGraphSAGE(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        hidden_channels=256,\n",
    "        out_channels=128,\n",
    "        num_layers=2,\n",
    "        dropout=0.2\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # Input layer\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_channels, aggr='mean'))\n",
    "        \n",
    "        # Hidden layers\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(SAGEConv(hidden_channels, hidden_channels, aggr='mean'))\n",
    "        \n",
    "        # Output layer\n",
    "        self.convs.append(SAGEConv(hidden_channels, out_channels, aggr='mean'))\n",
    "        \n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        self.batch_norm = torch.nn.ModuleList([\n",
    "            torch.nn.BatchNorm1d(hidden_channels) for _ in range(num_layers-1)\n",
    "        ])\n",
    "        self.batch_norm.append(torch.nn.BatchNorm1d(out_channels))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for i, conv in enumerate(self.convs[:-1]):\n",
    "            x = conv(x, edge_index)\n",
    "            x = self.batch_norm[i](x)\n",
    "            x = F.relu(x)\n",
    "            x = self.dropout(x)\n",
    "        x = self.convs[-1](x, edge_index)\n",
    "        x = self.batch_norm[-1](x)\n",
    "        return x\n",
    "    \n",
    "def prepare_graph_data(graph, device):\n",
    "    \"\"\"Convert NetworkX graph to PyG data with numpy string handling\"\"\"\n",
    "    print(\"Converting NetworkX graph to PyG format...\")\n",
    "    \n",
    "    # Extract node features and edge index\n",
    "    node_features = []\n",
    "    \n",
    "    # Get a sample node to check structure\n",
    "    first_node = list(graph.nodes())[0]\n",
    "    print(\"\\nSample node data:\")\n",
    "    print(f\"Title embedding type: {type(graph.nodes[first_node]['job_title_embedding'])}\")\n",
    "    print(f\"Title embedding length: {len(graph.nodes[first_node]['job_title_embedding'])}\")\n",
    "    \n",
    "    try:\n",
    "        for node in tqdm(graph.nodes(), desc=\"Extracting node features\"):\n",
    "            features = []\n",
    "            \n",
    "            # Convert string representations to numpy arrays\n",
    "            # Using string split and conversion for memory efficiency\n",
    "            title_str = graph.nodes[node]['job_title_embedding']\n",
    "            title_emb = np.fromstring(title_str.strip('[]'), sep=' ')\n",
    "            \n",
    "            desc_str = graph.nodes[node]['job_description_embedding']\n",
    "            desc_emb = np.fromstring(desc_str.strip('[]'), sep=' ')\n",
    "            \n",
    "            type_str = graph.nodes[node]['job_type_encoding']\n",
    "            type_emb = np.fromstring(type_str.strip('[]'), sep=' ')\n",
    "            \n",
    "            # Combine all embeddings\n",
    "            features.extend(title_emb)\n",
    "            features.extend(desc_emb)\n",
    "            features.extend(type_emb)\n",
    "            node_features.append(features)\n",
    "            \n",
    "            # Print first node information\n",
    "            if len(node_features) == 1:\n",
    "                print(f\"\\nFeature dimensions for first node:\")\n",
    "                print(f\"Title embedding: {len(title_emb)}\")\n",
    "                print(f\"Description embedding: {len(desc_emb)}\")\n",
    "                print(f\"Job type encoding: {len(type_emb)}\")\n",
    "                print(f\"Total features: {len(features)}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError processing node features: {str(e)}\")\n",
    "        print(\"\\nDetailed error information:\")\n",
    "        print(f\"Node: {node}\")\n",
    "        print(f\"Title embedding sample: {graph.nodes[node]['job_title_embedding'][:100]}\")\n",
    "        raise\n",
    "\n",
    "    # Convert to tensors\n",
    "    try:\n",
    "        x = torch.tensor(np.array(node_features), dtype=torch.float)\n",
    "        print(f\"\\nNode features tensor shape: {x.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError converting to tensor: {str(e)}\")\n",
    "        print(f\"Node features list shape: {len(node_features)} x {len(node_features[0]) if node_features else 0}\")\n",
    "        raise\n",
    "    \n",
    "    # Create edge index and weights\n",
    "    print(\"\\nProcessing edges...\")\n",
    "    edge_index = []\n",
    "    edge_weights = []\n",
    "    \n",
    "    try:\n",
    "        for u, v, data in tqdm(graph.edges(data=True), desc=\"Processing edges\"):\n",
    "            u_idx = int(u.split('_')[1])\n",
    "            v_idx = int(v.split('_')[1])\n",
    "            edge_index.append([u_idx, v_idx])\n",
    "            edge_weights.append(float(data.get('weight', 1.0)))\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError processing edges: {str(e)}\")\n",
    "        print(f\"Sample edge: {u} -> {v}\")\n",
    "        print(f\"Edge data: {data}\")\n",
    "        raise\n",
    "\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    edge_weights = torch.tensor(edge_weights, dtype=torch.float)\n",
    "    \n",
    "    # Create PyG data object\n",
    "    data = Data(\n",
    "        x=x,\n",
    "        edge_index=edge_index,\n",
    "        edge_weight=edge_weights,\n",
    "        num_nodes=len(graph)\n",
    "    )\n",
    "    \n",
    "    print(\"\\nData preparation completed successfully!\")\n",
    "    print(f\"Features shape: {data.x.shape}\")\n",
    "    print(f\"Edge index shape: {data.edge_index.shape}\")\n",
    "    print(f\"Edge weights shape: {data.edge_weight.shape}\")\n",
    "    \n",
    "    return data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Initial GPU memory: 1.86 GB\n",
      "Attempting to load cached graph data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Brandon\\AppData\\Local\\Temp\\ipykernel_21448\\912666011.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(cached_data_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded cached graph data!\n",
      "Initializing model...\n",
      "No checkpoint found, starting fresh training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Brandon\\AppData\\Local\\Temp\\ipykernel_21448\\912666011.py:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('best_graphsage_model.pt')\n",
      "C:\\Users\\Brandon\\AppData\\Local\\Temp\\ipykernel_21448\\912666011.py:82: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after data loading: 3.53 GB\n",
      "Starting training from epoch 1 to 100...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100:   0%|          | 0/50 [00:00<?, ?it/s]C:\\Users\\Brandon\\AppData\\Local\\Temp\\ipykernel_21448\\912666011.py:97: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Epoch 1/100: 100%|██████████| 50/50 [00:11<00:00,  4.42it/s, loss=0.149]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Average Loss: 0.3051\n",
      "Saved new best model with loss: 0.3051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100: 100%|██████████| 50/50 [00:09<00:00,  5.23it/s, loss=0.155] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Average Loss: 0.1117\n",
      "Saved new best model with loss: 0.1117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100: 100%|██████████| 50/50 [00:09<00:00,  5.25it/s, loss=0.123] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Average Loss: 0.1026\n",
      "Saved new best model with loss: 0.1026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100: 100%|██████████| 50/50 [00:09<00:00,  5.28it/s, loss=0.113] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Average Loss: 0.0935\n",
      "Saved new best model with loss: 0.0935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100: 100%|██████████| 50/50 [00:09<00:00,  5.31it/s, loss=0.0989]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Average Loss: 0.0864\n",
      "Saved new best model with loss: 0.0864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100: 100%|██████████| 50/50 [00:09<00:00,  5.34it/s, loss=0.0946]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Average Loss: 0.0795\n",
      "Saved new best model with loss: 0.0795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100: 100%|██████████| 50/50 [00:09<00:00,  5.33it/s, loss=0.116] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Average Loss: 0.0731\n",
      "Saved new best model with loss: 0.0731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100: 100%|██████████| 50/50 [00:09<00:00,  5.34it/s, loss=0.124] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Average Loss: 0.0676\n",
      "Saved new best model with loss: 0.0676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100: 100%|██████████| 50/50 [00:09<00:00,  5.28it/s, loss=0.0684]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Average Loss: 0.0615\n",
      "Saved new best model with loss: 0.0615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100: 100%|██████████| 50/50 [00:09<00:00,  5.45it/s, loss=0.0602]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Average Loss: 0.0556\n",
      "Saved new best model with loss: 0.0556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100: 100%|██████████| 50/50 [00:09<00:00,  5.26it/s, loss=0.0571]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Average Loss: 0.0501\n",
      "Saved new best model with loss: 0.0501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100: 100%|██████████| 50/50 [00:09<00:00,  5.40it/s, loss=0.0501]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Average Loss: 0.0454\n",
      "Saved new best model with loss: 0.0454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100: 100%|██████████| 50/50 [00:09<00:00,  5.31it/s, loss=0.0444]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Average Loss: 0.0408\n",
      "Saved new best model with loss: 0.0408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/100: 100%|██████████| 50/50 [00:09<00:00,  5.32it/s, loss=0.0374]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Average Loss: 0.0364\n",
      "Saved new best model with loss: 0.0364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/100: 100%|██████████| 50/50 [00:09<00:00,  5.34it/s, loss=0.0343]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Average Loss: 0.0323\n",
      "Saved new best model with loss: 0.0323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/100: 100%|██████████| 50/50 [00:09<00:00,  5.34it/s, loss=0.0306]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Average Loss: 0.0282\n",
      "Saved new best model with loss: 0.0282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/100: 100%|██████████| 50/50 [00:09<00:00,  5.30it/s, loss=0.0257]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Average Loss: 0.0243\n",
      "Saved new best model with loss: 0.0243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/100: 100%|██████████| 50/50 [00:09<00:00,  5.38it/s, loss=0.0209]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Average Loss: 0.0207\n",
      "Saved new best model with loss: 0.0207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/100: 100%|██████████| 50/50 [00:09<00:00,  5.34it/s, loss=0.0169]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Average Loss: 0.0171\n",
      "Saved new best model with loss: 0.0171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/100: 100%|██████████| 50/50 [00:09<00:00,  5.32it/s, loss=0.0138]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Average Loss: 0.0138\n",
      "Saved new best model with loss: 0.0138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100: 100%|██████████| 50/50 [00:09<00:00,  5.31it/s, loss=0.00924]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Average Loss: 0.0109\n",
      "Saved new best model with loss: 0.0109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/100: 100%|██████████| 50/50 [00:09<00:00,  5.27it/s, loss=0.00704]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, Average Loss: 0.0080\n",
      "Saved new best model with loss: 0.0080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/100: 100%|██████████| 50/50 [00:09<00:00,  5.54it/s, loss=0.00559]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, Average Loss: 0.0063\n",
      "Saved new best model with loss: 0.0063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/100: 100%|██████████| 50/50 [00:09<00:00,  5.52it/s, loss=0.00422]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, Average Loss: 0.0049\n",
      "Saved new best model with loss: 0.0049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/100: 100%|██████████| 50/50 [00:09<00:00,  5.29it/s, loss=0.00295]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, Average Loss: 0.0035\n",
      "Saved new best model with loss: 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/100: 100%|██████████| 50/50 [00:09<00:00,  5.33it/s, loss=0.00168]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, Average Loss: 0.0023\n",
      "Saved new best model with loss: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/100: 100%|██████████| 50/50 [00:09<00:00,  5.30it/s, loss=0.000713]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, Average Loss: 0.0011\n",
      "Saved new best model with loss: 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/100: 100%|██████████| 50/50 [00:09<00:00,  5.38it/s, loss=0.000562]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, Average Loss: 0.0006\n",
      "Saved new best model with loss: 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/100: 100%|██████████| 50/50 [00:09<00:00,  5.36it/s, loss=0.000544]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, Average Loss: 0.0006\n",
      "Saved new best model with loss: 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/100: 100%|██████████| 50/50 [00:09<00:00,  5.29it/s, loss=0.000559]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Average Loss: 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/100: 100%|██████████| 50/50 [00:09<00:00,  5.32it/s, loss=0.000553]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31, Average Loss: 0.0006\n",
      "Saved new best model with loss: 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/100: 100%|██████████| 50/50 [00:09<00:00,  5.45it/s, loss=0.000524]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, Average Loss: 0.0005\n",
      "Saved new best model with loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/100: 100%|██████████| 50/50 [00:09<00:00,  5.32it/s, loss=0.000514]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/100: 100%|██████████| 50/50 [00:09<00:00,  5.33it/s, loss=0.000554]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/100: 100%|██████████| 50/50 [00:09<00:00,  5.38it/s, loss=0.000518]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35, Average Loss: 0.0005\n",
      "Saved new best model with loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/100: 100%|██████████| 50/50 [00:09<00:00,  5.39it/s, loss=0.000543]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/100: 100%|██████████| 50/50 [00:09<00:00,  5.44it/s, loss=0.000526]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/100: 100%|██████████| 50/50 [00:09<00:00,  5.47it/s, loss=0.000504]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/100: 100%|██████████| 50/50 [00:09<00:00,  5.32it/s, loss=0.000561]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/100: 100%|██████████| 50/50 [00:09<00:00,  5.43it/s, loss=0.000585]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/100: 100%|██████████| 50/50 [00:09<00:00,  5.32it/s, loss=0.000559]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/100: 100%|██████████| 50/50 [00:09<00:00,  5.26it/s, loss=0.000472]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42, Average Loss: 0.0005\n",
      "Saved new best model with loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/100: 100%|██████████| 50/50 [00:09<00:00,  5.33it/s, loss=0.000472]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43, Average Loss: 0.0005\n",
      "Saved new best model with loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/100: 100%|██████████| 50/50 [00:09<00:00,  5.42it/s, loss=0.000505]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/100: 100%|██████████| 50/50 [00:09<00:00,  5.24it/s, loss=0.000468]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45, Average Loss: 0.0005\n",
      "Saved new best model with loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/100: 100%|██████████| 50/50 [00:09<00:00,  5.32it/s, loss=0.000476]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46, Average Loss: 0.0005\n",
      "Saved new best model with loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/100: 100%|██████████| 50/50 [00:09<00:00,  5.26it/s, loss=0.000493]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/100: 100%|██████████| 50/50 [00:09<00:00,  5.31it/s, loss=0.000491]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48, Average Loss: 0.0005\n",
      "Saved new best model with loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/100: 100%|██████████| 50/50 [00:09<00:00,  5.36it/s, loss=0.000466]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/100: 100%|██████████| 50/50 [00:09<00:00,  5.25it/s, loss=0.000474]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Average Loss: 0.0005\n",
      "Saved new best model with loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/100: 100%|██████████| 50/50 [00:09<00:00,  5.25it/s, loss=0.000488]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/100: 100%|██████████| 50/50 [00:09<00:00,  5.33it/s, loss=0.000513]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52, Average Loss: 0.0005\n",
      "Saved new best model with loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/100: 100%|██████████| 50/50 [00:09<00:00,  5.25it/s, loss=0.000472]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/100: 100%|██████████| 50/50 [00:09<00:00,  5.29it/s, loss=0.000497]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/100: 100%|██████████| 50/50 [00:09<00:00,  5.35it/s, loss=0.000483]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/100: 100%|██████████| 50/50 [00:09<00:00,  5.23it/s, loss=0.000513]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/100: 100%|██████████| 50/50 [00:09<00:00,  5.37it/s, loss=0.000452]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/100: 100%|██████████| 50/50 [00:09<00:00,  5.35it/s, loss=0.000463]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/100: 100%|██████████| 50/50 [00:09<00:00,  5.33it/s, loss=0.000447]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59, Average Loss: 0.0005\n",
      "Saved new best model with loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/100: 100%|██████████| 50/50 [00:09<00:00,  5.47it/s, loss=0.000475]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60, Average Loss: 0.0005\n",
      "Saved new best model with loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/100: 100%|██████████| 50/50 [00:09<00:00,  5.53it/s, loss=0.00047] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61, Average Loss: 0.0005\n",
      "Saved new best model with loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62/100: 100%|██████████| 50/50 [00:09<00:00,  5.33it/s, loss=0.000479]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62, Average Loss: 0.0005\n",
      "Saved new best model with loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63/100: 100%|██████████| 50/50 [00:09<00:00,  5.40it/s, loss=0.000474]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64/100: 100%|██████████| 50/50 [00:09<00:00,  5.27it/s, loss=0.000474]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65/100: 100%|██████████| 50/50 [00:09<00:00,  5.43it/s, loss=0.000442]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66/100: 100%|██████████| 50/50 [00:09<00:00,  5.46it/s, loss=0.000459]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67/100: 100%|██████████| 50/50 [00:09<00:00,  5.40it/s, loss=0.000455]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68/100: 100%|██████████| 50/50 [00:09<00:00,  5.37it/s, loss=0.000457]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69/100: 100%|██████████| 50/50 [00:09<00:00,  5.38it/s, loss=0.000481]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69, Average Loss: 0.0005\n",
      "Saved new best model with loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/100: 100%|██████████| 50/50 [00:09<00:00,  5.53it/s, loss=0.000484]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70, Average Loss: 0.0005\n",
      "Saved new best model with loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71/100: 100%|██████████| 50/50 [00:09<00:00,  5.40it/s, loss=0.00044] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71, Average Loss: 0.0004\n",
      "Saved new best model with loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72/100: 100%|██████████| 50/50 [00:09<00:00,  5.35it/s, loss=0.000465]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73/100: 100%|██████████| 50/50 [00:09<00:00,  5.27it/s, loss=0.000452]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74/100: 100%|██████████| 50/50 [00:09<00:00,  5.39it/s, loss=0.000448]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75/100: 100%|██████████| 50/50 [00:09<00:00,  5.39it/s, loss=0.000429]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76/100: 100%|██████████| 50/50 [00:09<00:00,  5.30it/s, loss=0.000446]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77/100: 100%|██████████| 50/50 [00:09<00:00,  5.31it/s, loss=0.000489]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78/100: 100%|██████████| 50/50 [00:09<00:00,  5.29it/s, loss=0.000476]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78, Average Loss: 0.0004\n",
      "Saved new best model with loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79/100: 100%|██████████| 50/50 [00:09<00:00,  5.29it/s, loss=0.000438]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80/100: 100%|██████████| 50/50 [00:09<00:00,  5.35it/s, loss=0.000441]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81/100: 100%|██████████| 50/50 [00:09<00:00,  5.35it/s, loss=0.000451]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82/100: 100%|██████████| 50/50 [00:09<00:00,  5.34it/s, loss=0.000385]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83/100: 100%|██████████| 50/50 [00:09<00:00,  5.39it/s, loss=0.000422]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84/100: 100%|██████████| 50/50 [00:09<00:00,  5.34it/s, loss=0.000447]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85/100: 100%|██████████| 50/50 [00:09<00:00,  5.30it/s, loss=0.000466]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85, Average Loss: 0.0004\n",
      "Saved new best model with loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86/100: 100%|██████████| 50/50 [00:09<00:00,  5.32it/s, loss=0.000457]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87/100: 100%|██████████| 50/50 [00:09<00:00,  5.35it/s, loss=0.000416]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88/100: 100%|██████████| 50/50 [00:09<00:00,  5.36it/s, loss=0.000444]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89/100: 100%|██████████| 50/50 [00:09<00:00,  5.28it/s, loss=0.000455]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90/100: 100%|██████████| 50/50 [00:09<00:00,  5.21it/s, loss=0.000433]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91/100: 100%|██████████| 50/50 [00:09<00:00,  5.26it/s, loss=0.000448]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92/100: 100%|██████████| 50/50 [00:09<00:00,  5.19it/s, loss=0.000458]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 93/100: 100%|██████████| 50/50 [00:09<00:00,  5.29it/s, loss=0.000439]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94/100: 100%|██████████| 50/50 [00:09<00:00,  5.39it/s, loss=0.000451]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94, Average Loss: 0.0004\n",
      "Saved new best model with loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 95/100: 100%|██████████| 50/50 [00:09<00:00,  5.27it/s, loss=0.000425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 96/100: 100%|██████████| 50/50 [00:09<00:00,  5.35it/s, loss=0.000448]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96, Average Loss: 0.0004\n",
      "Saved new best model with loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97/100: 100%|██████████| 50/50 [00:09<00:00,  5.51it/s, loss=0.000444]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 98/100: 100%|██████████| 50/50 [00:09<00:00,  5.47it/s, loss=0.000413]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99/100: 100%|██████████| 50/50 [00:08<00:00,  5.61it/s, loss=0.00044] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100/100: 100%|██████████| 50/50 [00:09<00:00,  5.40it/s, loss=0.000474]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Average Loss: 0.0004\n",
      "Training completed!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set up GPU device and print memory info\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Initial GPU memory: {torch.cuda.memory_allocated()/1e9:.2f} GB\")\n",
    "\n",
    "# Try to load cached data first\n",
    "cached_data_path = 'gpu_processed_graph.pt'\n",
    "try:\n",
    "    print(\"Attempting to load cached graph data...\")\n",
    "    data = torch.load(cached_data_path)\n",
    "    data = data.to(device)\n",
    "    print(\"Successfully loaded cached graph data!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"No cached data found. Processing graph from scratch...\")\n",
    "    # Prepare the data\n",
    "    data = prepare_graph_data(graph, device)\n",
    "    # Cache the processed data\n",
    "    print(\"Caching processed graph data...\")\n",
    "    torch.save(data, cached_data_path)\n",
    "    print(\"Graph data cached successfully!\")\n",
    "\n",
    "in_channels = data.x.size(1)\n",
    "\n",
    "# Initialize model\n",
    "print(\"Initializing model...\")\n",
    "model = EfficientGraphSAGE(\n",
    "    in_channels=in_channels,\n",
    "    hidden_channels=512,  # Increased to help with dimensionality reduction\n",
    "    out_channels=384,    # Changed to desired embedding size\n",
    "    num_layers=3,        # Added an extra layer to help with dimensionality reduction\n",
    "    dropout=0.2\n",
    ").to(device)\n",
    "\n",
    "# Set up optimizer with different learning rates for different components\n",
    "optimizer = torch.optim.AdamW([\n",
    "    {'params': model.convs.parameters(), 'lr': 0.001},\n",
    "    {'params': model.batch_norm.parameters(), 'lr': 0.001}\n",
    "])\n",
    "\n",
    "# Try to load checkpoint if it exists\n",
    "start_epoch = 0\n",
    "training_losses = []  # Store losses for plotting\n",
    "try:\n",
    "    checkpoint = torch.load('best_graphsage_model.pt')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    best_loss = checkpoint['loss']\n",
    "    if 'training_losses' in checkpoint:\n",
    "        training_losses = checkpoint['training_losses']\n",
    "    print(f\"Loaded checkpoint from epoch {start_epoch-1} with loss {best_loss:.4f}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"No checkpoint found, starting fresh training\")\n",
    "    best_loss = float('inf')\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=5, verbose=True\n",
    ")\n",
    "\n",
    "# Process data in smaller chunks if needed\n",
    "batch_size = 512  # Smaller batch size for memory efficiency\n",
    "train_loader = NeighborLoader(\n",
    "    data,\n",
    "    num_neighbors=[10, 5],  # Reduced number of neighbors\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "# Print memory usage after data loading\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU memory after data loading: {torch.cuda.memory_allocated()/1e9:.2f} GB\")\n",
    "\n",
    "num_epochs = 100\n",
    "patience = 10\n",
    "patience_counter = 0\n",
    "\n",
    "# Enable automatic mixed precision for faster training\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "print(f\"Starting training from epoch {start_epoch+1} to {num_epochs}...\")\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    # Process batches with progress bar\n",
    "    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}')\n",
    "    for batch in pbar:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Use automatic mixed precision\n",
    "        with torch.cuda.amp.autocast():\n",
    "            # Forward pass\n",
    "            out = model(batch.x, batch.edge_index)[:batch.batch_size]  # Only take batch_size nodes\n",
    "            \n",
    "            # Project target to same dimension as output\n",
    "            target = batch.x[:batch.batch_size]\n",
    "            target_projected = torch.nn.Linear(target.shape[1], 384).to(device)(target)\n",
    "            \n",
    "            loss = F.mse_loss(out, target_projected)\n",
    "            \n",
    "            # Add L2 regularization\n",
    "            l2_reg = 0\n",
    "            for param in model.parameters():\n",
    "                l2_reg += torch.norm(param)\n",
    "            loss += 0.001 * l2_reg\n",
    "        \n",
    "        # Backward pass with gradient scaling\n",
    "        scaler.scale(loss).backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "        \n",
    "        # Update progress bar\n",
    "        pbar.set_postfix({'loss': loss.item()})\n",
    "    \n",
    "    # Compute average loss\n",
    "    avg_loss = total_loss / num_batches\n",
    "    training_losses.append(avg_loss)\n",
    "    print(f'Epoch {epoch+1}, Average Loss: {avg_loss:.4f}')\n",
    "    \n",
    "    # Learning rate scheduling\n",
    "    scheduler.step(avg_loss)\n",
    "    \n",
    "    # Early stopping check\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        patience_counter = 0\n",
    "        # Save best model\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': best_loss,\n",
    "            'training_losses': training_losses\n",
    "        }, 'best_graphsage_model.pt')\n",
    "        print(f\"Saved new best model with loss: {best_loss:.4f}\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        \n",
    "    if patience_counter >= patience:\n",
    "        print(\"Early stopping triggered!\")\n",
    "        break\n",
    "\n",
    "print(\"Training completed!\")\n",
    "\n",
    "# Plot training loss\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(len(training_losses)), training_losses)\n",
    "plt.title('Training Loss Over Time')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the embeddings from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import from_networkx\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GraphSAGE model\n",
    "class EfficientGraphSAGE(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        hidden_channels=256,\n",
    "        out_channels=128,\n",
    "        num_layers=2,\n",
    "        dropout=0.2\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # Input layer\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_channels, aggr='mean'))\n",
    "        \n",
    "        # Hidden layers\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(SAGEConv(hidden_channels, hidden_channels, aggr='mean'))\n",
    "        \n",
    "        # Output layer\n",
    "        self.convs.append(SAGEConv(hidden_channels, out_channels, aggr='mean'))\n",
    "        \n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        self.batch_norm = torch.nn.ModuleList([\n",
    "            torch.nn.BatchNorm1d(hidden_channels) for _ in range(num_layers-1)\n",
    "        ])\n",
    "        self.batch_norm.append(torch.nn.BatchNorm1d(out_channels))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for i, conv in enumerate(self.convs[:-1]):\n",
    "            x = conv(x, edge_index)\n",
    "            x = self.batch_norm[i](x)\n",
    "            x = F.relu(x)\n",
    "            x = self.dropout(x)\n",
    "        x = self.convs[-1](x, edge_index)\n",
    "        x = self.batch_norm[-1](x)\n",
    "        return x\n",
    "    \n",
    "def prepare_graph_data(graph, device):\n",
    "    \"\"\"Convert NetworkX graph to PyG data with numpy string handling\"\"\"\n",
    "    print(\"Converting NetworkX graph to PyG format...\")\n",
    "    \n",
    "    # Extract node features and edge index\n",
    "    node_features = []\n",
    "    \n",
    "    # Get a sample node to check structure\n",
    "    first_node = list(graph.nodes())[0]\n",
    "    print(\"\\nSample node data:\")\n",
    "    print(f\"Title embedding type: {type(graph.nodes[first_node]['job_title_embedding'])}\")\n",
    "    print(f\"Title embedding length: {len(graph.nodes[first_node]['job_title_embedding'])}\")\n",
    "    \n",
    "    try:\n",
    "        for node in tqdm(graph.nodes(), desc=\"Extracting node features\"):\n",
    "            features = []\n",
    "            \n",
    "            # Convert string representations to numpy arrays\n",
    "            # Using string split and conversion for memory efficiency\n",
    "            title_str = graph.nodes[node]['job_title_embedding']\n",
    "            title_emb = np.fromstring(title_str.strip('[]'), sep=' ')\n",
    "            \n",
    "            desc_str = graph.nodes[node]['job_description_embedding']\n",
    "            desc_emb = np.fromstring(desc_str.strip('[]'), sep=' ')\n",
    "            \n",
    "            type_str = graph.nodes[node]['job_type_encoding']\n",
    "            type_emb = np.fromstring(type_str.strip('[]'), sep=' ')\n",
    "            \n",
    "            # Combine all embeddings\n",
    "            features.extend(title_emb)\n",
    "            features.extend(desc_emb)\n",
    "            features.extend(type_emb)\n",
    "            node_features.append(features)\n",
    "            \n",
    "            # Print first node information\n",
    "            if len(node_features) == 1:\n",
    "                print(f\"\\nFeature dimensions for first node:\")\n",
    "                print(f\"Title embedding: {len(title_emb)}\")\n",
    "                print(f\"Description embedding: {len(desc_emb)}\")\n",
    "                print(f\"Job type encoding: {len(type_emb)}\")\n",
    "                print(f\"Total features: {len(features)}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError processing node features: {str(e)}\")\n",
    "        print(\"\\nDetailed error information:\")\n",
    "        print(f\"Node: {node}\")\n",
    "        print(f\"Title embedding sample: {graph.nodes[node]['job_title_embedding'][:100]}\")\n",
    "        raise\n",
    "\n",
    "    # Convert to tensors\n",
    "    try:\n",
    "        x = torch.tensor(np.array(node_features), dtype=torch.float)\n",
    "        print(f\"\\nNode features tensor shape: {x.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError converting to tensor: {str(e)}\")\n",
    "        print(f\"Node features list shape: {len(node_features)} x {len(node_features[0]) if node_features else 0}\")\n",
    "        raise\n",
    "    \n",
    "    # Create edge index and weights\n",
    "    print(\"\\nProcessing edges...\")\n",
    "    edge_index = []\n",
    "    edge_weights = []\n",
    "    \n",
    "    try:\n",
    "        for u, v, data in tqdm(graph.edges(data=True), desc=\"Processing edges\"):\n",
    "            u_idx = int(u.split('_')[1])\n",
    "            v_idx = int(v.split('_')[1])\n",
    "            edge_index.append([u_idx, v_idx])\n",
    "            edge_weights.append(float(data.get('weight', 1.0)))\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError processing edges: {str(e)}\")\n",
    "        print(f\"Sample edge: {u} -> {v}\")\n",
    "        print(f\"Edge data: {data}\")\n",
    "        raise\n",
    "\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    edge_weights = torch.tensor(edge_weights, dtype=torch.float)\n",
    "    \n",
    "    # Create PyG data object\n",
    "    data = Data(\n",
    "        x=x,\n",
    "        edge_index=edge_index,\n",
    "        edge_weight=edge_weights,\n",
    "        num_nodes=len(graph)\n",
    "    )\n",
    "    \n",
    "    print(\"\\nData preparation completed successfully!\")\n",
    "    print(f\"Features shape: {data.x.shape}\")\n",
    "    print(f\"Edge index shape: {data.edge_index.shape}\")\n",
    "    print(f\"Edge weights shape: {data.edge_weight.shape}\")\n",
    "    \n",
    "    return data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Initial GPU memory: 1.72 GB\n",
      "Attempting to load cached graph data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Brandon\\AppData\\Local\\Temp\\ipykernel_21448\\554859613.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(cached_data_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded cached graph data!\n",
      "Initializing model...\n"
     ]
    }
   ],
   "source": [
    "# Set up GPU device and print memory info\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Initial GPU memory: {torch.cuda.memory_allocated()/1e9:.2f} GB\")\n",
    "\n",
    "# Try to load cached data first\n",
    "cached_data_path = 'gpu_processed_graph.pt'\n",
    "try:\n",
    "    print(\"Attempting to load cached graph data...\")\n",
    "    data = torch.load(cached_data_path)\n",
    "    data = data.to(device)\n",
    "    print(\"Successfully loaded cached graph data!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"No cached data found. Processing graph from scratch...\")\n",
    "    # Prepare the data\n",
    "    data = prepare_graph_data(graph, device)\n",
    "    # Cache the processed data\n",
    "    print(\"Caching processed graph data...\")\n",
    "    torch.save(data, cached_data_path)\n",
    "    print(\"Graph data cached successfully!\")\n",
    "\n",
    "in_channels = data.x.size(1)\n",
    "\n",
    "# Initialize model\n",
    "print(\"Initializing model...\")\n",
    "model = EfficientGraphSAGE(\n",
    "    in_channels=in_channels,\n",
    "    hidden_channels=512,  # Increased to help with dimensionality reduction\n",
    "    out_channels=384,    # Changed to desired embedding size\n",
    "    num_layers=3,        # Added an extra layer to help with dimensionality reduction\n",
    "    dropout=0.2\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading best model...\n",
      "Generating embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 393/393 [16:32<00:00,  2.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings shape: torch.Size([25142, 384])\n",
      "Embeddings saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Set CUDA launch blocking for better error tracking\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "# Load the best model and generate embeddings\n",
    "print(\"Loading best model...\")\n",
    "checkpoint = torch.load('best_graphsage_model.pt', weights_only=True)  # Set weights_only=True\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "def generate_embeddings(model, data, batch_size=64):  # Reduced batch size to 64\n",
    "    \"\"\"Generate embeddings for all nodes\"\"\"\n",
    "    print(\"Generating embeddings...\")\n",
    "    embeddings = []\n",
    "    model.eval()\n",
    "    \n",
    "    # Get list of all edges and keep on CPU\n",
    "    edge_index = data.edge_index.cpu()\n",
    "    data.x = data.x.cpu()  # Move features to CPU\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, data.num_nodes, batch_size)):\n",
    "            batch_end = min(i + batch_size, data.num_nodes)\n",
    "            batch_nodes = list(range(i, batch_end))\n",
    "            \n",
    "            # Process edge mask on CPU\n",
    "            mask = (edge_index[0].unsqueeze(1) == torch.tensor(batch_nodes)).any(dim=1) | \\\n",
    "                   (edge_index[1].unsqueeze(1) == torch.tensor(batch_nodes)).any(dim=1)\n",
    "            \n",
    "            # Only move necessary data to GPU\n",
    "            batch_edge_index = edge_index[:, mask].to(device)\n",
    "            batch_x = data.x.to(device)  # Move all node features to GPU\n",
    "            \n",
    "            try:\n",
    "                # Verify indices are in valid range\n",
    "                max_index = batch_edge_index.max().item()\n",
    "                if max_index >= batch_x.size(0):\n",
    "                    print(f\"Invalid index found: {max_index} >= {batch_x.size(0)}\")\n",
    "                    continue\n",
    "                    \n",
    "                # Generate embeddings for batch\n",
    "                batch_emb = model(batch_x, batch_edge_index)\n",
    "                embeddings.append(batch_emb[i:batch_end].cpu())  # Only keep embeddings for batch nodes\n",
    "            except RuntimeError as e:\n",
    "                print(f\"Error with batch {i}-{batch_end}: {str(e)}\")\n",
    "                del batch_edge_index, batch_x\n",
    "                torch.cuda.empty_cache()\n",
    "                continue\n",
    "                \n",
    "            # Clear GPU memory\n",
    "            del batch_edge_index, batch_x\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    # Concatenate all embeddings on CPU\n",
    "    all_embeddings = torch.cat(embeddings, dim=0)\n",
    "    print(f\"Generated embeddings shape: {all_embeddings.shape}\")\n",
    "    return all_embeddings\n",
    "\n",
    "# Generate and save embeddings\n",
    "node_embeddings = generate_embeddings(model, data)\n",
    "torch.save(node_embeddings, 'node_embeddings.pt')\n",
    "print(\"Embeddings saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
