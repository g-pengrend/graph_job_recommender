{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading node embeddings...\n",
      "Loading node embeddings from cache...\n",
      "Node embeddings loaded successfully!\n",
      "Loading/initializing language model...\n",
      "Loading model from cache...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Brandon\\AppData\\Local\\Temp\\ipykernel_6788\\1248321860.py:47: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  node_embeddings = torch.load(CACHE_PATHS['node_embeddings'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from cache successfully!\n",
      "Using device: cuda\n",
      "Loading graph and dataframe...\n",
      "Graph and dataframe loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import pandas as pd\n",
    "import ast\n",
    "from typing import List, Dict, Union, Tuple, Optional\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.distance import geodesic\n",
    "import annoy\n",
    "from pathlib import Path\n",
    "import time\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import pickle\n",
    "import faiss\n",
    "from dataclasses import dataclass\n",
    "from scipy.sparse import csr_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "import ollama\n",
    "import re\n",
    "\n",
    "# Initialization of job recommendation system components\n",
    "\n",
    "# Define cache paths\n",
    "CACHE_DIR = Path('recommendation_cache')\n",
    "CACHE_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "CACHE_PATHS = {\n",
    "    'graph': CACHE_DIR / 'final_complete_graph.pkl',\n",
    "    'dataframe': CACHE_DIR / 'final_graph_dataframe.pkl',\n",
    "    'annoy_index': CACHE_DIR / 'annoy_index.ann',\n",
    "    'faiss_index': CACHE_DIR / 'faiss_index.pkl', \n",
    "    'graph_metrics': CACHE_DIR / 'graph_metrics.pkl',\n",
    "    'embeddings_norm': CACHE_DIR / 'normalized_embeddings.pkl',\n",
    "    'degree_scores': CACHE_DIR / 'degree_scores.pkl',\n",
    "    'model': CACHE_DIR / 'model_cache.pkl',\n",
    "    'node_embeddings': CACHE_DIR / 'node_embeddings.pt'\n",
    "}\n",
    "\n",
    "# Load node embeddings\n",
    "print(\"Loading node embeddings...\")\n",
    "if CACHE_PATHS['node_embeddings'].exists():\n",
    "    print(\"Loading node embeddings from cache...\")\n",
    "    node_embeddings = torch.load(CACHE_PATHS['node_embeddings'])\n",
    "    print(\"Node embeddings loaded successfully!\")\n",
    "else:\n",
    "    raise FileNotFoundError(\"Node embeddings file not found. Please ensure node embeddings have been generated and saved from step 8.\")\n",
    "\n",
    "# MultiLabelBinarizer setup for job type decoding\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit([['contract'], ['fulltime'], ['internship'], ['parttime'], ['temporary']])\n",
    "\n",
    "# Geocoder initialization\n",
    "geolocator = Nominatim(user_agent=\"job_recommender_v1\")\n",
    "\n",
    "# Load or initialize model and tokenizer\n",
    "def load_or_init_model():\n",
    "    print(\"Loading/initializing language model...\")\n",
    "    if CACHE_PATHS['model'].exists():\n",
    "        print(\"Loading model from cache...\")\n",
    "        with open(CACHE_PATHS['model'], 'rb') as f:\n",
    "            cache = pickle.load(f)\n",
    "            tokenizer = cache['tokenizer']\n",
    "            model = cache['model']\n",
    "        print(\"Model loaded from cache successfully!\")\n",
    "    else:\n",
    "        print(\"Downloading and caching model...\")\n",
    "        tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L12-v2')\n",
    "        model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L12-v2')\n",
    "        \n",
    "        with open(CACHE_PATHS['model'], 'wb') as f:\n",
    "            pickle.dump({\n",
    "                'tokenizer': tokenizer,\n",
    "                'model': model\n",
    "            }, f)\n",
    "        print(\"Model downloaded and cached successfully!\")\n",
    "    \n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(f\"Using device: {device}\")\n",
    "    model = model.to(device)\n",
    "    return tokenizer, model, device\n",
    "\n",
    "# Initialize tokenizer, model, and device\n",
    "tokenizer, model, device = load_or_init_model()\n",
    "\n",
    "# Load graph and dataframe\n",
    "print(\"Loading graph and dataframe...\")\n",
    "if CACHE_PATHS['graph'].exists() and CACHE_PATHS['dataframe'].exists():\n",
    "    with open(CACHE_PATHS['graph'], 'rb') as f:\n",
    "        graph = pickle.load(f)\n",
    "    with open(CACHE_PATHS['dataframe'], 'rb') as f:\n",
    "        df = pickle.load(f)\n",
    "    print(\"Graph and dataframe loaded successfully!\")\n",
    "else:\n",
    "    print(\"Error: Graph or dataframe pickle files do not exist. Please check the paths.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "# Function to build Annoy index\n",
    "def build_ann_index(embeddings_np, n_trees=100):\n",
    "    print(\"\\nBuilding/Loading Annoy index...\")\n",
    "    if CACHE_PATHS['annoy_index'].exists():\n",
    "        print(\"Loading cached Annoy index...\")\n",
    "        index = annoy.AnnoyIndex(embeddings_np.shape[1], 'angular')\n",
    "        index.load(str(CACHE_PATHS['annoy_index']))\n",
    "        print(\"Annoy index loaded successfully!\")\n",
    "        return index\n",
    "    \n",
    "    print(\"Building new Annoy index...\")\n",
    "    index = annoy.AnnoyIndex(embeddings_np.shape[1], 'angular')\n",
    "    \n",
    "    for i in range(len(embeddings_np)):\n",
    "        if i % 1000 == 0:\n",
    "            print(f\"Adding item {i}/{len(embeddings_np)} to Annoy index...\")\n",
    "        index.add_item(i, embeddings_np[i])\n",
    "    \n",
    "    print(\"Building index with trees...\")\n",
    "    index.build(n_trees)\n",
    "    print(\"Saving index to disk...\")\n",
    "    index.save(str(CACHE_PATHS['annoy_index']))\n",
    "    print(\"Annoy index built and saved successfully!\")\n",
    "    return index\n",
    "\n",
    "# Function to build FAISS index\n",
    "def build_faiss_index(embeddings):\n",
    "    print(\"\\nBuilding/Loading FAISS index...\")\n",
    "    if CACHE_PATHS['faiss_index'].exists():\n",
    "        print(\"Loading cached FAISS index...\")\n",
    "        with open(CACHE_PATHS['faiss_index'], 'rb') as f:\n",
    "            index = pickle.load(f)\n",
    "        print(\"FAISS index loaded successfully!\")\n",
    "        return index\n",
    "            \n",
    "    print(\"Building new FAISS index...\")\n",
    "    dimension = embeddings.shape[1]\n",
    "    index = faiss.IndexFlatIP(dimension)\n",
    "    print(\"Normalizing embeddings...\")\n",
    "    normalized_embeddings = embeddings / np.linalg.norm(embeddings, axis=1)[:, np.newaxis]\n",
    "    print(\"Adding vectors to index...\")\n",
    "    index.add(normalized_embeddings.astype('float32'))\n",
    "    \n",
    "    print(\"Saving index to disk...\")\n",
    "    with open(CACHE_PATHS['faiss_index'], 'wb') as f:\n",
    "        pickle.dump(index, f)\n",
    "    print(\"FAISS index built and saved successfully!\")\n",
    "    return index\n",
    "\n",
    "# Function to cache normalized embeddings\n",
    "def cache_normalized_embeddings(embeddings_np):\n",
    "    print(\"\\nPreparing normalized embeddings...\")\n",
    "    if CACHE_PATHS['embeddings_norm'].exists():\n",
    "        print(\"Loading cached normalized embeddings...\")\n",
    "        with open(CACHE_PATHS['embeddings_norm'], 'rb') as f:\n",
    "            normalized = pickle.load(f)\n",
    "        print(\"Normalized embeddings loaded successfully!\")\n",
    "        return normalized\n",
    "    \n",
    "    print(\"Computing normalized embeddings...\")\n",
    "    normalized = embeddings_np / np.linalg.norm(embeddings_np, axis=1)[:, np.newaxis]\n",
    "    print(\"Saving normalized embeddings to disk...\")\n",
    "    with open(CACHE_PATHS['embeddings_norm'], 'wb') as f:\n",
    "        pickle.dump(normalized, f)\n",
    "    print(\"Normalized embeddings cached successfully!\")\n",
    "    return normalized\n",
    "\n",
    "def compute_pagerank_torch(graph, damping=0.85, max_iter=100, tol=1e-6):\n",
    "    print(\"\\nComputing PageRank scores...\")\n",
    "    # Create node ID to index mapping\n",
    "    node_map = {node: idx for idx, node in enumerate(graph.nodes())}\n",
    "    reverse_map = {idx: node for node, idx in node_map.items()}\n",
    "    n = len(node_map)\n",
    "    \n",
    "    # Convert edges using the mapping\n",
    "    edges = [(node_map[e[0]], node_map[e[1]]) for e in graph.edges()]\n",
    "    row = np.array([e[0] for e in edges])\n",
    "    col = np.array([e[1] for e in edges])\n",
    "    data = np.ones(len(edges))\n",
    "    adj_matrix = csr_matrix((data, (row, col)), shape=(n, n))\n",
    "\n",
    "    print(\"Normalizing adjacency matrix...\")\n",
    "    out_degree = np.array(adj_matrix.sum(axis=1)).flatten()\n",
    "    out_degree[out_degree == 0] = 1\n",
    "    D_inv = csr_matrix((1.0 / out_degree, (np.arange(n), np.arange(n))), shape=(n, n))\n",
    "    stochastic_matrix = D_inv @ adj_matrix\n",
    "\n",
    "    print(\"Converting to PyTorch sparse format...\")\n",
    "    coo_matrix = stochastic_matrix.tocoo()\n",
    "    indices = torch.tensor([coo_matrix.row, coo_matrix.col], dtype=torch.long)\n",
    "    values = torch.tensor(coo_matrix.data, dtype=torch.float32)\n",
    "    sparse_matrix = torch.sparse.FloatTensor(indices, values, torch.Size([n, n])).cuda()\n",
    "\n",
    "    print(\"Initializing PageRank computation...\")\n",
    "    pagerank_vector = torch.ones(n, device=\"cuda\") / n\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        new_pagerank_vector = (1 - damping) / n + damping * torch.sparse.mm(sparse_matrix.t(), pagerank_vector.unsqueeze(1)).squeeze()\n",
    "        if torch.norm(new_pagerank_vector - pagerank_vector, p=1) < tol:\n",
    "            print(f\"PageRank converged after {i + 1} iterations\")\n",
    "            break\n",
    "        pagerank_vector = new_pagerank_vector\n",
    "\n",
    "    print(\"PageRank computation completed!\")\n",
    "    # Convert back to original node IDs\n",
    "    pagerank_dict = {reverse_map[i]: score for i, score in enumerate(pagerank_vector.cpu().numpy())}\n",
    "    return pagerank_dict\n",
    "\n",
    "# Function to cache graph metrics\n",
    "def cache_graph_metrics(graph):\n",
    "    print(\"\\nComputing/Loading graph metrics...\")\n",
    "    if CACHE_PATHS['graph_metrics'].exists():\n",
    "        print(\"Loading cached graph metrics...\")\n",
    "        with open(CACHE_PATHS['graph_metrics'], 'rb') as f:\n",
    "            metrics = pickle.load(f)\n",
    "        print(\"Graph metrics loaded successfully!\")\n",
    "        return metrics\n",
    "    \n",
    "    print(\"Computing graph metrics...\")\n",
    "    print(\"Computing degree centrality...\")\n",
    "    degree = dict(graph.degree())\n",
    "    max_degree = max(degree.values())\n",
    "    \n",
    "    print(\"Computing PageRank...\")\n",
    "    pagerank = compute_pagerank_torch(graph)\n",
    "    \n",
    "    print(\"Computing core numbers...\")\n",
    "    core_numbers = nx.core_number(graph)\n",
    "    \n",
    "    metrics = {\n",
    "        'degree': degree,\n",
    "        'max_degree': max_degree,\n",
    "        'pagerank': pagerank,\n",
    "        'core_numbers': core_numbers\n",
    "    }\n",
    "    \n",
    "    print(\"Saving graph metrics to disk...\")\n",
    "    with open(CACHE_PATHS['graph_metrics'], 'wb') as f:\n",
    "        pickle.dump(metrics, f)\n",
    "    print(\"Graph metrics cached successfully!\")\n",
    "    return metrics\n",
    "\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0]\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "def get_job_description_embedding(text, tokenizer, model, max_chunk_length=512, overlap=50, device='cpu'):\n",
    "    print(\"\\nGenerating job description embedding...\")\n",
    "    tokens_per_chunk = max_chunk_length - 2  \n",
    "    words = text.split()\n",
    "    chunks = [' '.join(words[i:i+tokens_per_chunk]) for i in range(0, len(words), tokens_per_chunk - overlap)]\n",
    "    \n",
    "    embeddings = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        print(f\"Processing chunk {i+1}/{len(chunks)}...\")\n",
    "        encoded_input = tokenizer(chunk, return_tensors='pt', padding=True, truncation=True, max_length=max_chunk_length).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model_output = model(**encoded_input)\n",
    "        \n",
    "        sentence_embedding = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "        sentence_embedding = F.normalize(sentence_embedding, p=2, dim=1)\n",
    "        embeddings.append(sentence_embedding.cpu().numpy())\n",
    "\n",
    "    if embeddings:\n",
    "        print(\"Averaging chunk embeddings...\")\n",
    "        return np.mean(embeddings, axis=0).squeeze()\n",
    "    else:\n",
    "        print(\"Warning: No embeddings generated, returning zero vector\")\n",
    "        return np.zeros((384,))\n",
    "\n",
    "def get_job_title_embedding(text, tokenizer, model, device='cpu'):\n",
    "    print(f\"\\nGenerating embedding for job title: {text}\")\n",
    "    encoded_input = tokenizer(text, padding=True, truncation=True, return_tensors='pt').to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "    \n",
    "    sentence_embedding = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "    sentence_embedding = F.normalize(sentence_embedding, p=2, dim=1)\n",
    "    print(\"Job title embedding generated successfully!\")\n",
    "    \n",
    "    return sentence_embedding.cpu().numpy().squeeze()\n",
    "\n",
    "def process_job_description_with_LLM(document_text):\n",
    "    \"\"\"Process a single document using the same LLM setup.\"\"\"\n",
    "    model_name = 'capybarahermes-2.5-mistral-7b.Q5_K_M.gguf:latest'\n",
    "    prompt = f\"\"\"You are an expert in understanding job descriptions and extracting the details and even nuanced requirements for the job. Your goal is to read the input slowly and take time to consider what is written, extract the information and break it down into these 3 aspects:\n",
    "    1. responsibilites \n",
    "    2. qualifications\n",
    "    3. skills, technical and non-technical\n",
    "and summarize it in point form line by line.\n",
    "With each aspect answered, ensure that each of the aspects are properly differentiated and avoid overlaps as much as possible.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = ollama.chat(\n",
    "            model=model_name,\n",
    "            messages=[\n",
    "                {'role': 'system', 'content': prompt},\n",
    "                {'role': 'user', 'content': document_text}\n",
    "            ]\n",
    "        )\n",
    "        response_text = response['message']['content']\n",
    "        \n",
    "        # Clean the response text\n",
    "        # Remove special characters except alphanumeric, spaces, periods and commas\n",
    "        cleaned_text = re.sub(r'[^A-Za-z0-9\\s.,]', '', response_text)\n",
    "        # Remove point formatted numbers but keep time patterns\n",
    "        cleaned_text = re.sub(r'(?<!\\d)(\\d+)\\.(?!\\d)', '', cleaned_text).strip()\n",
    "        \n",
    "        return cleaned_text\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing document: {e}\")\n",
    "        return None\n",
    "\n",
    "@dataclass\n",
    "class UserPreferences:\n",
    "    \"\"\"User preferences for job recommendations\"\"\"\n",
    "    location: Optional[Tuple[float, float]] = None\n",
    "    location_name: Optional[str] = None  # Added for geocoding\n",
    "    job_title: Optional[str] = None\n",
    "    job_description: Optional[str] = None\n",
    "    max_distance_km: float = 10.0\n",
    "    weights: dict = None\n",
    "    remote_preference: bool = False\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.weights is None:\n",
    "            self.weights = {\n",
    "                'title_similarity': 0.3,\n",
    "                'description_similarity': 0.2,\n",
    "                'location_proximity': 0.2,\n",
    "                'degree': 0.1,\n",
    "                'pagerank': 0.1,\n",
    "                'core_number': 0.1\n",
    "            }\n",
    "def get_graph_based_recommendations(\n",
    "    graph: nx.Graph,\n",
    "    node_embeddings: torch.Tensor,\n",
    "    preferences: UserPreferences,\n",
    "    n_hops: int = 2,\n",
    "    top_k: int = 5,\n",
    "    n_candidates: int = 1000\n",
    ") -> List[dict]:\n",
    "    \"\"\"Generate recommendations using both FAISS and Annoy for hybrid search\"\"\"\n",
    "    print(\"\\nStarting recommendation generation...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(\"Preparing embeddings...\")\n",
    "    embeddings_np = node_embeddings.numpy()\n",
    "    print(f\"Embeddings shape: {embeddings_np.shape}\")\n",
    "    \n",
    "    print(\"\\nInitializing search indices...\")\n",
    "    faiss_index = build_faiss_index(embeddings_np)\n",
    "    annoy_index = build_ann_index(embeddings_np)\n",
    "    normalized_embeddings = cache_normalized_embeddings(embeddings_np)\n",
    "    graph_metrics = cache_graph_metrics(graph)\n",
    "    \n",
    "    # Create mapping from string ID to graph node name\n",
    "    id_to_node = {row['id']: f\"job_{idx}\" for idx, row in df.iterrows()}\n",
    "    node_to_id = {f\"job_{idx}\": row['id'] for idx, row in df.iterrows()}\n",
    "    \n",
    "    print(\"\\nGenerating candidate nodes...\")\n",
    "    candidate_indices = set()\n",
    "    if preferences.job_title:\n",
    "        print(f\"Finding similar jobs to title: {preferences.job_title}\")\n",
    "        title_embedding = get_job_title_embedding(preferences.job_title, tokenizer, model, device)\n",
    "        title_embedding = title_embedding / np.linalg.norm(title_embedding)\n",
    "        \n",
    "        print(\"Searching with FAISS...\")\n",
    "        D_faiss, I_faiss = faiss_index.search(title_embedding.astype('float32').reshape(1,-1), top_k)\n",
    "        faiss_candidates = set(I_faiss[0])\n",
    "        \n",
    "        print(\"Searching with Annoy...\")\n",
    "        annoy_candidates = set(annoy_index.get_nns_by_vector(\n",
    "            title_embedding, \n",
    "            top_k,\n",
    "            search_k=-1\n",
    "        ))\n",
    "        \n",
    "        candidate_indices = faiss_candidates.union(annoy_candidates)\n",
    "        print(f\"Found {len(candidate_indices)} candidate indices\")\n",
    "    else:\n",
    "        print(\"No job title specified, using PageRank for candidate selection...\")\n",
    "        weights = np.array([graph_metrics['pagerank'][f\"job_{i}\"] for i in range(len(df))])\n",
    "        weights = weights / weights.sum()\n",
    "        candidate_indices = set(np.random.choice(\n",
    "            len(df),\n",
    "            size=min(n_candidates, len(df)),\n",
    "            p=weights,\n",
    "            replace=False\n",
    "        ))\n",
    "    \n",
    "    print(\"\\nComputing job scores...\")\n",
    "    \n",
    "    # Determine which inputs are available\n",
    "    has_title = preferences.job_title is not None\n",
    "    has_description = preferences.job_description is not None\n",
    "    has_location = preferences.location is not None\n",
    "    \n",
    "    # Set weights based on available inputs\n",
    "    if has_title and has_description:\n",
    "        # All semantic inputs available\n",
    "        weights = {\n",
    "            'title_similarity': 0.25,\n",
    "            'description_similarity': 0.25,\n",
    "            'pagerank': 0.15,\n",
    "            'degree': 0.10,\n",
    "            'core_number': 0.05,\n",
    "            'location_proximity': 0.20 if has_location else 0.0\n",
    "        }\n",
    "    elif has_title or has_description:\n",
    "        # Only one semantic input\n",
    "        semantic_weight = 0.40\n",
    "        graph_weight_total = 0.40\n",
    "        weights = {\n",
    "            'title_similarity': semantic_weight if has_title else 0.0,\n",
    "            'description_similarity': semantic_weight if has_description else 0.0,\n",
    "            'pagerank': 0.20,\n",
    "            'degree': 0.15,\n",
    "            'core_number': 0.05,\n",
    "            'location_proximity': 0.20 if has_location else 0.0\n",
    "        }\n",
    "    else:\n",
    "        # No semantic inputs\n",
    "        weights = {\n",
    "            'pagerank': 0.35,\n",
    "            'degree': 0.35,\n",
    "            'core_number': 0.10,\n",
    "            'location_proximity': 0.20 if has_location else 0.0\n",
    "        }\n",
    "    \n",
    "    # Normalize weights if location is not provided\n",
    "    if not has_location:\n",
    "        total_weight = sum(weights.values())\n",
    "        weights = {k: v/total_weight for k, v in weights.items()}\n",
    "    \n",
    "    # Update preferences with new weights\n",
    "    preferences.weights = weights\n",
    "    \n",
    "    # Pre-compute normalized graph metrics\n",
    "    print(\"Normalizing graph metrics...\")\n",
    "    max_pagerank = max(graph_metrics['pagerank'].values())\n",
    "    max_core_number = max(graph_metrics['core_numbers'].values())\n",
    "    \n",
    "    # Normalize degree scores for the subgraph\n",
    "    subgraph = graph.subgraph([f\"job_{i}\" for i in candidate_indices])\n",
    "    degree_scores = dict(subgraph.degree())\n",
    "    max_degree = max(degree_scores.values()) if degree_scores else 1\n",
    "    \n",
    "    batch_size = 100\n",
    "    job_scores = []\n",
    "    total_batches = len(candidate_indices) // batch_size + (1 if len(candidate_indices) % batch_size else 0)\n",
    "    \n",
    "    for i in range(0, len(candidate_indices), batch_size):\n",
    "        batch_indices = list(candidate_indices)[i:i + batch_size]\n",
    "        current_batch = i // batch_size + 1\n",
    "        print(f\"\\nProcessing batch {current_batch}/{total_batches}...\")\n",
    "        batch_scores = []\n",
    "        \n",
    "        for idx in batch_indices:\n",
    "            try:\n",
    "                node = f\"job_{idx}\"\n",
    "                attrs = graph.nodes[node]\n",
    "                \n",
    "                score_components = {}\n",
    "                \n",
    "                # Normalize semantic similarities by mapping from [-1,1] to [0,1]\n",
    "                if preferences.job_title:\n",
    "                    raw_similarity = np.dot(\n",
    "                        title_embedding,\n",
    "                        normalized_embeddings[idx]\n",
    "                    )\n",
    "                    # Map from [-1,1] to [0,1] using (x + 1) / 2\n",
    "                    score_components['title_similarity'] = (raw_similarity + 1) / 2\n",
    "\n",
    "                if preferences.job_description:\n",
    "                    desc_embedding = get_job_description_embedding(\n",
    "                        preferences.job_description,\n",
    "                        tokenizer,\n",
    "                        model,\n",
    "                        device=device\n",
    "                    )\n",
    "                    raw_similarity = np.dot(\n",
    "                        desc_embedding,\n",
    "                        normalized_embeddings[idx]\n",
    "                    )\n",
    "                    # Map from [-1,1] to [0,1] using (x + 1) / 2\n",
    "                    score_components['description_similarity'] = (raw_similarity + 1) / 2\n",
    "                \n",
    "                # Normalize location proximity using exponential decay\n",
    "                if preferences.location:\n",
    "                    job_location = (\n",
    "                        ast.literal_eval(attrs['lat_long'])\n",
    "                        if isinstance(attrs['lat_long'], str)\n",
    "                        else attrs['lat_long']\n",
    "                    )\n",
    "                    distance = geodesic(preferences.location, job_location).kilometers\n",
    "                    score_components['location_proximity'] = np.exp(-distance / preferences.max_distance_km)\n",
    "                \n",
    "                # Normalize graph metrics\n",
    "                score_components['degree'] = degree_scores[node] / max_degree\n",
    "                score_components['pagerank'] = graph_metrics['pagerank'][node] / max_pagerank\n",
    "                score_components['core_number'] = graph_metrics['core_numbers'][node] / max_core_number\n",
    "                \n",
    "                # Verify all components are in [0,1] range\n",
    "                for component in score_components:\n",
    "                    score_components[component] = max(0, min(1, score_components[component]))\n",
    "                \n",
    "                # Calculate final score using normalized components and weights\n",
    "                final_score = sum(\n",
    "                    score * preferences.weights.get(component, 0)\n",
    "                    for component, score in score_components.items()\n",
    "                )\n",
    "                \n",
    "                job_type_encoded = attrs['job_type_encoding']\n",
    "                if isinstance(job_type_encoded, str):\n",
    "                    job_type_encoded = ast.literal_eval(job_type_encoded)\n",
    "                job_type_encoded = np.array(job_type_encoded)\n",
    "                if job_type_encoded.ndim == 1:\n",
    "                    job_type_encoded = job_type_encoded.reshape(1, -1)\n",
    "\n",
    "                job_type_decoded = mlb.inverse_transform(job_type_encoded)[0]\n",
    "\n",
    "                batch_scores.append({\n",
    "                    'index': node_to_id[node],\n",
    "                    'company': attrs['company'],\n",
    "                    'job_type': job_type_decoded,\n",
    "                    'location': attrs['lat_long'],\n",
    "                    'is_remote': attrs['is_remote'],\n",
    "                    'score_components': score_components,\n",
    "                    'final_score': final_score\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing index {idx}: {str(e)}\")\n",
    "                traceback.print_exc()\n",
    "                continue\n",
    "        \n",
    "        job_scores.extend(batch_scores)\n",
    "    \n",
    "    print(\"\\nSorting recommendations...\")\n",
    "    recommendations = sorted(\n",
    "        job_scores,\n",
    "        key=lambda x: x['final_score'],\n",
    "        reverse=True\n",
    "    )[:top_k]\n",
    "    \n",
    "    # Get URLs and titles for only the top recommendations\n",
    "    for rec in recommendations:\n",
    "        job_data = df.loc[df['id'] == rec['index']].iloc[0]\n",
    "        rec['job_url'] = job_data['job_url']\n",
    "        rec['job_url_direct'] = job_data['job_url_direct']\n",
    "        rec['title'] = job_data['title']\n",
    "    \n",
    "        # Add cosine similarity matrix for top-k recommendations\n",
    "    if len(recommendations) > 1:\n",
    "        print(\"\\nComputing similarity matrix for top recommendations...\")\n",
    "        \n",
    "        # Get pre-computed embeddings for titles and descriptions\n",
    "        title_embeddings = []\n",
    "        desc_embeddings = []\n",
    "        \n",
    "        for rec in recommendations:\n",
    "            job_data = df.loc[df['id'] == rec['index']].iloc[0]\n",
    "            \n",
    "            # Get pre-computed embeddings from DataFrame\n",
    "            title_embeddings.append(job_data['job_title_embedding'])\n",
    "            desc_embeddings.append(job_data['job_description_embedding'])\n",
    "        \n",
    "        # Convert to numpy arrays\n",
    "        title_embeddings = np.array(title_embeddings)\n",
    "        desc_embeddings = np.array(desc_embeddings)\n",
    "        \n",
    "        # Compute similarity matrices\n",
    "        title_similarity = cosine_similarity(title_embeddings)\n",
    "        desc_similarity = cosine_similarity(desc_embeddings)\n",
    "        \n",
    "        # Add similarity matrices to the output\n",
    "        for i, rec in enumerate(recommendations):\n",
    "            rec['title_similarities'] = {\n",
    "                recommendations[j]['title']: float(title_similarity[i][j])\n",
    "                for j in range(len(recommendations))\n",
    "                if i != j\n",
    "            }\n",
    "            rec['description_similarities'] = {\n",
    "                recommendations[j]['title']: float(desc_similarity[i][j])\n",
    "                for j in range(len(recommendations))\n",
    "                if i != j\n",
    "            }\n",
    "\n",
    "    print(f\"\\nRecommendation generation completed in {time.time() - start_time:.2f} seconds\")\n",
    "    return recommendations\n",
    "\n",
    "def get_personalized_recommendations(preload_preferences=False):\n",
    "    \"\"\"Interactive function to get user preferences and return recommendations\"\"\"\n",
    "    print(\"\\nJob Recommendation System\")\n",
    "    print(\"------------------------\")\n",
    "    \n",
    "    preferences = UserPreferences()\n",
    "    \n",
    "    if preload_preferences:\n",
    "        # Preload default preferences\n",
    "        preferences.location = (1.3521, 103.8198)  # Singapore coordinates\n",
    "        preferences.location_name = \"Singapore\"\n",
    "        preferences.max_distance_km = 10\n",
    "        preferences.job_title = \"Service Engineer\"\n",
    "        preferences.job_description = \"Skilled in mechanical work, always hardworking, able to handle odd hours, able to do all jobs\"\n",
    "        preferences.weights = {\n",
    "            'title_similarity': 0.3,\n",
    "            'description_similarity': 0.2,\n",
    "            'location_proximity': 0.2,\n",
    "            'degree': 0.1,\n",
    "            'pagerank': 0.1,\n",
    "            'core_number': 0.1\n",
    "        }\n",
    "        print(\"Using preloaded preferences:\")\n",
    "        print(f\"Location: {preferences.location_name}\")\n",
    "        print(f\"Job Title: {preferences.job_title}\")\n",
    "        print(f\"Job Description: {preferences.job_description}\")\n",
    "        print(f\"Max Distance: {preferences.max_distance_km} km\")\n",
    "        print(\"Weights:\", preferences.weights)\n",
    "    else:\n",
    "        use_location = input(\"Would you like to specify a location? (y/n): \").lower() == 'y'\n",
    "        if use_location:\n",
    "            location_input = int(input(\"Enter Postal Code (e.g., 123456): \"))\n",
    "            try:\n",
    "                print(\"Geocoding location...\")\n",
    "                location = geolocator.geocode(location_input)\n",
    "                if location:\n",
    "                    preferences.location = (location.latitude, location.longitude)\n",
    "                    preferences.location_name = location_input\n",
    "                    print(f\"Location found: {location.address}\")\n",
    "                else:\n",
    "                    print(\"Location not found. Please enter coordinates manually.\")\n",
    "                    lat = float(input(\"Enter latitude (e.g., 1.3521 for Singapore): \"))\n",
    "                    lon = float(input(\"Enter longitude (e.g., 103.8198): \"))\n",
    "                    preferences.location = (lat, lon)\n",
    "            except Exception as e:\n",
    "                print(f\"Error geocoding location: {str(e)}\")\n",
    "                print(\"Please enter coordinates manually.\")\n",
    "                lat = float(input(\"Enter latitude (e.g., 1.3521 for Singapore): \"))\n",
    "                lon = float(input(\"Enter longitude (e.g., 103.8198): \"))\n",
    "                preferences.location = (lat, lon)\n",
    "            \n",
    "            preferences.max_distance_km = float(input(\"Maximum distance in km (default 10): \") or 10)\n",
    "        \n",
    "        use_title = input(\"Would you like to specify a job title? (y/n): \").lower() == 'y'\n",
    "        if use_title:\n",
    "            preferences.job_title = input(\"Enter job title: \")\n",
    "        \n",
    "        use_desc = input(\"Would you like to specify a job description? (y/n): \").lower() == 'y'\n",
    "        if use_desc:\n",
    "            preferences.job_description = input(\"Enter job description: \")\n",
    "            use_llm = input(\"Would you like to summarize your job description using our in-built AI matching tool? (y/n): \").lower() == 'y'\n",
    "            if use_llm:\n",
    "                print(\"Processing job description with JD_Matching_Tool...\")\n",
    "                summarized_desc = process_job_description_with_LLM(preferences.job_description)\n",
    "                if summarized_desc:\n",
    "                    print(\"\\nSummarized job description:\\n\")\n",
    "                    print(summarized_desc)\n",
    "                    preferences.job_description = summarized_desc\n",
    "        \n",
    "        print(\"\\nSet the importance for each of the following factors on a scale from 0 (not important) to 1 (very important):\")\n",
    "        if use_title:\n",
    "            preferences.weights['title_similarity'] = float(input(\"How important is it for the job title to match your preferences? (default 0.3): \") or 0.3)\n",
    "        if use_desc:\n",
    "            preferences.weights['description_similarity'] = float(input(\"How important is it for the job description to match your skills and experience? (default 0.2): \") or 0.2)\n",
    "        if use_location:\n",
    "            preferences.weights['location_proximity'] = float(input(\"How important is it for the job to be near your preferred location? (default 0.2): \") or 0.2)\n",
    "\n",
    "        preferences.weights['degree'] = float(input(\"How important is it for the job to be popular or well-connected within the network? (default 0.1): \") or 0.1)\n",
    "        preferences.weights['pagerank'] = float(input(\"How important is it for the job to be influential within the network? (default 0.1): \") or 0.1)\n",
    "        preferences.weights['core_number'] = float(input(\"How important is it for the job to be well-connected within its area or community? (default 0.1): \") or 0.1)\n",
    "    \n",
    "    print(\"\\nGenerating recommendations...\")\n",
    "    recommendations = get_graph_based_recommendations(\n",
    "        graph=graph,\n",
    "        node_embeddings=node_embeddings,\n",
    "        preferences=preferences\n",
    "    )        \n",
    "    \n",
    "    print(\"\\nTop Recommendations:\")\n",
    "    print(\"-------------------\")\n",
    "    for i, rec in enumerate(recommendations, 1):\n",
    "        print(f\"\\n{i}. Company: {rec['company']}\")\n",
    "        print(f\"   Job Title: {rec['title']}\")\n",
    "        print(f\"   Job Type: {', '.join(rec['job_type'])}\")\n",
    "        if preferences.location:\n",
    "            job_loc = ast.literal_eval(rec['location']) if isinstance(rec['location'], str) else rec['location']\n",
    "            distance = geodesic(preferences.location, job_loc).kilometers\n",
    "            print(f\"   Distance: {distance:.1f} km\")\n",
    "        print(f\"   Remote: {rec['is_remote']}\")\n",
    "        print(f\"   Job URL: {rec['job_url']}\")\n",
    "        print(f\"   Direct URL: {rec['job_url_direct']}\")\n",
    "        print(\"   Scores:\")\n",
    "        for component, score in rec['score_components'].items():\n",
    "            print(f\"      - {component}: {score:.3f}\")\n",
    "        print(f\"   Final Score: {rec['final_score']:.3f}\")\n",
    "        \n",
    "        # Print similarities with other recommendations\n",
    "        if 'title_similarities' in rec:\n",
    "            print(\"   Title Similarities:\")\n",
    "            for other_title, sim_score in rec['title_similarities'].items():\n",
    "                print(f\"      - {other_title}: {sim_score:.3f}\")\n",
    "        if 'description_similarities' in rec:\n",
    "            print(\"   Description Similarities:\")\n",
    "            for other_title, sim_score in rec['description_similarities'].items():\n",
    "                print(f\"      - {other_title}: {sim_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Recommendation System\n",
      "------------------------\n",
      "Using preloaded preferences:\n",
      "Location: Singapore\n",
      "Job Title: Service Engineer\n",
      "Job Description: Skilled in mechanical work, always hardworking, able to handle odd hours, able to do all jobs\n",
      "Max Distance: 10 km\n",
      "Weights: {'title_similarity': 0.3, 'description_similarity': 0.2, 'location_proximity': 0.2, 'degree': 0.1, 'pagerank': 0.1, 'core_number': 0.1}\n",
      "\n",
      "Generating recommendations...\n",
      "\n",
      "Starting recommendation generation...\n",
      "Preparing embeddings...\n",
      "Embeddings shape: (25610, 384)\n",
      "\n",
      "Initializing search indices...\n",
      "\n",
      "Building/Loading FAISS index...\n",
      "Loading cached FAISS index...\n",
      "FAISS index loaded successfully!\n",
      "\n",
      "Building/Loading Annoy index...\n",
      "Loading cached Annoy index...\n",
      "Annoy index loaded successfully!\n",
      "\n",
      "Preparing normalized embeddings...\n",
      "Loading cached normalized embeddings...\n",
      "Normalized embeddings loaded successfully!\n",
      "\n",
      "Computing/Loading graph metrics...\n",
      "Loading cached graph metrics...\n",
      "Graph metrics loaded successfully!\n",
      "\n",
      "Generating candidate nodes...\n",
      "Finding similar jobs to title: Service Engineer\n",
      "\n",
      "Generating embedding for job title: Service Engineer\n",
      "Job title embedding generated successfully!\n",
      "Searching with FAISS...\n",
      "Searching with Annoy...\n",
      "Found 10 candidate indices\n",
      "\n",
      "Computing job scores...\n",
      "Normalizing graph metrics...\n",
      "\n",
      "Processing batch 1/1...\n",
      "\n",
      "Generating job description embedding...\n",
      "Processing chunk 1/1...\n",
      "Averaging chunk embeddings...\n",
      "\n",
      "Generating job description embedding...\n",
      "Processing chunk 1/1...\n",
      "Averaging chunk embeddings...\n",
      "\n",
      "Generating job description embedding...\n",
      "Processing chunk 1/1...\n",
      "Averaging chunk embeddings...\n",
      "\n",
      "Generating job description embedding...\n",
      "Processing chunk 1/1...\n",
      "Averaging chunk embeddings...\n",
      "\n",
      "Generating job description embedding...\n",
      "Processing chunk 1/1...\n",
      "Averaging chunk embeddings...\n",
      "\n",
      "Generating job description embedding...\n",
      "Processing chunk 1/1...\n",
      "Averaging chunk embeddings...\n",
      "\n",
      "Generating job description embedding...\n",
      "Processing chunk 1/1...\n",
      "Averaging chunk embeddings...\n",
      "\n",
      "Generating job description embedding...\n",
      "Processing chunk 1/1...\n",
      "Averaging chunk embeddings...\n",
      "\n",
      "Generating job description embedding...\n",
      "Processing chunk 1/1...\n",
      "Averaging chunk embeddings...\n",
      "\n",
      "Generating job description embedding...\n",
      "Processing chunk 1/1...\n",
      "Averaging chunk embeddings...\n",
      "\n",
      "Sorting recommendations...\n",
      "\n",
      "Computing similarity matrix for top recommendations...\n",
      "\n",
      "Recommendation generation completed in 0.98 seconds\n",
      "\n",
      "Top Recommendations:\n",
      "-------------------\n",
      "\n",
      "1. Company: Tana Development (Singapore) Pte Ltd\n",
      "   Job Title: Part / Full Time Cook\n",
      "   Job Type: fulltime, parttime\n",
      "   Distance: 6.0 km\n",
      "   Remote: False\n",
      "   Job URL: https://sg.indeed.com/viewjob?jk=00b023a857ba861e\n",
      "   Direct URL: https://www.mycareersfuture.gov.sg/job/food-and-beverage/part-full-time-cook-tana-development-f8b79371ac1cd9b8fdd3a37417bc295b\n",
      "   Scores:\n",
      "      - title_similarity: 0.529\n",
      "      - description_similarity: 0.485\n",
      "      - location_proximity: 0.551\n",
      "      - degree: 1.000\n",
      "      - pagerank: 0.000\n",
      "      - core_number: 0.286\n",
      "   Final Score: 0.478\n",
      "   Title Similarities:\n",
      "      - Accountant: 0.230\n",
      "      - Snr Executive/ Executive, Quality and Safety Standards: 0.144\n",
      "      - Sales Promoter: 0.294\n",
      "      - Porter: 0.177\n",
      "   Description Similarities:\n",
      "      - Accountant: 0.453\n",
      "      - Snr Executive/ Executive, Quality and Safety Standards: 0.456\n",
      "      - Sales Promoter: 0.430\n",
      "      - Porter: 0.394\n",
      "\n",
      "2. Company: LIFEUP MART PTE. LTD.\n",
      "   Job Title: Accountant\n",
      "   Job Type: fulltime\n",
      "   Distance: 6.3 km\n",
      "   Remote: False\n",
      "   Job URL: https://sg.indeed.com/viewjob?jk=01d903fc0a206d1f\n",
      "   Direct URL: https://www.mycareersfuture.gov.sg/job/accounting/accountant-lifeup-mart-b53b2a2c078d103e26ffb9b0255c4e6f\n",
      "   Scores:\n",
      "      - title_similarity: 0.529\n",
      "      - description_similarity: 0.485\n",
      "      - location_proximity: 0.533\n",
      "      - degree: 1.000\n",
      "      - pagerank: 0.000\n",
      "      - core_number: 0.315\n",
      "   Final Score: 0.476\n",
      "   Title Similarities:\n",
      "      - Part / Full Time Cook: 0.230\n",
      "      - Snr Executive/ Executive, Quality and Safety Standards: 0.294\n",
      "      - Sales Promoter: 0.415\n",
      "      - Porter: 0.183\n",
      "   Description Similarities:\n",
      "      - Part / Full Time Cook: 0.453\n",
      "      - Snr Executive/ Executive, Quality and Safety Standards: 0.370\n",
      "      - Sales Promoter: 0.354\n",
      "      - Porter: 0.419\n",
      "\n",
      "3. Company: Singapore Manufacturing Federation\n",
      "   Job Title: Snr Executive/ Executive, Quality and Safety Standards\n",
      "   Job Type: fulltime\n",
      "   Distance: 8.6 km\n",
      "   Remote: False\n",
      "   Job URL: https://sg.indeed.com/viewjob?jk=01e2366962e4c99b\n",
      "   Direct URL: https://www.mycareersfuture.gov.sg/job/admin/snr-executive-executive-quality-safety-standards-singapore-manufacturing-federation-c9006651ac180c0d5000556360e6fcc1\n",
      "   Scores:\n",
      "      - title_similarity: 0.529\n",
      "      - description_similarity: 0.485\n",
      "      - location_proximity: 0.424\n",
      "      - degree: 1.000\n",
      "      - pagerank: 0.000\n",
      "      - core_number: 0.108\n",
      "   Final Score: 0.444\n",
      "   Title Similarities:\n",
      "      - Part / Full Time Cook: 0.144\n",
      "      - Accountant: 0.294\n",
      "      - Sales Promoter: 0.281\n",
      "      - Porter: 0.063\n",
      "   Description Similarities:\n",
      "      - Part / Full Time Cook: 0.456\n",
      "      - Accountant: 0.370\n",
      "      - Sales Promoter: 0.322\n",
      "      - Porter: 0.374\n",
      "\n",
      "4. Company: Oomph Pte. Ltd.\n",
      "   Job Title: Sales Promoter\n",
      "   Job Type: fulltime\n",
      "   Distance: 8.8 km\n",
      "   Remote: False\n",
      "   Job URL: https://sg.indeed.com/viewjob?jk=000a01db7a6ccc16\n",
      "   Direct URL: https://www.mycareersfuture.gov.sg/job/customer-service/sales-promoter-oomph-e63161cdb7dda2c74dfa04a764ed31af\n",
      "   Scores:\n",
      "      - title_similarity: 0.529\n",
      "      - description_similarity: 0.485\n",
      "      - location_proximity: 0.415\n",
      "      - degree: 1.000\n",
      "      - pagerank: 0.000\n",
      "      - core_number: 0.108\n",
      "   Final Score: 0.442\n",
      "   Title Similarities:\n",
      "      - Part / Full Time Cook: 0.294\n",
      "      - Accountant: 0.415\n",
      "      - Snr Executive/ Executive, Quality and Safety Standards: 0.281\n",
      "      - Porter: 0.235\n",
      "   Description Similarities:\n",
      "      - Part / Full Time Cook: 0.430\n",
      "      - Accountant: 0.354\n",
      "      - Snr Executive/ Executive, Quality and Safety Standards: 0.322\n",
      "      - Porter: 0.477\n",
      "\n",
      "5. Company: PHOENIX OPCO PTE. LTD.\n",
      "   Job Title: Porter\n",
      "   Job Type: fulltime\n",
      "   Distance: 9.0 km\n",
      "   Remote: False\n",
      "   Job URL: https://sg.indeed.com/viewjob?jk=0005a77c5af02f32\n",
      "   Direct URL: https://www.mycareersfuture.gov.sg/job/customer-service/porter-phoenix-opco-c6a4a2faf33919b8d6287a84e39748f9\n",
      "   Scores:\n",
      "      - title_similarity: 0.529\n",
      "      - description_similarity: 0.485\n",
      "      - location_proximity: 0.407\n",
      "      - degree: 0.000\n",
      "      - pagerank: 0.000\n",
      "      - core_number: 0.894\n",
      "   Final Score: 0.380\n",
      "   Title Similarities:\n",
      "      - Part / Full Time Cook: 0.177\n",
      "      - Accountant: 0.183\n",
      "      - Snr Executive/ Executive, Quality and Safety Standards: 0.063\n",
      "      - Sales Promoter: 0.235\n",
      "   Description Similarities:\n",
      "      - Part / Full Time Cook: 0.394\n",
      "      - Accountant: 0.419\n",
      "      - Snr Executive/ Executive, Quality and Safety Standards: 0.374\n",
      "      - Sales Promoter: 0.477\n"
     ]
    }
   ],
   "source": [
    "get_personalized_recommendations(preload_preferences=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating job description embedding...\n",
      "Processing chunk 1/1...\n",
      "Averaging chunk embeddings...\n",
      "                                                        title                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         description\n",
      "11221                               Machine Learning Engineer                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    **Responsibilities**:\\n\\n Develop and deploy machine learning models: Design, build, and optimize machine learning models and algorithms to solve specific business problems. Collaborate with cross-functional teams to gather requirements, define objectives, and deploy models into production environments.\\n\\n Model training and evaluation: Train and fine-tune machine learning models using appropriate algorithms and techniques. Evaluate model performance and identify areas for improvement, employing techniques such as cross-validation, hyperparameter optimization, and ensemble methods.\\n\\n Model deployment and integration: Collaborate with software engineers and DevOps teams to deploy machine learning models into production environments. Implement APIs and integrate models with existing systems and applications to enable real-time decision-making.\\n\\n Performance monitoring and maintenance: Monitor model performance and address any issues or anomalies that arise. Continuously improve models by refining algorithms, optimizing code, and incorporating feedback from users and stakeholders.\\n\\n Data analysis and insights: Perform exploratory data analysis, generate insights, and present findings to stakeholders. Use statistical methods and visualization techniques to communicate complex concepts and patterns effectively.\\n\\n Stay up-to-date with the latest advancements: Keep abreast of the latest research and trends in machine learning and artificial intelligence. Evaluate and recommend new tools, libraries, and methodologies to enhance the efficiency and effectiveness of the machine learning workflow.\\n\\n**Requirements:**\\n\\n Education: Bachelor's or Master's degree in Computer Science, Data Science, Machine Learning, or a related field. An equivalent combination of education and experience will also be considered. (Fresh Grad open to apply)\\n\\n Experience: At least 2 years experience working in a similar role. Hands-on experience in designing, developing, and deploying machine learning models in real-world applications.\\n\\n Solid understanding of machine learning algorithms, techniques, and libraries (e.g., TensorFlow, PyTorch, scikit-learn).\\n\\n Experience with working on Large Language Models and Generative AI technology is a plus.\\n\\n**Technical skills:**\\n\\n1) Strong programming skills in languages such as Python.\\n\\n2) Proficiency in machine learning frameworks such as TensorFlow, PyTorch, or Scikit-Learn etc.\\n\\n3) Solid understanding of Statistical Analysis, Probability Theory, and Hypothesis Testing.\\n\\n4) Familiarity with machine learning tools on cloud platforms (e.g., AWS, Azure, GCP) and distributed computing frameworks (e.g., Spark) is a plus.\\n\\n5) Problem-solving and analytical mindset: Ability to analyze complex problems, break them down into solvable components, and develop innovative machine learning solutions. Strong mathematical and analytical skills are essential.\\n\\n6) Communication and collaboration: Excellent verbal and written communication skills, with the ability to convey technical concepts to both technical and non-technical stakeholders. Proven ability to work collaboratively in a team environment and effectively manage multiple priorities.\\n\\n7) Adaptability and continuous learning: Willingness to adapt to evolving technologies and learn new tools and techniques. Demonstrated commitment to staying updated with the latest advancements in machine learning and artificial intelligence.\\n\\nOnly shortlisted candidates will be notified.\\n\\nPlease email a copy of your detailed resume to bianca@talentsis.com.sg for immediate processing.\\n\\n(EA Reg No: 20C0312)\\n\\nJob Type: Full-time\\n\\nPay: $4,200.00 - $5,500.00 per month\\n\\nWork Location: In person\n",
      "16180                  Senior AI/ML Engineer (Permanent role)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         **Job Responsibilities** :\\n\\n\\n* Develop and deploy machine learning models: Design, build, and optimize machine learning models and algorithms to solve specific business problems. Collaborate with cross-functional teams to gather requirements, define objectives, and deploy models into production environments.\\n* Model training and evaluation: Train and fine-tune machine learning models using appropriate algorithms and techniques. Evaluate model performance and identify areas for improvement, employing techniques such as cross-validation, hyperparameter optimization, and ensemble methods.\\n* Model deployment and integration: Collaborate with software engineers and DevOps teams to deploy machine learning models into production environments. Implement APIs and integrate models with existing systems and applications to enable real-time decision-making.\\n* Performance monitoring and maintenance: Monitor model performance and address any issues or anomalies that arise. Continuously improve models by refining algorithms, optimizing code, and incorporating feedback from users and stakeholders.\\n* Data analysis and insights: Perform exploratory data analysis, generate insights, and present findings to stakeholders. Use statistical methods and visualization techniques to communicate complex concepts and patterns effectively.\\n* Stay up-to-date with the latest advancements: Keep abreast of the latest research and trends in machine learning and artificial intelligence. Evaluate and recommend new tools, libraries, and methodologies to enhance the efficiency and effectiveness of the machine learning workflow.\\n\\n**Requirements:**\\n\\n* Bachelor's or Master's degree in Computer Science, Data Science, Machine Learning, or a related field. An equivalent combination of education and experience will also be considered.\\n* At least 2 years experience working in a similar role. Hands-on experience in designing, developing, and deploying machine learning models in real-world applications.\\n* Solid understanding of machine learning algorithms, techniques, and libraries (e.g., TensorFlow, PyTorch, scikit-learn).\\n* Experience with working on Large Language Models and Generative AI technology is a plus.\\n\\n**Technical skills:**\\n\\n* Strong programming skills in languages such as Python.\\n* Proficiency in machine learning frameworks such as TensorFlow, PyTorch, or Scikit-Learn etc.\\n* Solid understanding of Statistical Analysis, Probability Theory, and Hypothesis Testing.\\n* Familiarity with machine learning tools on cloud platforms (e.g., AWS, Azure, GCP) and distributed computing frameworks (e.g., Spark) is a plus.\\n* Problem-solving and analytical mindset: Ability to analyze complex problems, break them down into solvable components, and develop innovative machine learning solutions. Strong mathematical and analytical skills are essential.\\n* Communication and collaboration: Excellent verbal and written communication skills, with the ability to convey technical concepts to both technical and non-technical stakeholders. Proven ability to work collaboratively in a team environment and effectively manage multiple priorities.\\n* Adaptability and continuous learning: Willingness to adapt to evolving technologies and learn new tools and techniques. Demonstrated commitment to staying updated with the latest advancements in machine learning and artificial intelligence.\\n\\n(EA Reg No: 20C0312)\\n\\n\\nPlease email a copy of your detailed resume to qianyu@talentsis.com.sg for immediate processing.\\n\\n\\nOnly shortlisted candidates will be notified.\n",
      "20147                    Software Engineer - Machine Learning                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        **What is Splore?**\\n\\n **Splore** is transforming how businesses handle information by utilizing enterprise-grade generative AI and multi-agent systems to streamline and enhance decision-making processes. Founded and funded by industry leaders Temasek and Menyala, Splore specializes in AI-driven solutions for precision and efficiency in information retrieval.  \\n\\n  \\n\\nOur proprietary Agentic Answer Engine boost up to 95% accuracy in retrieving relevant data and slashes search times by 60%, empowering organizations to make informed decisions rapidly.  \\n\\n  \\n\\nSplore's platform effortlessly connects with your existing business systems, turning routine tasks into automated workflows and delivering deep analytical insights. This innovative technology enhances operational efficiency and empowers smarter decision-making in industries such as finance, customer service, and R&D.  \\n\\n  \\n\\nBacked by a team of AI and machine learning experts, Splore is on a mission to redefine AI applications in business. We empower organizations with the tools to stay ahead in a data-driven world, providing precise, actionable insights that drive businesses to operate more effectively and make smarter decisions.\\n\\n **What is the role?**\\n\\n  \\n\\nWe are seeking a motivated Machine Learning Engineer with proficiency in Python, ML/DL algorithms and microservice framework. The ideal candidate will have a good understanding in NLP and deep learning with certain exposure to generative models, and familiarity with cloud services. This position offers a unique opportunity to gain hands-on experience in applying machine learning techniques to real-world projects.\\n\\n **Responsibilities**\\n\\n  \\n\\nIn this role, you will:\\n\\n\\n* Collaborate with senior engineers to develop and implement machine learning models and algorithms for our AI answer engine.\\n* Assist in collecting, preprocessing, and analyzing data sets to derive meaningful insights.\\n* Support the design, testing, and fine-tuning of machine learning models.\\n* Participate in brainstorming sessions, contributing innovative ideas to enhance existing models or develop new ones.\\n* Engage with customer success team to identify potential customer painpoints and design solutions correspondingly.\\n* Stay up-to-date with the latest advancements in machine learning and related technologies.\\n\\n  \\n\\n\\n**Attributes**\\n\\n  \\n\\nWe are looking for a Machine Learning Engineer with the following:\\n\\n\\n* **Dealing with Ambiguity** - You thrive in navigating dynamic environments, making informed decisions amid evolving scenarios and comfortably embracing uncertainty.\\n* **Collaborates** - We're all about teamwork here. You will work closely with the Senior Engineers to develop and implement machine learning models and algorithms. Close cross functional collaboration with our Product, Design and Engineering teams will be key in building our gaming search engine!\\n* **Nimble Learning** - We're looking for someone who thrives in a startup environment. You're not afraid to get your hands dirty and learn through experimentation when faced with fresh challenges. You're always on the pulse of the latest ML trends and immersing yourself in new technologies.\\n* **Functional/ Technical Skills** - Strong foundations in machine learning fundamentals and algorithms, with prior experience in developing and implementing machine learning models.\\n\\t+ Proficiency in Python and FastAPI\\n\\t+ Proficiency in machine learning libraries and frameworks (e.g., TensorFlow, PyTorch, transformers, scikit-learn).\\n\\t+ Experience in LLM fine-tuning, e.g. full fine-tuning, LoRA based\\n\\t+ Experience with NLP libraries/frameworks such as NLTK, SpaCy, Gensim, LLMs for NLP tasks.\\n\\t+ Knowledge of accelerated DL training distributed training and cloud platforms such as AWS is a bonus.\n",
      "16789  Sr. Applied Scientist, Generative AI Innovation Center  * 5+ years of building machine learning models for business application experience\\n* PhD, or Master's degree and 5+ years of applied research experience\\n* Experience programming in Java, C++, Python or related language\\n* Experience with neural deep learning methods and machine learning\\n* Experience in patents or publications at top-tier peer-reviewed conferences or journals\\n\\n\\nMachine learning (ML) has been strategic to Amazon from the early years. We are pioneers in areas such as recommendation engines, product search, eCommerce fraud detection, and large-scale optimization of fulfillment center operations.\\n  \\n  \\n\\nThe Generative AI team helps AWS customers accelerate the use of Generative AI to solve business and operational problems and promote innovation in their organization. As an applied scientist, you are proficient in designing and developing advanced ML models to solve diverse problems and opportunities. You will be working with terabytes of text, images, and other types of data to solve real-world problems. You'll design and run experiments, research new algorithms, and find new ways of optimizing risk, profitability, and customer experience.\\n  \\n  \\n\\nWere looking for talented scientists capable of applying ML algorithms and cutting-edge deep learning (DL) and reinforcement learning approaches to areas such as drug discovery, customer segmentation, fraud prevention, capacity planning, predictive maintenance, pricing optimization, call center analytics, player pose estimation, event detection, and virtual assistant among others.\\n  \\n  \\n\\nKey job responsibilities\\n  \\n  \\n\\n**The primary responsibilities of this role are to:**  \\n\\n* Design, develop, and evaluate innovative ML models to solve diverse problems and opportunities across industries\\n* Interact with customer directly to understand their business problems, and help them with defining and implementing scalable Generative AI solutions to solve them\\n* Work closely with account teams, research scientist teams, and product engineering teams to drive model implementations and new solution\\n\\n\\nAbout the team\\n  \\nAbout AWS\\n  \\n  \\n\\nDiverse Experiences\\n  \\nAWS values diverse experiences. Even if you do not meet all of the preferred qualifications and skills listed in the job description, we encourage candidates to apply. If your career is just starting, hasnt followed a traditional path, or includes alternative experiences, dont let it stop you from applying.\\n  \\n  \\n\\nWhy AWS?\\n  \\nAmazon Web Services (AWS) is the worlds most comprehensive and broadly adopted cloud platform. We pioneered cloud computing and never stopped innovating  thats why customers from the most successful startups to Global 500 companies trust our robust suite of products and services to power their businesses.\\n  \\n  \\n\\nInclusive Team Culture\\n  \\nHere at AWS, its in our nature to learn and be curious. Our employee-led affinity groups foster a culture of inclusion that empower us to be proud of our differences. Ongoing events and learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences, inspire us to never stop embracing our uniqueness.\\n  \\n  \\n\\nMentorship & Career Growth\\n  \\nWere continuously raising our performance bar as we strive to become Earths Best Employer. Thats why youll find endless knowledge-sharing, mentorship and other career-advancing resources here to help you develop into a better-rounded professional.\\n  \\n  \\n\\nWork/Life Balance\\n  \\nWe value work-life harmony. Achieving success at work should never come at the expense of sacrifices at home, which is why we strive for flexibility as part of our working culture. When we feel supported in the workplace and at home, theres nothing we cant achieve in the cloud.\\n  \\n  \\n\\nAWS Sales, Marketing, and Global Services (SMGS) is responsible for driving revenue, adoption, and growth from the largest and fastest growing small- and mid-market accounts to enterprise-level customers including public sector. The AWS Global Support team interacts with leading companies and believes that world-class support is critical to customer success. AWS Support also partners with a global list of customers that are building mission-critical applications on top of AWS services.\\n  \\n  \\n\\n* Experience in professional software development\\n* PhD degree in computer science, engineering, mathematics, operations research, or in a highly quantitative field\\n* Practical experience in solving complex problems in an applied environment\\n* Hands on experience building models with deep learning frameworks like MXNet, Tensorflow, or PyTorch\\n* Strong communication skills, with attention to detail and ability to convey rigorous mathematical concepts and considerations to non-experts\\n* Comfortable working in a fast paced, highly collaborative, dynamic work environment\\n* Scientific thinking and the ability to invent, a track record of thought leadership and contributions that have advanced the field.\n",
      "5354                 ASUS AICS SG - Machine Learning Engineer                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              #### **About ASUS**\\n\\nAICS is part of ASUS, a multinational company known for the worlds best motherboards, PCs, monitors, graphics cards and routers. Along with an expanding range of superior gaming, content-creation and AIoT solutions, ASUS leads the industry through cutting-edge design and innovations made to create the most ubiquitous, intelligent, heartfelt and joyful smart life for everyone. With a global workforce that includes more than 5,000 R&D professionals, ASUS is driven to become the worlds most admired innovative leading technology enterprise.\\n\\n\\n**About AICS**\\n\\nThe mission of ASUS Intelligent Cloud Services (AICS) is to build revolutionary healthcare solutions with natural language processing, computer vision, and big data analytics. We provide Software as a Service (SaaS) applications to accelerate the effective use of medical data and improve the efficiency of hospital operations, unleashing the power of data for precision healthcare and bringing transformative impact to the industry.  \\n\\n\\n\\n  \\n\\n**Job Responsibilities:**\\n\\n* Research and implement appropriate ML algorithms and tools with a focus on optimizing performance and efficiency in maintenance.\\n* Explore cutting-edge GenAI technology to integrate SOTA methodologies into our practice.\\n* Work closely with an entrepreneurial team of experienced researchers and software engineers to successfully integrate ML models to production and continue to grow our business.\\n\\n**Requirements:**\\n\\n* Bachelors degree or above in computer science or related field with relevant experience\\n* 3+ years of experience with developing machine learning models at scale\\n* Proven experience in NLP or CV projects, like multi-label classification, text summarization, motion detection and object recognition\\n* Proven experience in LLM/VLM project, hands-on experience with pretrain and instruction finetune.\\n* Strong programming in Python, experience with ML frameworks and libraries such as TensorFlow, PyTorch and Transformers.\n",
      "\n",
      "Cosine Similarity Scores:\n",
      "Match 1: 0.7607\n",
      "Match 2: 0.7204\n",
      "Match 3: 0.6965\n",
      "Match 4: 0.6940\n",
      "Match 5: 0.6735\n",
      "\n",
      "Generating embedding for job title: Service Engineer\n",
      "Job title embedding generated successfully!\n",
      "\n",
      "Title matches for 'Service Engineer':\n",
      "7214     Service Engineer\n",
      "17487    Service Engineer\n",
      "15974    Service Engineer\n",
      "18916    Service Engineer\n",
      "17533    Service Engineer\n",
      "\n",
      "Title Similarity Scores:\n",
      "Match 1: 1.0000\n",
      "Match 2: 1.0000\n",
      "Match 3: 1.0000\n",
      "Match 4: 1.0000\n",
      "Match 5: 1.0000\n"
     ]
    }
   ],
   "source": [
    "input_desc = \"\"\"A machine learning (ML) engineer's job is to create artificial intelligence (AI) systems that can mimic human thought processes: \n",
    "Design and build: Create AI algorithm prototypes, design machine learning systems, and build and refine algorithms \n",
    "Test and analyze: Run machine learning tests and experiments, analyze data to identify strengths and weaknesses, and troubleshoot problems \n",
    "Train and monitor: Train, retrain, and monitor machine learning systems and models \n",
    "Collaborate: Collaborate with cross-functional teams to develop and implement machine learning models and algorithms \n",
    "Document: Document all steps in the development process \n",
    "Stay up to date: Stay up to date on the latest innovations in machine learning \n",
    "ML engineers need a variety of skills, including: \n",
    "Deep knowledge of machine learning frameworks \n",
    "Knowledge of programming languages like Python, Java, and C/C++ \n",
    "Strong problem-solving skills and analytical thinking \n",
    "Effective verbal and written communication skills \n",
    "Project management skills \n",
    "A Bachelor's or Master's degree in Computer Science, Engineering, or a related field \n",
    "Prior experience in machine learning, data science, or related fields \"\"\"\n",
    "input_embedding = get_job_description_embedding(input_desc, tokenizer, model, max_chunk_length=512, overlap=50, device=device)\n",
    "similarities = np.dot(np.array(df['job_description_embedding'].tolist()), input_embedding)\n",
    "closest_matches = df.iloc[np.argsort(similarities)[::-1][:5]]\n",
    "print(closest_matches[['title', 'description']].to_string())\n",
    "print(\"\\nCosine Similarity Scores:\")\n",
    "for i, score in enumerate(np.sort(similarities)[::-1][:5]):\n",
    "    print(f\"Match {i+1}: {score:.4f}\")\n",
    "\n",
    "input_title = \"Service Engineer\"\n",
    "title_similarities = np.dot(np.array(df['job_title_embedding'].tolist()), get_job_title_embedding(input_title, tokenizer, model, device=device))\n",
    "title_matches = df.iloc[np.argsort(title_similarities)[::-1][:5]]\n",
    "print(f\"\\nTitle matches for '{input_title}':\")\n",
    "print(title_matches['title'].to_string())\n",
    "print(\"\\nTitle Similarity Scores:\")\n",
    "for i, score in enumerate(np.sort(title_similarities)[::-1][:5]):\n",
    "    print(f\"Match {i+1}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>job_type</th>\n",
       "      <th>is_remote</th>\n",
       "      <th>description</th>\n",
       "      <th>address</th>\n",
       "      <th>cleaned_address</th>\n",
       "      <th>lat_long</th>\n",
       "      <th>model_response</th>\n",
       "      <th>id</th>\n",
       "      <th>job_url</th>\n",
       "      <th>job_url_direct</th>\n",
       "      <th>job_type_cleaned</th>\n",
       "      <th>job_type_encoded</th>\n",
       "      <th>job_title_embedding</th>\n",
       "      <th>job_description_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Porter</td>\n",
       "      <td>PHOENIX OPCO PTE. LTD.</td>\n",
       "      <td>fulltime</td>\n",
       "      <td>False</td>\n",
       "      <td>Are you currently working in a service based e...</td>\n",
       "      <td>Tras Street, #9-177 Union Building, 079025</td>\n",
       "      <td>Tras Street,  Union Building, 079025</td>\n",
       "      <td>(1.27444651846065, 103.843929515239)</td>\n",
       "      <td>Responsibilities\\n    Ensure guest experiences...</td>\n",
       "      <td>0005a77c5af02f32</td>\n",
       "      <td>https://sg.indeed.com/viewjob?jk=0005a77c5af02f32</td>\n",
       "      <td>https://www.mycareersfuture.gov.sg/job/custome...</td>\n",
       "      <td>fulltime</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>[-0.032369263, 0.037560612, -0.08516074, -0.04...</td>\n",
       "      <td>[0.036492854, 0.022954665, 0.038240157, 0.0592...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Outlet Executive - Tan Tock Seng Hospital</td>\n",
       "      <td>Kopitiam Investment Pte Ltd</td>\n",
       "      <td>fulltime</td>\n",
       "      <td>False</td>\n",
       "      <td>Outlet Executive - Tan Tock Seng Hospital\\nRes...</td>\n",
       "      <td>1 Joo Koon Cir, #13-01 FairPrice Joo Koon, Sin...</td>\n",
       "      <td>1 Joo Koon Cir,  FairPrice Joo Koon, Singapore...</td>\n",
       "      <td>(1.32476879097421, 103.674484690433)</td>\n",
       "      <td>Responsibilities\\n Operations\\n    Support Out...</td>\n",
       "      <td>000989af12dd337f</td>\n",
       "      <td>https://sg.indeed.com/viewjob?jk=000989af12dd337f</td>\n",
       "      <td>https://kopitiam.recruiterpal.com/career/jobs/...</td>\n",
       "      <td>fulltime</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>[-0.059394874, 0.07162735, -0.06818533, 0.0556...</td>\n",
       "      <td>[-0.007846934, 0.04081503, -0.030761063, -0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sales Promoter</td>\n",
       "      <td>Oomph Pte. Ltd.</td>\n",
       "      <td>fulltime</td>\n",
       "      <td>False</td>\n",
       "      <td>SALARY UP TO $4,000.00 (subject to experience)...</td>\n",
       "      <td>2 Alexandra Rd, #04-01 Delta House, Singapore ...</td>\n",
       "      <td>2 Alexandra Rd,  Delta House, Singapore 159919</td>\n",
       "      <td>(1.27425442821763, 103.803711567804)</td>\n",
       "      <td>Aspect 1 Responsibilities\\n Actively promote l...</td>\n",
       "      <td>000a01db7a6ccc16</td>\n",
       "      <td>https://sg.indeed.com/viewjob?jk=000a01db7a6ccc16</td>\n",
       "      <td>https://www.mycareersfuture.gov.sg/job/custome...</td>\n",
       "      <td>fulltime</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>[-0.050802007, -0.00822947, -0.035635166, -0.0...</td>\n",
       "      <td>[-0.0066097165, 0.06563731, -0.025015522, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quantity Surveyor</td>\n",
       "      <td>LBD ENGINEERING PTE. LTD.</td>\n",
       "      <td>fulltime</td>\n",
       "      <td>False</td>\n",
       "      <td>Job Description\\n\\n\\n* Prepare and analyse cos...</td>\n",
       "      <td>58A Sungei Kadut Loop, LBD Construction Group ...</td>\n",
       "      <td>58A Sungei Kadut Loop, LBD Construction Group ...</td>\n",
       "      <td>(1.40981215298244, 103.742781634928)</td>\n",
       "      <td>Responsibilities\\n\\n Prepare and analyze cost ...</td>\n",
       "      <td>000bdc93e15d1325</td>\n",
       "      <td>https://sg.indeed.com/viewjob?jk=000bdc93e15d1325</td>\n",
       "      <td>https://www.mycareersfuture.gov.sg/job/buildin...</td>\n",
       "      <td>fulltime</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>[-0.027023997, 0.025126753, 0.0062498134, -0.0...</td>\n",
       "      <td>[-0.0005235376, 0.031939197, 0.05250165, 0.031...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cleaning Operations Assistant Supervisor</td>\n",
       "      <td>ECOCLEAN MAINTENANCE PTE. LTD.</td>\n",
       "      <td>fulltime</td>\n",
       "      <td>False</td>\n",
       "      <td>**Requirements**\\n\\n* at least 3 years of work...</td>\n",
       "      <td>1 Yishun Industrial Street 1, #06-27 A'Posh Bi...</td>\n",
       "      <td>1 Yishun Industrial Street 1,  A'Posh BizHub, ...</td>\n",
       "      <td>(1.43732110123747, 103.842085763701)</td>\n",
       "      <td>Responsibilities\\n Respond to emergency calls,...</td>\n",
       "      <td>000be27bd990645d</td>\n",
       "      <td>https://sg.indeed.com/viewjob?jk=000be27bd990645d</td>\n",
       "      <td>https://www.mycareersfuture.gov.sg/job/others/...</td>\n",
       "      <td>fulltime</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>[-0.0720216, -0.00010167251, 0.05262413, -0.02...</td>\n",
       "      <td>[0.0046085776, 0.013509961, 0.048739396, -0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25605</th>\n",
       "      <td>AV Engineer (Based in Sri Lanka)</td>\n",
       "      <td>Spectrum Audio Visual Pte Ltd</td>\n",
       "      <td>fulltime</td>\n",
       "      <td>False</td>\n",
       "      <td>**Job Objective:**\\n\\n* Work closely with manu...</td>\n",
       "      <td>41 Kallang Pudding Rd, #07-00 Golden Wheel Bui...</td>\n",
       "      <td>41 Kallang Pudding Rd,  Golden Wheel Building,...</td>\n",
       "      <td>(1.32922242996711, 103.878996925493)</td>\n",
       "      <td>Responsibilities\\n\\n System configuration, Tes...</td>\n",
       "      <td>fff44a23abbb24b8</td>\n",
       "      <td>https://sg.indeed.com/viewjob?jk=fff44a23abbb24b8</td>\n",
       "      <td>https://www.mycareersfuture.gov.sg/job/enginee...</td>\n",
       "      <td>fulltime</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>[0.017765759, 0.0026095482, 0.021792056, -0.02...</td>\n",
       "      <td>[0.046365045, 0.021310633, 0.044983394, -0.029...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25606</th>\n",
       "      <td>Batch Operator, DC Operations</td>\n",
       "      <td>ITCAN Pte Ltd</td>\n",
       "      <td>fulltime, contract</td>\n",
       "      <td>False</td>\n",
       "      <td>* DC operation\\n* Provide Batch Scheduling / c...</td>\n",
       "      <td>30 Cecil St, #18-08, Singapore 049712</td>\n",
       "      <td>30 Cecil St, , Singapore 049712</td>\n",
       "      <td>(1.27967894092681, 103.84859453785)</td>\n",
       "      <td>Responsibilities\\n    DC operation\\n    Provid...</td>\n",
       "      <td>fff7a157262619d5</td>\n",
       "      <td>https://sg.indeed.com/viewjob?jk=fff7a157262619d5</td>\n",
       "      <td>http://sg.indeed.com/job/batch-operator-dc-ope...</td>\n",
       "      <td>fulltime,contract</td>\n",
       "      <td>[1, 1, 0, 0, 0]</td>\n",
       "      <td>[-0.056008913, 0.03407558, -0.03200176, -0.055...</td>\n",
       "      <td>[-0.077440314, 0.04420748, -0.020601498, -0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25607</th>\n",
       "      <td>Business Development Consultant (Recruitment)</td>\n",
       "      <td>RECRUITPEDIA PTE. LTD.</td>\n",
       "      <td>fulltime</td>\n",
       "      <td>False</td>\n",
       "      <td>**We are a centrally located boutique recruitm...</td>\n",
       "      <td>146 Robinson Rd, Singapore 068909</td>\n",
       "      <td>146 Robinson Rd, Singapore 068909</td>\n",
       "      <td>(1.27954844710103, 103.848970997768)</td>\n",
       "      <td>Job Highlights\\n Startup environment, welcomin...</td>\n",
       "      <td>fff8178deb218454</td>\n",
       "      <td>https://sg.indeed.com/viewjob?jk=fff8178deb218454</td>\n",
       "      <td>https://www.mycareersfuture.gov.sg/job/admin/b...</td>\n",
       "      <td>fulltime</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>[0.010034194, -0.013607246, -0.05233627, 0.050...</td>\n",
       "      <td>[0.00701115, 0.04573657, 0.02808972, 0.0588057...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25608</th>\n",
       "      <td>TRUCK DRIVER</td>\n",
       "      <td>FE CONSULTANCY</td>\n",
       "      <td>fulltime</td>\n",
       "      <td>False</td>\n",
       "      <td>* Planning routes and travel schedules to ensu...</td>\n",
       "      <td>21 Bukit Batok Cres, #07-84 Wcega Tower, Singa...</td>\n",
       "      <td>21 Bukit Batok Cres,  Wcega Tower, Singapore 6...</td>\n",
       "      <td>(1.33696571508317, 103.759665479168)</td>\n",
       "      <td>Responsibilities\\n Planning routes and travel ...</td>\n",
       "      <td>fffa91c5d0e3d752</td>\n",
       "      <td>https://sg.indeed.com/viewjob?jk=fffa91c5d0e3d752</td>\n",
       "      <td>https://www.mycareersfuture.gov.sg/job/general...</td>\n",
       "      <td>fulltime</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>[-0.023009812, 0.056057077, -0.010153614, 0.00...</td>\n",
       "      <td>[0.026069092, -0.024150336, 0.0052029975, 0.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25609</th>\n",
       "      <td>Director, AUD Rates Trader, Global Markets and...</td>\n",
       "      <td>Sumitomo Mitsui Banking Corporation</td>\n",
       "      <td>fulltime</td>\n",
       "      <td>False</td>\n",
       "      <td>**Job Responsibilities**\\n* Primary responsibi...</td>\n",
       "      <td>88 Market St, #33-01, Singapore 048948</td>\n",
       "      <td>88 Market St, , Singapore 048948</td>\n",
       "      <td>(1.28446676154254, 103.850660645126)</td>\n",
       "      <td>Job Responsibilities\\n Primary responsibility ...</td>\n",
       "      <td>fffb23bb5f718b14</td>\n",
       "      <td>https://sg.indeed.com/viewjob?jk=fffb23bb5f718b14</td>\n",
       "      <td>https://www.efinancialcareers.sg/jobs-Singapor...</td>\n",
       "      <td>fulltime</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>[-0.046709396, 0.024411831, 0.0007536252, 0.00...</td>\n",
       "      <td>[-0.043065317, -0.007592732, -0.054091353, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25610 rows  16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0                                                 Porter   \n",
       "1              Outlet Executive - Tan Tock Seng Hospital   \n",
       "2                                         Sales Promoter   \n",
       "3                                      Quantity Surveyor   \n",
       "4               Cleaning Operations Assistant Supervisor   \n",
       "...                                                  ...   \n",
       "25605                   AV Engineer (Based in Sri Lanka)   \n",
       "25606                      Batch Operator, DC Operations   \n",
       "25607      Business Development Consultant (Recruitment)   \n",
       "25608                                       TRUCK DRIVER   \n",
       "25609  Director, AUD Rates Trader, Global Markets and...   \n",
       "\n",
       "                                   company            job_type  is_remote  \\\n",
       "0                   PHOENIX OPCO PTE. LTD.            fulltime      False   \n",
       "1              Kopitiam Investment Pte Ltd            fulltime      False   \n",
       "2                          Oomph Pte. Ltd.            fulltime      False   \n",
       "3                LBD ENGINEERING PTE. LTD.            fulltime      False   \n",
       "4           ECOCLEAN MAINTENANCE PTE. LTD.            fulltime      False   \n",
       "...                                    ...                 ...        ...   \n",
       "25605        Spectrum Audio Visual Pte Ltd            fulltime      False   \n",
       "25606                        ITCAN Pte Ltd  fulltime, contract      False   \n",
       "25607               RECRUITPEDIA PTE. LTD.            fulltime      False   \n",
       "25608                       FE CONSULTANCY            fulltime      False   \n",
       "25609  Sumitomo Mitsui Banking Corporation            fulltime      False   \n",
       "\n",
       "                                             description  \\\n",
       "0      Are you currently working in a service based e...   \n",
       "1      Outlet Executive - Tan Tock Seng Hospital\\nRes...   \n",
       "2      SALARY UP TO $4,000.00 (subject to experience)...   \n",
       "3      Job Description\\n\\n\\n* Prepare and analyse cos...   \n",
       "4      **Requirements**\\n\\n* at least 3 years of work...   \n",
       "...                                                  ...   \n",
       "25605  **Job Objective:**\\n\\n* Work closely with manu...   \n",
       "25606  * DC operation\\n* Provide Batch Scheduling / c...   \n",
       "25607  **We are a centrally located boutique recruitm...   \n",
       "25608  * Planning routes and travel schedules to ensu...   \n",
       "25609  **Job Responsibilities**\\n* Primary responsibi...   \n",
       "\n",
       "                                                 address  \\\n",
       "0             Tras Street, #9-177 Union Building, 079025   \n",
       "1      1 Joo Koon Cir, #13-01 FairPrice Joo Koon, Sin...   \n",
       "2      2 Alexandra Rd, #04-01 Delta House, Singapore ...   \n",
       "3      58A Sungei Kadut Loop, LBD Construction Group ...   \n",
       "4      1 Yishun Industrial Street 1, #06-27 A'Posh Bi...   \n",
       "...                                                  ...   \n",
       "25605  41 Kallang Pudding Rd, #07-00 Golden Wheel Bui...   \n",
       "25606              30 Cecil St, #18-08, Singapore 049712   \n",
       "25607                  146 Robinson Rd, Singapore 068909   \n",
       "25608  21 Bukit Batok Cres, #07-84 Wcega Tower, Singa...   \n",
       "25609             88 Market St, #33-01, Singapore 048948   \n",
       "\n",
       "                                         cleaned_address  \\\n",
       "0                   Tras Street,  Union Building, 079025   \n",
       "1      1 Joo Koon Cir,  FairPrice Joo Koon, Singapore...   \n",
       "2         2 Alexandra Rd,  Delta House, Singapore 159919   \n",
       "3      58A Sungei Kadut Loop, LBD Construction Group ...   \n",
       "4      1 Yishun Industrial Street 1,  A'Posh BizHub, ...   \n",
       "...                                                  ...   \n",
       "25605  41 Kallang Pudding Rd,  Golden Wheel Building,...   \n",
       "25606                    30 Cecil St, , Singapore 049712   \n",
       "25607                  146 Robinson Rd, Singapore 068909   \n",
       "25608  21 Bukit Batok Cres,  Wcega Tower, Singapore 6...   \n",
       "25609                   88 Market St, , Singapore 048948   \n",
       "\n",
       "                                   lat_long  \\\n",
       "0      (1.27444651846065, 103.843929515239)   \n",
       "1      (1.32476879097421, 103.674484690433)   \n",
       "2      (1.27425442821763, 103.803711567804)   \n",
       "3      (1.40981215298244, 103.742781634928)   \n",
       "4      (1.43732110123747, 103.842085763701)   \n",
       "...                                     ...   \n",
       "25605  (1.32922242996711, 103.878996925493)   \n",
       "25606   (1.27967894092681, 103.84859453785)   \n",
       "25607  (1.27954844710103, 103.848970997768)   \n",
       "25608  (1.33696571508317, 103.759665479168)   \n",
       "25609  (1.28446676154254, 103.850660645126)   \n",
       "\n",
       "                                          model_response                id  \\\n",
       "0      Responsibilities\\n    Ensure guest experiences...  0005a77c5af02f32   \n",
       "1      Responsibilities\\n Operations\\n    Support Out...  000989af12dd337f   \n",
       "2      Aspect 1 Responsibilities\\n Actively promote l...  000a01db7a6ccc16   \n",
       "3      Responsibilities\\n\\n Prepare and analyze cost ...  000bdc93e15d1325   \n",
       "4      Responsibilities\\n Respond to emergency calls,...  000be27bd990645d   \n",
       "...                                                  ...               ...   \n",
       "25605  Responsibilities\\n\\n System configuration, Tes...  fff44a23abbb24b8   \n",
       "25606  Responsibilities\\n    DC operation\\n    Provid...  fff7a157262619d5   \n",
       "25607  Job Highlights\\n Startup environment, welcomin...  fff8178deb218454   \n",
       "25608  Responsibilities\\n Planning routes and travel ...  fffa91c5d0e3d752   \n",
       "25609  Job Responsibilities\\n Primary responsibility ...  fffb23bb5f718b14   \n",
       "\n",
       "                                                 job_url  \\\n",
       "0      https://sg.indeed.com/viewjob?jk=0005a77c5af02f32   \n",
       "1      https://sg.indeed.com/viewjob?jk=000989af12dd337f   \n",
       "2      https://sg.indeed.com/viewjob?jk=000a01db7a6ccc16   \n",
       "3      https://sg.indeed.com/viewjob?jk=000bdc93e15d1325   \n",
       "4      https://sg.indeed.com/viewjob?jk=000be27bd990645d   \n",
       "...                                                  ...   \n",
       "25605  https://sg.indeed.com/viewjob?jk=fff44a23abbb24b8   \n",
       "25606  https://sg.indeed.com/viewjob?jk=fff7a157262619d5   \n",
       "25607  https://sg.indeed.com/viewjob?jk=fff8178deb218454   \n",
       "25608  https://sg.indeed.com/viewjob?jk=fffa91c5d0e3d752   \n",
       "25609  https://sg.indeed.com/viewjob?jk=fffb23bb5f718b14   \n",
       "\n",
       "                                          job_url_direct   job_type_cleaned  \\\n",
       "0      https://www.mycareersfuture.gov.sg/job/custome...           fulltime   \n",
       "1      https://kopitiam.recruiterpal.com/career/jobs/...           fulltime   \n",
       "2      https://www.mycareersfuture.gov.sg/job/custome...           fulltime   \n",
       "3      https://www.mycareersfuture.gov.sg/job/buildin...           fulltime   \n",
       "4      https://www.mycareersfuture.gov.sg/job/others/...           fulltime   \n",
       "...                                                  ...                ...   \n",
       "25605  https://www.mycareersfuture.gov.sg/job/enginee...           fulltime   \n",
       "25606  http://sg.indeed.com/job/batch-operator-dc-ope...  fulltime,contract   \n",
       "25607  https://www.mycareersfuture.gov.sg/job/admin/b...           fulltime   \n",
       "25608  https://www.mycareersfuture.gov.sg/job/general...           fulltime   \n",
       "25609  https://www.efinancialcareers.sg/jobs-Singapor...           fulltime   \n",
       "\n",
       "      job_type_encoded                                job_title_embedding  \\\n",
       "0      [0, 1, 0, 0, 0]  [-0.032369263, 0.037560612, -0.08516074, -0.04...   \n",
       "1      [0, 1, 0, 0, 0]  [-0.059394874, 0.07162735, -0.06818533, 0.0556...   \n",
       "2      [0, 1, 0, 0, 0]  [-0.050802007, -0.00822947, -0.035635166, -0.0...   \n",
       "3      [0, 1, 0, 0, 0]  [-0.027023997, 0.025126753, 0.0062498134, -0.0...   \n",
       "4      [0, 1, 0, 0, 0]  [-0.0720216, -0.00010167251, 0.05262413, -0.02...   \n",
       "...                ...                                                ...   \n",
       "25605  [0, 1, 0, 0, 0]  [0.017765759, 0.0026095482, 0.021792056, -0.02...   \n",
       "25606  [1, 1, 0, 0, 0]  [-0.056008913, 0.03407558, -0.03200176, -0.055...   \n",
       "25607  [0, 1, 0, 0, 0]  [0.010034194, -0.013607246, -0.05233627, 0.050...   \n",
       "25608  [0, 1, 0, 0, 0]  [-0.023009812, 0.056057077, -0.010153614, 0.00...   \n",
       "25609  [0, 1, 0, 0, 0]  [-0.046709396, 0.024411831, 0.0007536252, 0.00...   \n",
       "\n",
       "                               job_description_embedding  \n",
       "0      [0.036492854, 0.022954665, 0.038240157, 0.0592...  \n",
       "1      [-0.007846934, 0.04081503, -0.030761063, -0.03...  \n",
       "2      [-0.0066097165, 0.06563731, -0.025015522, -0.0...  \n",
       "3      [-0.0005235376, 0.031939197, 0.05250165, 0.031...  \n",
       "4      [0.0046085776, 0.013509961, 0.048739396, -0.04...  \n",
       "...                                                  ...  \n",
       "25605  [0.046365045, 0.021310633, 0.044983394, -0.029...  \n",
       "25606  [-0.077440314, 0.04420748, -0.020601498, -0.02...  \n",
       "25607  [0.00701115, 0.04573657, 0.02808972, 0.0588057...  \n",
       "25608  [0.026069092, -0.024150336, 0.0052029975, 0.07...  \n",
       "25609  [-0.043065317, -0.007592732, -0.054091353, 0.0...  \n",
       "\n",
       "[25610 rows x 16 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
